{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, WhisperConfig\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS is available\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_mapping(transcript_dir, audio_dir):\n",
    "    # Create lists of transcript and audio file paths\n",
    "    transcript_paths = [os.path.join(transcript_dir, filename) for filename in os.listdir(transcript_dir) if filename.endswith('.txt')]\n",
    "    audio_paths = [os.path.join(audio_dir, filename) for filename in os.listdir(audio_dir) if filename.endswith('.wav')]\n",
    "\n",
    "    # Extract identifiers from filenames\n",
    "    transcript_ids = [os.path.splitext(os.path.basename(path))[0] for path in transcript_paths]\n",
    "    audio_ids = [os.path.splitext(os.path.basename(path))[0] for path in audio_paths]\n",
    "\n",
    "    # Create a dictionary to map identifiers to file paths\n",
    "    file_mapping = {\n",
    "        'Interview': [],\n",
    "        'Transcript Path': [],\n",
    "        'Audio Path': []\n",
    "    }\n",
    "\n",
    "    # Match transcript files with audio files using their identifiers\n",
    "    for transcript_id in transcript_ids:\n",
    "        if transcript_id in audio_ids:\n",
    "            transcript_path = os.path.join(transcript_dir, transcript_id + '.txt')\n",
    "            audio_path = os.path.join(audio_dir, transcript_id + '.wav')\n",
    "            file_mapping['Interview'].append(transcript_id)\n",
    "            file_mapping['Transcript Path'].append(transcript_path)\n",
    "            file_mapping['Audio Path'].append(audio_path)\n",
    "\n",
    "    # Create DataFrame from the file mapping dictionary\n",
    "    df = pd.DataFrame(file_mapping)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interview</th>\n",
       "      <th>Transcript Path</th>\n",
       "      <th>Audio Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag2_f_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag2_f_02_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL_se0_ag2_m_02_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag2_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag2_m_02_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL_se0_ag2_f_01_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag2_f_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag2_f_01_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL_se0_ag2_m_03_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag2_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag2_m_03_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL_se0_ag2_m_01_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag2_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag2_m_01_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ATL_se0_ag1_m_05_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_m_05_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ATL_se0_ag1_m_03_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_m_03_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ATL_se0_ag1_f_01_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_f_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_f_01_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ATL_se0_ag1_f_03_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_f_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_f_03_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ATL_se0_ag1_m_01_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_m_01_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ATL_se0_ag1_m_04_2</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_m_04_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ATL_se0_ag1_m_04_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_m_04_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ATL_se0_ag1_f_02_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_f_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_f_02_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_m_02_1.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Interview                                    Transcript Path  \\\n",
       "0   ATL_se0_ag2_f_02_1  ../data/coraal/transcript/text/ATL_se0_ag2_f_0...   \n",
       "1   ATL_se0_ag2_m_02_1  ../data/coraal/transcript/text/ATL_se0_ag2_m_0...   \n",
       "2   ATL_se0_ag2_f_01_1  ../data/coraal/transcript/text/ATL_se0_ag2_f_0...   \n",
       "3   ATL_se0_ag2_m_03_1  ../data/coraal/transcript/text/ATL_se0_ag2_m_0...   \n",
       "4   ATL_se0_ag2_m_01_1  ../data/coraal/transcript/text/ATL_se0_ag2_m_0...   \n",
       "5   ATL_se0_ag1_m_05_1  ../data/coraal/transcript/text/ATL_se0_ag1_m_0...   \n",
       "6   ATL_se0_ag1_m_03_1  ../data/coraal/transcript/text/ATL_se0_ag1_m_0...   \n",
       "7   ATL_se0_ag1_f_01_1  ../data/coraal/transcript/text/ATL_se0_ag1_f_0...   \n",
       "8   ATL_se0_ag1_f_03_1  ../data/coraal/transcript/text/ATL_se0_ag1_f_0...   \n",
       "9   ATL_se0_ag1_m_01_1  ../data/coraal/transcript/text/ATL_se0_ag1_m_0...   \n",
       "10  ATL_se0_ag1_m_04_2  ../data/coraal/transcript/text/ATL_se0_ag1_m_0...   \n",
       "11  ATL_se0_ag1_m_04_1  ../data/coraal/transcript/text/ATL_se0_ag1_m_0...   \n",
       "12  ATL_se0_ag1_f_02_1  ../data/coraal/transcript/text/ATL_se0_ag1_f_0...   \n",
       "13  ATL_se0_ag1_m_02_1  ../data/coraal/transcript/text/ATL_se0_ag1_m_0...   \n",
       "\n",
       "                                         Audio Path  \n",
       "0   ../data/coraal/audio/wav/ATL_se0_ag2_f_02_1.wav  \n",
       "1   ../data/coraal/audio/wav/ATL_se0_ag2_m_02_1.wav  \n",
       "2   ../data/coraal/audio/wav/ATL_se0_ag2_f_01_1.wav  \n",
       "3   ../data/coraal/audio/wav/ATL_se0_ag2_m_03_1.wav  \n",
       "4   ../data/coraal/audio/wav/ATL_se0_ag2_m_01_1.wav  \n",
       "5   ../data/coraal/audio/wav/ATL_se0_ag1_m_05_1.wav  \n",
       "6   ../data/coraal/audio/wav/ATL_se0_ag1_m_03_1.wav  \n",
       "7   ../data/coraal/audio/wav/ATL_se0_ag1_f_01_1.wav  \n",
       "8   ../data/coraal/audio/wav/ATL_se0_ag1_f_03_1.wav  \n",
       "9   ../data/coraal/audio/wav/ATL_se0_ag1_m_01_1.wav  \n",
       "10  ../data/coraal/audio/wav/ATL_se0_ag1_m_04_2.wav  \n",
       "11  ../data/coraal/audio/wav/ATL_se0_ag1_m_04_1.wav  \n",
       "12  ../data/coraal/audio/wav/ATL_se0_ag1_f_02_1.wav  \n",
       "13  ../data/coraal/audio/wav/ATL_se0_ag1_m_02_1.wav  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "transcript_dir = '../data/coraal/transcript/text/'\n",
    "audio_dir = '../data/coraal/audio/wav/'\n",
    "\n",
    "paths_df = create_file_mapping(transcript_dir, audio_dir)\n",
    "display(paths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transcripts(paths_df):\n",
    "    all_transcript_data = []\n",
    "\n",
    "    # Iterate over each row in the file_mapping_df\n",
    "    for _, row in paths_df.iterrows():\n",
    "        transcript_path = row['Transcript Path']\n",
    "        \n",
    "        # Load transcript data\n",
    "        transcript_df = pd.read_csv(transcript_path, delimiter=\"\\t\")\n",
    "        \n",
    "        # Extract relevant columns\n",
    "        transcript_data = transcript_df[['StTime', 'EnTime', 'Content']].copy()\n",
    "        \n",
    "        # Convert times from minutes to milliseconds for easier calculations\n",
    "        transcript_data['StTime'] *= 1000\n",
    "        transcript_data['EnTime'] *= 1000\n",
    "        transcript_data['Content'] = transcript_data['Content'].str.upper()\n",
    "        \n",
    "        # Add identifier column (optional)\n",
    "        transcript_data['Interview'] = row['Interview']\n",
    "\n",
    "        # Append to list\n",
    "        all_transcript_data.append(transcript_data)\n",
    "    \n",
    "    # Combine all transcript data into a single DataFrame\n",
    "    combined_transcript_df = pd.concat(all_transcript_data, ignore_index=True)\n",
    "    \n",
    "    return combined_transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>Interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>752.6</td>\n",
       "      <td>2511.3</td>\n",
       "      <td>HEY WHAT'S GOING ON?</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2511.3</td>\n",
       "      <td>3144.7</td>\n",
       "      <td>(PAUSE 0.63)</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3144.7</td>\n",
       "      <td>4165.9</td>\n",
       "      <td>I'M HERE WITH</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4165.9</td>\n",
       "      <td>5083.0</td>\n",
       "      <td>(PAUSE 0.92)</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5083.0</td>\n",
       "      <td>5853.6</td>\n",
       "      <td>/RD-NAME-2/.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5853.6</td>\n",
       "      <td>6312.2</td>\n",
       "      <td>(PAUSE 0.46)</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6312.2</td>\n",
       "      <td>7844.7</td>\n",
       "      <td>THIS IS /RD-NAME-2/ BY THE WAY.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7844.7</td>\n",
       "      <td>8799.6</td>\n",
       "      <td>(PAUSE 0.95)</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8799.6</td>\n",
       "      <td>10241.5</td>\n",
       "      <td>UM, /RD-NAME-2/, IF YOU COULD</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10241.5</td>\n",
       "      <td>10534.6</td>\n",
       "      <td>(PAUSE 0.29)</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    StTime   EnTime                          Content           Interview\n",
       "0    752.6   2511.3             HEY WHAT'S GOING ON?  ATL_se0_ag2_f_02_1\n",
       "1   2511.3   3144.7                     (PAUSE 0.63)  ATL_se0_ag2_f_02_1\n",
       "2   3144.7   4165.9                    I'M HERE WITH  ATL_se0_ag2_f_02_1\n",
       "3   4165.9   5083.0                     (PAUSE 0.92)  ATL_se0_ag2_f_02_1\n",
       "4   5083.0   5853.6                     /RD-NAME-2/.  ATL_se0_ag2_f_02_1\n",
       "5   5853.6   6312.2                     (PAUSE 0.46)  ATL_se0_ag2_f_02_1\n",
       "6   6312.2   7844.7  THIS IS /RD-NAME-2/ BY THE WAY.  ATL_se0_ag2_f_02_1\n",
       "7   7844.7   8799.6                     (PAUSE 0.95)  ATL_se0_ag2_f_02_1\n",
       "8   8799.6  10241.5    UM, /RD-NAME-2/, IF YOU COULD  ATL_se0_ag2_f_02_1\n",
       "9  10241.5  10534.6                     (PAUSE 0.29)  ATL_se0_ag2_f_02_1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>Interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23827</th>\n",
       "      <td>2423303.1</td>\n",
       "      <td>2424396.2</td>\n",
       "      <td>ABOUT YOUR FUTURE.</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23828</th>\n",
       "      <td>2424396.2</td>\n",
       "      <td>2425081.9</td>\n",
       "      <td>(PAUSE 0.69)</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23829</th>\n",
       "      <td>2425081.9</td>\n",
       "      <td>2425860.4</td>\n",
       "      <td>DEFINITELY GONNA</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23830</th>\n",
       "      <td>2425937.8</td>\n",
       "      <td>2426912.2</td>\n",
       "      <td>I APPRECIATE [THAT.]</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23831</th>\n",
       "      <td>2426726.6</td>\n",
       "      <td>2428514.3</td>\n",
       "      <td>[BE IN] TOUCH AFTER THIS INTERVIEW,</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23832</th>\n",
       "      <td>2429019.6</td>\n",
       "      <td>2429658.9</td>\n",
       "      <td>AND, UM,</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23833</th>\n",
       "      <td>2429658.9</td>\n",
       "      <td>2430942.7</td>\n",
       "      <td>(PAUSE 1.28)</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23834</th>\n",
       "      <td>2430942.7</td>\n",
       "      <td>2432412.1</td>\n",
       "      <td>IT'S /RD-NAME-3/, AND</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23835</th>\n",
       "      <td>2432412.1</td>\n",
       "      <td>2433113.3</td>\n",
       "      <td>(PAUSE 0.70)</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23836</th>\n",
       "      <td>2433113.3</td>\n",
       "      <td>2434628.8</td>\n",
       "      <td>I'M SIGNING OFF. THIS IS A WRAP.</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          StTime     EnTime                              Content  \\\n",
       "23827  2423303.1  2424396.2                   ABOUT YOUR FUTURE.   \n",
       "23828  2424396.2  2425081.9                         (PAUSE 0.69)   \n",
       "23829  2425081.9  2425860.4                     DEFINITELY GONNA   \n",
       "23830  2425937.8  2426912.2                 I APPRECIATE [THAT.]   \n",
       "23831  2426726.6  2428514.3  [BE IN] TOUCH AFTER THIS INTERVIEW,   \n",
       "23832  2429019.6  2429658.9                             AND, UM,   \n",
       "23833  2429658.9  2430942.7                         (PAUSE 1.28)   \n",
       "23834  2430942.7  2432412.1                IT'S /RD-NAME-3/, AND   \n",
       "23835  2432412.1  2433113.3                         (PAUSE 0.70)   \n",
       "23836  2433113.3  2434628.8     I'M SIGNING OFF. THIS IS A WRAP.   \n",
       "\n",
       "                Interview  \n",
       "23827  ATL_se0_ag1_m_02_1  \n",
       "23828  ATL_se0_ag1_m_02_1  \n",
       "23829  ATL_se0_ag1_m_02_1  \n",
       "23830  ATL_se0_ag1_m_02_1  \n",
       "23831  ATL_se0_ag1_m_02_1  \n",
       "23832  ATL_se0_ag1_m_02_1  \n",
       "23833  ATL_se0_ag1_m_02_1  \n",
       "23834  ATL_se0_ag1_m_02_1  \n",
       "23835  ATL_se0_ag1_m_02_1  \n",
       "23836  ATL_se0_ag1_m_02_1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "combined_transcript_df = process_transcripts(paths_df)\n",
    "display(combined_transcript_df.head(10), combined_transcript_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>Interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>752.6</td>\n",
       "      <td>2511.3</td>\n",
       "      <td>HEY WHAT'S GOING ON?</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3144.7</td>\n",
       "      <td>4165.9</td>\n",
       "      <td>I'M HERE WITH</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10534.6</td>\n",
       "      <td>11289.9</td>\n",
       "      <td>SAY HELLO.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12142.4</td>\n",
       "      <td>12846.2</td>\n",
       "      <td>HELLO.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13458.1</td>\n",
       "      <td>13962.9</td>\n",
       "      <td>OKAY,</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14227.6</td>\n",
       "      <td>15991.0</td>\n",
       "      <td>MIC SEEMS TO BE PICKING YOU UP WELL.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16841.9</td>\n",
       "      <td>17230.4</td>\n",
       "      <td>UM,</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17306.0</td>\n",
       "      <td>17618.0</td>\n",
       "      <td>MM.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17646.4</td>\n",
       "      <td>18227.9</td>\n",
       "      <td>WE'LL GO</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18932.3</td>\n",
       "      <td>21206.2</td>\n",
       "      <td>AND, UM, CONTINUE WITH THIS INTERVIEW.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    StTime   EnTime                                 Content  \\\n",
       "0    752.6   2511.3                    HEY WHAT'S GOING ON?   \n",
       "1   3144.7   4165.9                           I'M HERE WITH   \n",
       "2  10534.6  11289.9                              SAY HELLO.   \n",
       "3  12142.4  12846.2                                  HELLO.   \n",
       "4  13458.1  13962.9                                   OKAY,   \n",
       "5  14227.6  15991.0    MIC SEEMS TO BE PICKING YOU UP WELL.   \n",
       "6  16841.9  17230.4                                     UM,   \n",
       "7  17306.0  17618.0                                     MM.   \n",
       "8  17646.4  18227.9                                WE'LL GO   \n",
       "9  18932.3  21206.2  AND, UM, CONTINUE WITH THIS INTERVIEW.   \n",
       "\n",
       "            Interview  \n",
       "0  ATL_se0_ag2_f_02_1  \n",
       "1  ATL_se0_ag2_f_02_1  \n",
       "2  ATL_se0_ag2_f_02_1  \n",
       "3  ATL_se0_ag2_f_02_1  \n",
       "4  ATL_se0_ag2_f_02_1  \n",
       "5  ATL_se0_ag2_f_02_1  \n",
       "6  ATL_se0_ag2_f_02_1  \n",
       "7  ATL_se0_ag2_f_02_1  \n",
       "8  ATL_se0_ag2_f_02_1  \n",
       "9  ATL_se0_ag2_f_02_1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>Interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9958</th>\n",
       "      <td>2405803.3</td>\n",
       "      <td>2407020.0</td>\n",
       "      <td>THAT WAS DOPE AS WELL, MAN.</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9959</th>\n",
       "      <td>2409658.4</td>\n",
       "      <td>2411158.8</td>\n",
       "      <td>OH MAN, WELL,</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9960</th>\n",
       "      <td>2415648.1</td>\n",
       "      <td>2417452.7</td>\n",
       "      <td>AND THE WORDS OF WISDOM</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9961</th>\n",
       "      <td>2417782.6</td>\n",
       "      <td>2418267.3</td>\n",
       "      <td>AND</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9962</th>\n",
       "      <td>2419437.7</td>\n",
       "      <td>2420386.3</td>\n",
       "      <td>JUST, YOU KNOW,</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9963</th>\n",
       "      <td>2421273.1</td>\n",
       "      <td>2422947.4</td>\n",
       "      <td>EVERYTHING. I'M EXCITED</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>2423303.1</td>\n",
       "      <td>2424396.2</td>\n",
       "      <td>ABOUT YOUR FUTURE.</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9965</th>\n",
       "      <td>2425081.9</td>\n",
       "      <td>2425860.4</td>\n",
       "      <td>DEFINITELY GONNA</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9966</th>\n",
       "      <td>2429019.6</td>\n",
       "      <td>2429658.9</td>\n",
       "      <td>AND, UM,</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>2433113.3</td>\n",
       "      <td>2434628.8</td>\n",
       "      <td>I'M SIGNING OFF. THIS IS A WRAP.</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         StTime     EnTime                           Content  \\\n",
       "9958  2405803.3  2407020.0       THAT WAS DOPE AS WELL, MAN.   \n",
       "9959  2409658.4  2411158.8                     OH MAN, WELL,   \n",
       "9960  2415648.1  2417452.7           AND THE WORDS OF WISDOM   \n",
       "9961  2417782.6  2418267.3                               AND   \n",
       "9962  2419437.7  2420386.3                   JUST, YOU KNOW,   \n",
       "9963  2421273.1  2422947.4           EVERYTHING. I'M EXCITED   \n",
       "9964  2423303.1  2424396.2                ABOUT YOUR FUTURE.   \n",
       "9965  2425081.9  2425860.4                  DEFINITELY GONNA   \n",
       "9966  2429019.6  2429658.9                          AND, UM,   \n",
       "9967  2433113.3  2434628.8  I'M SIGNING OFF. THIS IS A WRAP.   \n",
       "\n",
       "               Interview  \n",
       "9958  ATL_se0_ag1_m_02_1  \n",
       "9959  ATL_se0_ag1_m_02_1  \n",
       "9960  ATL_se0_ag1_m_02_1  \n",
       "9961  ATL_se0_ag1_m_02_1  \n",
       "9962  ATL_se0_ag1_m_02_1  \n",
       "9963  ATL_se0_ag1_m_02_1  \n",
       "9964  ATL_se0_ag1_m_02_1  \n",
       "9965  ATL_se0_ag1_m_02_1  \n",
       "9966  ATL_se0_ag1_m_02_1  \n",
       "9967  ATL_se0_ag1_m_02_1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the regex pattern for unwanted characters\n",
    "pattern = r'[\\(\\)\\[\\]/<>]'\n",
    "\n",
    "# Filter out rows with unwanted characters in the 'Content' column\n",
    "filtered_transcript_df = combined_transcript_df[~combined_transcript_df['Content'].str.contains(pattern)].reset_index(drop=True)\n",
    "\n",
    "display(filtered_transcript_df.head(10), filtered_transcript_df.tail(10))\n",
    "\n",
    "# import re\n",
    "\n",
    "# # Define the regex pattern for unwanted characters and enclosed content\n",
    "# pattern = r'\\([^)]*\\)|\\[[^\\]]*\\]|<[^>]*>|\\/[^\\/]*\\/'\n",
    "\n",
    "# def remove_enclosed_content(text):\n",
    "#     return re.sub(pattern, '', text)\n",
    "\n",
    "# # Apply the function to remove enclosed content\n",
    "# combined_transcript_df['Content'] = combined_transcript_df['Content'].apply(remove_enclosed_content)\n",
    "\n",
    "# # Optionally, you can filter out rows with empty 'Content' after removal\n",
    "# filtered_transcript_df = combined_transcript_df[combined_transcript_df['Content'].str.strip() != ''].reset_index(drop=True)\n",
    "\n",
    "# display(filtered_transcript_df.head(10), filtered_transcript_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>Interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>1903747.8</td>\n",
       "      <td>1907220.5</td>\n",
       "      <td>YOUR GRIND AND WHAT YOU GET A- OUT OF IT. IT'S...</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1382617.7</td>\n",
       "      <td>1383209.3</td>\n",
       "      <td>FUCKING J-</td>\n",
       "      <td>ATL_se0_ag2_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>1187951.0</td>\n",
       "      <td>1188831.8</td>\n",
       "      <td>MM-MM.</td>\n",
       "      <td>ATL_se0_ag1_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>1839011.7</td>\n",
       "      <td>1840170.1</td>\n",
       "      <td>I DON'T EVEN KNOW, BRO.</td>\n",
       "      <td>ATL_se0_ag2_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9662</th>\n",
       "      <td>1572775.3</td>\n",
       "      <td>1575791.5</td>\n",
       "      <td>FOOTBALL JOCK DOING THE THEATER SHIT, COOL AS ...</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>744470.2</td>\n",
       "      <td>745670.1</td>\n",
       "      <td>SOME RHYME AND SOME DOESN'T?</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>1297661.0</td>\n",
       "      <td>1298302.0</td>\n",
       "      <td>YOU KNOW,</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>1449021.3</td>\n",
       "      <td>1449545.7</td>\n",
       "      <td>BUT, UM,</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3765</th>\n",
       "      <td>1738973.3</td>\n",
       "      <td>1740904.1</td>\n",
       "      <td>SO-CALLED INDIAN HAIR LOOK.</td>\n",
       "      <td>ATL_se0_ag2_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669</th>\n",
       "      <td>531112.7</td>\n",
       "      <td>532345.0</td>\n",
       "      <td>AS OF RIGHT NOW</td>\n",
       "      <td>ATL_se0_ag1_m_04_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>2015279.4</td>\n",
       "      <td>2017281.1</td>\n",
       "      <td>PRODUCER OR SINGER, SONGWRITER,</td>\n",
       "      <td>ATL_se0_ag1_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>1643676.1</td>\n",
       "      <td>1646455.1</td>\n",
       "      <td>AND THEN THE OTHER NIGHT YOU WAS WORKING, AND ...</td>\n",
       "      <td>ATL_se0_ag1_m_05_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7791</th>\n",
       "      <td>920935.0</td>\n",
       "      <td>922952.6</td>\n",
       "      <td>THEY DON'T WANT A BLACK MAN TO EVER BE ABLE TO...</td>\n",
       "      <td>ATL_se0_ag1_m_04_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>1787035.0</td>\n",
       "      <td>1787441.6</td>\n",
       "      <td>OH.</td>\n",
       "      <td>ATL_se0_ag2_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>901275.3</td>\n",
       "      <td>903243.7</td>\n",
       "      <td>I WOULD GET TO SEE LIKE, WHY</td>\n",
       "      <td>ATL_se0_ag2_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>635227.2</td>\n",
       "      <td>638001.8</td>\n",
       "      <td>YOU KNOW, THE WAY GOD CREATED IT, BUT AT THE S...</td>\n",
       "      <td>ATL_se0_ag2_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>1386982.7</td>\n",
       "      <td>1389220.3</td>\n",
       "      <td>LIKE SEASON OF WHAT? THE AQUARIUS OR SOME SHIT...</td>\n",
       "      <td>ATL_se0_ag2_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>1903690.6</td>\n",
       "      <td>1904396.0</td>\n",
       "      <td>APPRECIATE IT.</td>\n",
       "      <td>ATL_se0_ag2_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>2790160.2</td>\n",
       "      <td>2796026.2</td>\n",
       "      <td>YEAH, YOU GOTTA FUCK WITH THE DJ. YOU FUCK WIT...</td>\n",
       "      <td>ATL_se0_ag2_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>995688.6</td>\n",
       "      <td>996471.6</td>\n",
       "      <td>OKAY. IT'S-</td>\n",
       "      <td>ATL_se0_ag1_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5774</th>\n",
       "      <td>1072958.6</td>\n",
       "      <td>1073609.9</td>\n",
       "      <td>HM-</td>\n",
       "      <td>ATL_se0_ag1_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8791</th>\n",
       "      <td>1397016.1</td>\n",
       "      <td>1397416.0</td>\n",
       "      <td>OKAY.</td>\n",
       "      <td>ATL_se0_ag1_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>846551.6</td>\n",
       "      <td>848128.7</td>\n",
       "      <td>BUT IT WAS IN THEATERS RIGHT N-</td>\n",
       "      <td>ATL_se0_ag2_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>1594267.7</td>\n",
       "      <td>1595197.5</td>\n",
       "      <td>FROM A GREAT</td>\n",
       "      <td>ATL_se0_ag2_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4369</th>\n",
       "      <td>1398762.7</td>\n",
       "      <td>1402376.9</td>\n",
       "      <td>THAN CERTAIN THINGS. IT'S NOT THAT THERE'S OTH...</td>\n",
       "      <td>ATL_se0_ag1_m_05_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>2212655.7</td>\n",
       "      <td>2214092.5</td>\n",
       "      <td>NAH, THAT WE DON'T GOT LIKE</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>265250.3</td>\n",
       "      <td>265805.4</td>\n",
       "      <td>UM,</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>714032.6</td>\n",
       "      <td>715311.2</td>\n",
       "      <td>THAT NIGGA W- UH,</td>\n",
       "      <td>ATL_se0_ag2_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>858635.5</td>\n",
       "      <td>860186.1</td>\n",
       "      <td>SOME LIGHTS I DON'T LIKE, BUT</td>\n",
       "      <td>ATL_se0_ag2_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6209</th>\n",
       "      <td>705305.0</td>\n",
       "      <td>705875.7</td>\n",
       "      <td>OKAY.</td>\n",
       "      <td>ATL_se0_ag1_f_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>2176567.0</td>\n",
       "      <td>2177838.6</td>\n",
       "      <td>OH, THEY NOT PLAYING.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>959007.5</td>\n",
       "      <td>960761.0</td>\n",
       "      <td>SEE ONE OF TWO THINGS CAN HAPPEN.</td>\n",
       "      <td>ATL_se0_ag2_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>1381175.1</td>\n",
       "      <td>1381948.5</td>\n",
       "      <td>SPACE?</td>\n",
       "      <td>ATL_se0_ag1_m_05_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3025</th>\n",
       "      <td>1996094.3</td>\n",
       "      <td>1998210.2</td>\n",
       "      <td>WHY THE FUCK Y'ALL CALL THE NATIONAL GUARD FIRST?</td>\n",
       "      <td>ATL_se0_ag2_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>431383.8</td>\n",
       "      <td>435488.0</td>\n",
       "      <td>I DON'T KNOW, CONNECT ON THAT PART, AND SHE'S ...</td>\n",
       "      <td>ATL_se0_ag2_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>2868035.8</td>\n",
       "      <td>2868882.8</td>\n",
       "      <td>YOUTUBE ME</td>\n",
       "      <td>ATL_se0_ag2_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862</th>\n",
       "      <td>1117258.8</td>\n",
       "      <td>1117684.5</td>\n",
       "      <td>OUT THE M-</td>\n",
       "      <td>ATL_se0_ag2_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>169437.1</td>\n",
       "      <td>172857.6</td>\n",
       "      <td>THAT WASN'T GIVEN TO YOU BY MISTAKE. THAT WAS ...</td>\n",
       "      <td>ATL_se0_ag2_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7676</th>\n",
       "      <td>547478.3</td>\n",
       "      <td>549231.3</td>\n",
       "      <td>NEED TO BE, I GUESS</td>\n",
       "      <td>ATL_se0_ag1_m_04_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>1573293.7</td>\n",
       "      <td>1573793.1</td>\n",
       "      <td>BUT,</td>\n",
       "      <td>ATL_se0_ag1_m_05_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>1425919.4</td>\n",
       "      <td>1427735.7</td>\n",
       "      <td>IN AS FAR AS AMERICA TERMS CAUSE-</td>\n",
       "      <td>ATL_se0_ag2_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5807</th>\n",
       "      <td>1267910.4</td>\n",
       "      <td>1268456.3</td>\n",
       "      <td>MAN.</td>\n",
       "      <td>ATL_se0_ag1_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9676</th>\n",
       "      <td>1612226.3</td>\n",
       "      <td>1613821.5</td>\n",
       "      <td>AUTOMATICALLY AIN'T GONNA UNDERSTAND ME</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>1288618.2</td>\n",
       "      <td>1293495.2</td>\n",
       "      <td>DEPENDS ON- IT'S GONNA SOUND REALLY WEIRD, AND...</td>\n",
       "      <td>ATL_se0_ag2_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6916</th>\n",
       "      <td>977589.4</td>\n",
       "      <td>979430.0</td>\n",
       "      <td>I WENT TO TWO SCHOOLS MY FRESHMAN YEAR.</td>\n",
       "      <td>ATL_se0_ag1_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9603</th>\n",
       "      <td>1413302.4</td>\n",
       "      <td>1417390.3</td>\n",
       "      <td>IT'S POLITICS DEFINITELY IN A LOT OF THAT SCHO...</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>2171115.3</td>\n",
       "      <td>2174609.7</td>\n",
       "      <td>FROM THE CONSEQUENCES OF BEING OPENLY GAY IN T...</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7522</th>\n",
       "      <td>89186.1</td>\n",
       "      <td>90315.3</td>\n",
       "      <td>THOROUGHLY I WOULD SAY,</td>\n",
       "      <td>ATL_se0_ag1_m_04_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9706</th>\n",
       "      <td>1713821.7</td>\n",
       "      <td>1716482.1</td>\n",
       "      <td>SUBCONSCIOUSLY KIND OF FORCING HIM INTO THIS P...</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5869</th>\n",
       "      <td>1478495.6</td>\n",
       "      <td>1478799.5</td>\n",
       "      <td>RIGHT.</td>\n",
       "      <td>ATL_se0_ag1_f_01_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         StTime     EnTime                                            Content  \\\n",
       "645   1903747.8  1907220.5  YOUR GRIND AND WHAT YOU GET A- OUT OF IT. IT'S...   \n",
       "1438  1382617.7  1383209.3                                         FUCKING J-   \n",
       "5791  1187951.0  1188831.8                                             MM-MM.   \n",
       "3012  1839011.7  1840170.1                            I DON'T EVEN KNOW, BRO.   \n",
       "9662  1572775.3  1575791.5  FOOTBALL JOCK DOING THE THEATER SHIT, COOL AS ...   \n",
       "9357   744470.2   745670.1                       SOME RHYME AND SOME DOESN'T?   \n",
       "9564  1297661.0  1298302.0                                          YOU KNOW,   \n",
       "529   1449021.3  1449545.7                                           BUT, UM,   \n",
       "3765  1738973.3  1740904.1                        SO-CALLED INDIAN HAIR LOOK.   \n",
       "7669   531112.7   532345.0                                    AS OF RIGHT NOW   \n",
       "5249  2015279.4  2017281.1                    PRODUCER OR SINGER, SONGWRITER,   \n",
       "4450  1643676.1  1646455.1  AND THEN THE OTHER NIGHT YOU WAS WORKING, AND ...   \n",
       "7791   920935.0   922952.6  THEY DON'T WANT A BLACK MAN TO EVER BE ABLE TO...   \n",
       "2402  1787035.0  1787441.6                                                OH.   \n",
       "2113   901275.3   903243.7                       I WOULD GET TO SEE LIKE, WHY   \n",
       "2016   635227.2   638001.8  YOU KNOW, THE WAY GOD CREATED IT, BUT AT THE S...   \n",
       "2909  1386982.7  1389220.3  LIKE SEASON OF WHAT? THE AQUARIUS OR SOME SHIT...   \n",
       "1610  1903690.6  1904396.0                                     APPRECIATE IT.   \n",
       "3197  2790160.2  2796026.2  YEAH, YOU GOTTA FUCK WITH THE DJ. YOU FUCK WIT...   \n",
       "4962   995688.6   996471.6                                        OKAY. IT'S-   \n",
       "5774  1072958.6  1073609.9                                                HM-   \n",
       "8791  1397016.1  1397416.0                                              OKAY.   \n",
       "3489   846551.6   848128.7                    BUT IT WAS IN THEATERS RIGHT N-   \n",
       "3737  1594267.7  1595197.5                                       FROM A GREAT   \n",
       "4369  1398762.7  1402376.9  THAN CERTAIN THINGS. IT'S NOT THAT THERE'S OTH...   \n",
       "767   2212655.7  2214092.5                        NAH, THAT WE DON'T GOT LIKE   \n",
       "122    265250.3   265805.4                                                UM,   \n",
       "2782   714032.6   715311.2                                  THAT NIGGA W- UH,   \n",
       "2097   858635.5   860186.1                      SOME LIGHTS I DON'T LIKE, BUT   \n",
       "6209   705305.0   705875.7                                              OKAY.   \n",
       "752   2176567.0  2177838.6                              OH, THEY NOT PLAYING.   \n",
       "3526   959007.5   960761.0                  SEE ONE OF TWO THINGS CAN HAPPEN.   \n",
       "4363  1381175.1  1381948.5                                             SPACE?   \n",
       "3025  1996094.3  1998210.2  WHY THE FUCK Y'ALL CALL THE NATIONAL GUARD FIRST?   \n",
       "1950   431383.8   435488.0  I DON'T KNOW, CONNECT ON THAT PART, AND SHE'S ...   \n",
       "3210  2868035.8  2868882.8                                         YOUTUBE ME   \n",
       "2862  1117258.8  1117684.5                                         OUT THE M-   \n",
       "3286   169437.1   172857.6  THAT WASN'T GIVEN TO YOU BY MISTAKE. THAT WAS ...   \n",
       "7676   547478.3   549231.3                                NEED TO BE, I GUESS   \n",
       "4429  1573293.7  1573793.1                                               BUT,   \n",
       "2918  1425919.4  1427735.7                  IN AS FAR AS AMERICA TERMS CAUSE-   \n",
       "5807  1267910.4  1268456.3                                               MAN.   \n",
       "9676  1612226.3  1613821.5            AUTOMATICALLY AIN'T GONNA UNDERSTAND ME   \n",
       "1402  1288618.2  1293495.2  DEPENDS ON- IT'S GONNA SOUND REALLY WEIRD, AND...   \n",
       "6916   977589.4   979430.0            I WENT TO TWO SCHOOLS MY FRESHMAN YEAR.   \n",
       "9603  1413302.4  1417390.3  IT'S POLITICS DEFINITELY IN A LOT OF THAT SCHO...   \n",
       "750   2171115.3  2174609.7  FROM THE CONSEQUENCES OF BEING OPENLY GAY IN T...   \n",
       "7522    89186.1    90315.3                            THOROUGHLY I WOULD SAY,   \n",
       "9706  1713821.7  1716482.1  SUBCONSCIOUSLY KIND OF FORCING HIM INTO THIS P...   \n",
       "5869  1478495.6  1478799.5                                             RIGHT.   \n",
       "\n",
       "               Interview  \n",
       "645   ATL_se0_ag2_f_02_1  \n",
       "1438  ATL_se0_ag2_m_02_1  \n",
       "5791  ATL_se0_ag1_f_01_1  \n",
       "3012  ATL_se0_ag2_m_03_1  \n",
       "9662  ATL_se0_ag1_m_02_1  \n",
       "9357  ATL_se0_ag1_m_02_1  \n",
       "9564  ATL_se0_ag1_m_02_1  \n",
       "529   ATL_se0_ag2_f_02_1  \n",
       "3765  ATL_se0_ag2_m_01_1  \n",
       "7669  ATL_se0_ag1_m_04_2  \n",
       "5249  ATL_se0_ag1_m_03_1  \n",
       "4450  ATL_se0_ag1_m_05_1  \n",
       "7791  ATL_se0_ag1_m_04_2  \n",
       "2402  ATL_se0_ag2_f_01_1  \n",
       "2113  ATL_se0_ag2_f_01_1  \n",
       "2016  ATL_se0_ag2_f_01_1  \n",
       "2909  ATL_se0_ag2_m_03_1  \n",
       "1610  ATL_se0_ag2_m_02_1  \n",
       "3197  ATL_se0_ag2_m_03_1  \n",
       "4962  ATL_se0_ag1_m_03_1  \n",
       "5774  ATL_se0_ag1_f_01_1  \n",
       "8791  ATL_se0_ag1_f_02_1  \n",
       "3489  ATL_se0_ag2_m_01_1  \n",
       "3737  ATL_se0_ag2_m_01_1  \n",
       "4369  ATL_se0_ag1_m_05_1  \n",
       "767   ATL_se0_ag2_f_02_1  \n",
       "122   ATL_se0_ag2_f_02_1  \n",
       "2782  ATL_se0_ag2_m_03_1  \n",
       "2097  ATL_se0_ag2_f_01_1  \n",
       "6209  ATL_se0_ag1_f_03_1  \n",
       "752   ATL_se0_ag2_f_02_1  \n",
       "3526  ATL_se0_ag2_m_01_1  \n",
       "4363  ATL_se0_ag1_m_05_1  \n",
       "3025  ATL_se0_ag2_m_03_1  \n",
       "1950  ATL_se0_ag2_f_01_1  \n",
       "3210  ATL_se0_ag2_m_03_1  \n",
       "2862  ATL_se0_ag2_m_03_1  \n",
       "3286  ATL_se0_ag2_m_01_1  \n",
       "7676  ATL_se0_ag1_m_04_2  \n",
       "4429  ATL_se0_ag1_m_05_1  \n",
       "2918  ATL_se0_ag2_m_03_1  \n",
       "5807  ATL_se0_ag1_f_01_1  \n",
       "9676  ATL_se0_ag1_m_02_1  \n",
       "1402  ATL_se0_ag2_m_02_1  \n",
       "6916  ATL_se0_ag1_m_01_1  \n",
       "9603  ATL_se0_ag1_m_02_1  \n",
       "750   ATL_se0_ag2_f_02_1  \n",
       "7522  ATL_se0_ag1_m_04_2  \n",
       "9706  ATL_se0_ag1_m_02_1  \n",
       "5869  ATL_se0_ag1_f_01_1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset = filtered_transcript_df.sample(50)\n",
    "data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_segment(audio_file_path, start_time_ms, end_time_ms, target_sample_rate=16000, segment_length_ms=30000):\n",
    "    \"\"\"\n",
    "    Extracts a segment from an audio file based on start and end times and resamples it to a target sample rate.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_file_path (str): Path to the audio file.\n",
    "    - start_time_ms (int): Start time in milliseconds.\n",
    "    - end_time_ms (int): End time in milliseconds.\n",
    "    - target_sample_rate (int): The target sample rate for the audio segment.\n",
    "    - segment_length_ms (int): The desired length of the audio segment in milliseconds.\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: Extracted and resampled audio segment.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    waveform, sr = torchaudio.load(audio_file_path)\n",
    "    \n",
    "    # Resample if the sample rate is not the target sample rate\n",
    "    if sr != target_sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "        sr = target_sample_rate\n",
    "    \n",
    "    # Convert milliseconds to sample indices\n",
    "    start_sample = int(start_time_ms * sr / 1000)\n",
    "    end_sample = int(end_time_ms * sr / 1000)\n",
    "    \n",
    "    # Extract the segment\n",
    "    segment = waveform[:, start_sample:end_sample]\n",
    "    \n",
    "    # # Ensure the segment is of the desired length\n",
    "    # target_length_samples = int(segment_length_ms * sr / 1000)\n",
    "    # if segment.size(1) < target_length_samples:\n",
    "    #     # Pad the segment if it's shorter than the target length\n",
    "    #     padding = target_length_samples - segment.size(1)\n",
    "    #     segment = torch.nn.functional.pad(segment, (0, padding))\n",
    "    # else:\n",
    "    #     # Trim the segment if it's longer than the target length\n",
    "    #     segment = segment[:, :target_length_samples]\n",
    "    \n",
    "    return segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Interview</th>\n",
       "      <th>Content</th>\n",
       "      <th>Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1903747.8</td>\n",
       "      <td>1907220.5</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "      <td>YOUR GRIND AND WHAT YOU GET A- OUT OF IT. IT'S...</td>\n",
       "      <td>[[tensor(-0.0038), tensor(-0.0038), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1382617.7</td>\n",
       "      <td>1383209.3</td>\n",
       "      <td>ATL_se0_ag2_m_02_1</td>\n",
       "      <td>FUCKING J-</td>\n",
       "      <td>[[tensor(-0.0011), tensor(-0.0019), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1187951.0</td>\n",
       "      <td>1188831.8</td>\n",
       "      <td>ATL_se0_ag1_f_01_1</td>\n",
       "      <td>MM-MM.</td>\n",
       "      <td>[[tensor(-0.0001), tensor(0.0002), tensor(0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1839011.7</td>\n",
       "      <td>1840170.1</td>\n",
       "      <td>ATL_se0_ag2_m_03_1</td>\n",
       "      <td>I DON'T EVEN KNOW, BRO.</td>\n",
       "      <td>[[tensor(0.0005), tensor(0.0005), tensor(0.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1572775.3</td>\n",
       "      <td>1575791.5</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "      <td>FOOTBALL JOCK DOING THE THEATER SHIT, COOL AS ...</td>\n",
       "      <td>[[tensor(-0.0004), tensor(-1.3209e-06), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>744470.2</td>\n",
       "      <td>745670.1</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "      <td>SOME RHYME AND SOME DOESN'T?</td>\n",
       "      <td>[[tensor(6.8611e-05), tensor(-0.0001), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1297661.0</td>\n",
       "      <td>1298302.0</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "      <td>YOU KNOW,</td>\n",
       "      <td>[[tensor(-0.0005), tensor(-0.0004), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1449021.3</td>\n",
       "      <td>1449545.7</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "      <td>BUT, UM,</td>\n",
       "      <td>[[tensor(-0.0005), tensor(-0.0005), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1738973.3</td>\n",
       "      <td>1740904.1</td>\n",
       "      <td>ATL_se0_ag2_m_01_1</td>\n",
       "      <td>SO-CALLED INDIAN HAIR LOOK.</td>\n",
       "      <td>[[tensor(0.0006), tensor(0.0005), tensor(0.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>531112.7</td>\n",
       "      <td>532345.0</td>\n",
       "      <td>ATL_se0_ag1_m_04_2</td>\n",
       "      <td>AS OF RIGHT NOW</td>\n",
       "      <td>[[tensor(-0.0007), tensor(-0.0009), tensor(-0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      StTime     EnTime           Interview  \\\n",
       "0  1903747.8  1907220.5  ATL_se0_ag2_f_02_1   \n",
       "1  1382617.7  1383209.3  ATL_se0_ag2_m_02_1   \n",
       "2  1187951.0  1188831.8  ATL_se0_ag1_f_01_1   \n",
       "3  1839011.7  1840170.1  ATL_se0_ag2_m_03_1   \n",
       "4  1572775.3  1575791.5  ATL_se0_ag1_m_02_1   \n",
       "5   744470.2   745670.1  ATL_se0_ag1_m_02_1   \n",
       "6  1297661.0  1298302.0  ATL_se0_ag1_m_02_1   \n",
       "7  1449021.3  1449545.7  ATL_se0_ag2_f_02_1   \n",
       "8  1738973.3  1740904.1  ATL_se0_ag2_m_01_1   \n",
       "9   531112.7   532345.0  ATL_se0_ag1_m_04_2   \n",
       "\n",
       "                                             Content  \\\n",
       "0  YOUR GRIND AND WHAT YOU GET A- OUT OF IT. IT'S...   \n",
       "1                                         FUCKING J-   \n",
       "2                                             MM-MM.   \n",
       "3                            I DON'T EVEN KNOW, BRO.   \n",
       "4  FOOTBALL JOCK DOING THE THEATER SHIT, COOL AS ...   \n",
       "5                       SOME RHYME AND SOME DOESN'T?   \n",
       "6                                          YOU KNOW,   \n",
       "7                                           BUT, UM,   \n",
       "8                        SO-CALLED INDIAN HAIR LOOK.   \n",
       "9                                    AS OF RIGHT NOW   \n",
       "\n",
       "                                             Segment  \n",
       "0  [[tensor(-0.0038), tensor(-0.0038), tensor(-0....  \n",
       "1  [[tensor(-0.0011), tensor(-0.0019), tensor(-0....  \n",
       "2  [[tensor(-0.0001), tensor(0.0002), tensor(0.00...  \n",
       "3  [[tensor(0.0005), tensor(0.0005), tensor(0.000...  \n",
       "4  [[tensor(-0.0004), tensor(-1.3209e-06), tensor...  \n",
       "5  [[tensor(6.8611e-05), tensor(-0.0001), tensor(...  \n",
       "6  [[tensor(-0.0005), tensor(-0.0004), tensor(-0....  \n",
       "7  [[tensor(-0.0005), tensor(-0.0005), tensor(-0....  \n",
       "8  [[tensor(0.0006), tensor(0.0005), tensor(0.000...  \n",
       "9  [[tensor(-0.0007), tensor(-0.0009), tensor(-0....  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a list to store extracted audio segments\n",
    "audio_segments = []\n",
    "\n",
    "for idx, row in data_subset.iterrows():\n",
    "    start_tm = row['StTime']\n",
    "    end_tm = row['EnTime']\n",
    "    content = row['Content']\n",
    "    interview = row['Interview']\n",
    "\n",
    "    transcript_path = transcript_dir+interview+\".txt\"\n",
    "    audio_path = audio_dir+interview+\".wav\"\n",
    "\n",
    "    segment = extract_audio_segment(audio_path, start_tm, end_tm)\n",
    "    \n",
    "    # Optionally, save the segment or process it further\n",
    "    audio_segments.append({\n",
    "        'StTime': start_tm,\n",
    "        'EnTime': end_tm,\n",
    "        'Interview': interview,\n",
    "        'Content': content,\n",
    "        'Segment': segment\n",
    "    })\n",
    "\n",
    "audio_segments_subset_df = pd.DataFrame(audio_segments)\n",
    "audio_segments_subset_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 55564])\n",
      "torch.Size([1, 9465])\n",
      "torch.Size([1, 14092])\n",
      "torch.Size([1, 18534])\n",
      "torch.Size([1, 48260])\n",
      "torch.Size([1, 19198])\n",
      "torch.Size([1, 10256])\n",
      "torch.Size([1, 8391])\n",
      "torch.Size([1, 30893])\n",
      "torch.Size([1, 19717])\n"
     ]
    }
   ],
   "source": [
    "for idx, row in audio_segments_subset_df.iterrows():\n",
    "    if idx == 10:\n",
    "        break\n",
    "    print(row['Segment'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Initialize processor and model for whisper-tiny\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to the appropriate device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(audio_tensor, sample_rate, target_sample_rate=16000):\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "        audio_tensor = resampler(audio_tensor)\n",
    "    return audio_tensor\n",
    "\n",
    "def transcribe_audio(audio_tensor, model, processor):\n",
    "    audio_tensor = audio_tensor.to(device)\n",
    "    inputs = processor(audio_tensor.squeeze().cpu().numpy(), return_tensors=\"pt\", sampling_rate=16000)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(**inputs)\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    return transcription[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment Start: 1903747.8\n",
      "Actual Transcript: YOUR GRIND AND WHAT YOU GET A- OUT OF IT. IT'S JUST WHAT IT IS, RIGHT?\n",
      "Model Transcription:  ВОН, ВЫ ЖЕ НЕ БУДЕМ.\n",
      "\n",
      "\n",
      "Segment Start: 1382617.7\n",
      "Actual Transcript: FUCKING J-\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 1187951.0\n",
      "Actual Transcript: MM-MM.\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 1839011.7\n",
      "Actual Transcript: I DON'T EVEN KNOW, BRO.\n",
      "Model Transcription:  YEAH.\n",
      "\n",
      "\n",
      "Segment Start: 1572775.3\n",
      "Actual Transcript: FOOTBALL JOCK DOING THE THEATER SHIT, COOL AS SHIT.\n",
      "Model Transcription:  THANK YOU.\n",
      "\n",
      "\n",
      "Segment Start: 744470.2\n",
      "Actual Transcript: SOME RHYME AND SOME DOESN'T?\n",
      "Model Transcription:  BYE.\n",
      "\n",
      "\n",
      "Segment Start: 1297661.0\n",
      "Actual Transcript: YOU KNOW,\n",
      "Model Transcription:  I'M SORRY.\n",
      "\n",
      "\n",
      "Segment Start: 1449021.3\n",
      "Actual Transcript: BUT, UM,\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 1738973.3\n",
      "Actual Transcript: SO-CALLED INDIAN HAIR LOOK.\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 531112.7000000001\n",
      "Actual Transcript: AS OF RIGHT NOW\n",
      "Model Transcription:  THEY WERE THERE.\n",
      "\n",
      "\n",
      "Segment Start: 2015279.4\n",
      "Actual Transcript: PRODUCER OR SINGER, SONGWRITER,\n",
      "Model Transcription:  THANK YOU.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists for metrics\n",
    "true_transcriptions = []\n",
    "predicted_transcriptions = []\n",
    "\n",
    "sample_rate = 44100\n",
    "\n",
    "# Process each segment and compare transcriptions\n",
    "for idx in range(len(audio_segments_subset_df)):\n",
    "    audio_tensor = audio_segments_subset_df['Segment'][idx]\n",
    "    actual_transcript = audio_segments_subset_df['Content'][idx]\n",
    "    \n",
    "    # Ensure audio is in the correct format\n",
    "    audio_tensor = preprocess_audio(audio_tensor, sample_rate)\n",
    "    \n",
    "    # Transcribe audio\n",
    "    model_transcription = transcribe_audio(audio_tensor, model, processor)\n",
    "    model_transcription = model_transcription.upper()\n",
    "    \n",
    "    # Store transcriptions for metric calculation\n",
    "    true_transcriptions.append(actual_transcript)\n",
    "    predicted_transcriptions.append(model_transcription)\n",
    "    \n",
    "    # Print segment info\n",
    "    print(f\"Segment Start: {audio_segments_subset_df['StTime'][idx]}\")\n",
    "    print(f\"Actual Transcript: {actual_transcript}\")\n",
    "    print(f\"Model Transcription: {model_transcription}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate (WER): 2.3282208588957056\n"
     ]
    }
   ],
   "source": [
    "wer_score = wer(true_transcriptions, predicted_transcriptions)\n",
    "print(f\"Word Error Rate (WER): {wer_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training `whisper-tiny` on CORAAL:ATL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, WhisperConfig\n",
    "from jiwer import wer\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "transcript_dir = '../data/coraal/transcript/text/'\n",
    "audio_dir = '../data/coraal/audio/wav/'\n",
    "\n",
    "paths_df = create_file_mapping(transcript_dir, audio_dir)\n",
    "combined_transcript_df = process_transcripts(paths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with unwanted characters in the 'Content' column\n",
    "pattern = r'[\\(\\)\\[\\]/<>]'\n",
    "filtered_transcript_df = combined_transcript_df[~combined_transcript_df['Content'].str.contains(pattern)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# subset_size = int(len(filtered_transcript_df)*.20)\n",
    "# data_subset = filtered_transcript_df.sample(subset_size)\n",
    "data_subset = filtered_transcript_df.sample(100)\n",
    "print(len(data_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>Interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9531</th>\n",
       "      <td>1164719.5</td>\n",
       "      <td>1165790.6</td>\n",
       "      <td>I LOVE GOOD MUSIC.</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5617</th>\n",
       "      <td>434093.0</td>\n",
       "      <td>434514.8</td>\n",
       "      <td>MM-HM.</td>\n",
       "      <td>ATL_se0_ag1_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6650</th>\n",
       "      <td>125283.1</td>\n",
       "      <td>125905.6</td>\n",
       "      <td>UH,</td>\n",
       "      <td>ATL_se0_ag1_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>2621873.9</td>\n",
       "      <td>2623842.1</td>\n",
       "      <td>THAT'S STILL LIT THOUGH TO GET, UM,</td>\n",
       "      <td>ATL_se0_ag2_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6157</th>\n",
       "      <td>552074.8</td>\n",
       "      <td>555554.6</td>\n",
       "      <td>YOU WAS TREATED DIFFERENTLY BECAUSE YOU WAS TH...</td>\n",
       "      <td>ATL_se0_ag1_f_03_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         StTime     EnTime                                            Content  \\\n",
       "9531  1164719.5  1165790.6                                 I LOVE GOOD MUSIC.   \n",
       "5617   434093.0   434514.8                                             MM-HM.   \n",
       "6650   125283.1   125905.6                                                UH,   \n",
       "3173  2621873.9  2623842.1                THAT'S STILL LIT THOUGH TO GET, UM,   \n",
       "6157   552074.8   555554.6  YOU WAS TREATED DIFFERENTLY BECAUSE YOU WAS TH...   \n",
       "\n",
       "               Interview  \n",
       "9531  ATL_se0_ag1_m_02_1  \n",
       "5617  ATL_se0_ag1_f_01_1  \n",
       "6650  ATL_se0_ag1_m_01_1  \n",
       "3173  ATL_se0_ag2_m_03_1  \n",
       "6157  ATL_se0_ag1_f_03_1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(data_subset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, df, transcript_dir, audio_dir, processor):\n",
    "        self.df = df\n",
    "        self.transcript_dir = transcript_dir\n",
    "        self.audio_dir = audio_dir\n",
    "        self.processor = processor\n",
    "        self.target_sample_rate = 16000\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        start_tm = row['StTime']\n",
    "        end_tm = row['EnTime']\n",
    "        content = row['Content']\n",
    "        interview = row['Interview']\n",
    "        audio_path = os.path.join(self.audio_dir, interview + '.wav')\n",
    "        \n",
    "        # Extract audio segment\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        start_sample = int(start_tm * sr / 1000)\n",
    "        end_sample = int(end_tm * sr / 1000)\n",
    "        audio_segment = waveform[:, start_sample:end_sample]\n",
    "        \n",
    "        # Resample audio to target sample rate\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.target_sample_rate)\n",
    "            audio_segment = resampler(audio_segment)\n",
    "        \n",
    "        # Preprocess audio segment\n",
    "        audio_tensor = self.processor(audio_segment.squeeze().numpy(), sampling_rate=self.target_sample_rate, return_tensors=\"pt\").input_features\n",
    "        \n",
    "        return {\n",
    "            'input_features': audio_tensor.squeeze(),\n",
    "            'labels': self.processor.tokenizer(content, return_tensors=\"pt\").input_ids.squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Initialize processor and model\n",
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "config = WhisperConfig.from_pretrained(\"openai/whisper-tiny\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = AudioDataset(train_df, transcript_dir, audio_dir, processor)\n",
    "test_dataset = AudioDataset(test_df, transcript_dir, audio_dir, processor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_loader, processor, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    true_transcriptions = []\n",
    "    predicted_transcriptions = []\n",
    "    \n",
    "    for batch in tqdm(train_loader, total=len(train_loader), desc='Training'):\n",
    "        inputs = batch['input_features'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_features=inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        outputs = model.generate(input_features=inputs)\n",
    "        transcriptions = processor.batch_decode(outputs, skip_special_tokens=True)\n",
    "        true_transcriptions.extend(processor.batch_decode(labels, skip_special_tokens=True))\n",
    "        predicted_transcriptions.extend(transcriptions)\n",
    "\n",
    "        predicted_transcriptions = [x.upper() for x in predicted_transcriptions]\n",
    "        wer_score = wer(true_transcriptions, predicted_transcriptions)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    total_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    return total_loss, wer_score\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, test_loader, processor, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    true_transcriptions = []\n",
    "    predicted_transcriptions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # for batch in tqdm(test_loader, total=len(test_loader), desc='Testing'):\n",
    "        for batch in test_loader:\n",
    "            inputs = batch['input_features'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_features=inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            outputs = model.generate(input_features=inputs)\n",
    "            transcriptions = processor.batch_decode(outputs, skip_special_tokens=True)\n",
    "            true_transcriptions.extend(processor.batch_decode(labels, skip_special_tokens=True))\n",
    "            predicted_transcriptions.extend(transcriptions)\n",
    "\n",
    "    total_loss = total_loss / len(train_loader)\n",
    "    predicted_transcriptions = [x.upper() for x in predicted_transcriptions]\n",
    "    wer_score = wer(true_transcriptions, predicted_transcriptions)\n",
    "    \n",
    "    return total_loss, wer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [01:36<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.4433, WER: 0.5142\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [01:49<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.2080, WER: 0.4953\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [01:41<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.2080, WER: 0.4953\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 64/80 [01:28<00:23,  1.45s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Fine-tuning\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    train_loss, train_wer = train(model, train_loader, processor, optimizer, scheduler, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}, WER: {train_wer:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7490, WER: 0.4286\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_wer = evaluate(model, test_loader, processor, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, WER: {test_wer:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_test = []\n",
    "for k in range(10):\n",
    "    test_loss, test_wer = evaluate(model, test_loader, processor, device)\n",
    "    k_test.append([k, test_loss, test_wer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_test_df = pd.DataFrame(k_test, columns=['k', 'Loss', 'Word Error Rate']).sort_values(by=\"Word Error Rate\", ascending=False).groupby('k')[:5]\n",
    "k_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-to-text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
