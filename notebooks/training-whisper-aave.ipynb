{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, WhisperConfig\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS is available\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_mapping(transcript_dir, audio_dir):\n",
    "    # Create lists of transcript and audio file paths\n",
    "    transcript_paths = [os.path.join(transcript_dir, filename) for filename in os.listdir(transcript_dir) if filename.endswith('.txt')]\n",
    "    audio_paths = [os.path.join(audio_dir, filename) for filename in os.listdir(audio_dir) if filename.endswith('.wav')]\n",
    "\n",
    "    # Extract identifiers from filenames\n",
    "    transcript_ids = [os.path.splitext(os.path.basename(path))[0] for path in transcript_paths]\n",
    "    audio_ids = [os.path.splitext(os.path.basename(path))[0] for path in audio_paths]\n",
    "\n",
    "    # Create a dictionary to map identifiers to file paths\n",
    "    file_mapping = {\n",
    "        'Interview': [],\n",
    "        'Transcript Path': [],\n",
    "        'Audio Path': []\n",
    "    }\n",
    "\n",
    "    # Match transcript files with audio files using their identifiers\n",
    "    for transcript_id in transcript_ids:\n",
    "        if transcript_id in audio_ids:\n",
    "            transcript_path = os.path.join(transcript_dir, transcript_id + '.txt')\n",
    "            audio_path = os.path.join(audio_dir, transcript_id + '.wav')\n",
    "            file_mapping['Interview'].append(transcript_id)\n",
    "            file_mapping['Transcript Path'].append(transcript_path)\n",
    "            file_mapping['Audio Path'].append(audio_path)\n",
    "\n",
    "    # Create DataFrame from the file mapping dictionary\n",
    "    df = pd.DataFrame(file_mapping)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interview</th>\n",
       "      <th>Transcript Path</th>\n",
       "      <th>Audio Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag2_f_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag2_f_02_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL_se0_ag2_m_02_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag2_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag2_m_02_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL_se0_ag2_f_01_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag2_f_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag2_f_01_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL_se0_ag2_m_03_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag2_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag2_m_03_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL_se0_ag2_m_01_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag2_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag2_m_01_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ATL_se0_ag1_m_05_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_m_05_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ATL_se0_ag1_m_03_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_m_03_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ATL_se0_ag1_f_01_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_f_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_f_01_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ATL_se0_ag1_f_03_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_f_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_f_03_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ATL_se0_ag1_m_01_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_m_01_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ATL_se0_ag1_m_04_2</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_m_04_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ATL_se0_ag1_m_04_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_m_04_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ATL_se0_ag1_f_02_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_f_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_f_02_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "      <td>../data/coraal/transcript/text/ATL_se0_ag1_m_0...</td>\n",
       "      <td>../data/coraal/audio/wav/ATL_se0_ag1_m_02_1.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Interview                                    Transcript Path  \\\n",
       "0   ATL_se0_ag2_f_02_1  ../data/coraal/transcript/text/ATL_se0_ag2_f_0...   \n",
       "1   ATL_se0_ag2_m_02_1  ../data/coraal/transcript/text/ATL_se0_ag2_m_0...   \n",
       "2   ATL_se0_ag2_f_01_1  ../data/coraal/transcript/text/ATL_se0_ag2_f_0...   \n",
       "3   ATL_se0_ag2_m_03_1  ../data/coraal/transcript/text/ATL_se0_ag2_m_0...   \n",
       "4   ATL_se0_ag2_m_01_1  ../data/coraal/transcript/text/ATL_se0_ag2_m_0...   \n",
       "5   ATL_se0_ag1_m_05_1  ../data/coraal/transcript/text/ATL_se0_ag1_m_0...   \n",
       "6   ATL_se0_ag1_m_03_1  ../data/coraal/transcript/text/ATL_se0_ag1_m_0...   \n",
       "7   ATL_se0_ag1_f_01_1  ../data/coraal/transcript/text/ATL_se0_ag1_f_0...   \n",
       "8   ATL_se0_ag1_f_03_1  ../data/coraal/transcript/text/ATL_se0_ag1_f_0...   \n",
       "9   ATL_se0_ag1_m_01_1  ../data/coraal/transcript/text/ATL_se0_ag1_m_0...   \n",
       "10  ATL_se0_ag1_m_04_2  ../data/coraal/transcript/text/ATL_se0_ag1_m_0...   \n",
       "11  ATL_se0_ag1_m_04_1  ../data/coraal/transcript/text/ATL_se0_ag1_m_0...   \n",
       "12  ATL_se0_ag1_f_02_1  ../data/coraal/transcript/text/ATL_se0_ag1_f_0...   \n",
       "13  ATL_se0_ag1_m_02_1  ../data/coraal/transcript/text/ATL_se0_ag1_m_0...   \n",
       "\n",
       "                                         Audio Path  \n",
       "0   ../data/coraal/audio/wav/ATL_se0_ag2_f_02_1.wav  \n",
       "1   ../data/coraal/audio/wav/ATL_se0_ag2_m_02_1.wav  \n",
       "2   ../data/coraal/audio/wav/ATL_se0_ag2_f_01_1.wav  \n",
       "3   ../data/coraal/audio/wav/ATL_se0_ag2_m_03_1.wav  \n",
       "4   ../data/coraal/audio/wav/ATL_se0_ag2_m_01_1.wav  \n",
       "5   ../data/coraal/audio/wav/ATL_se0_ag1_m_05_1.wav  \n",
       "6   ../data/coraal/audio/wav/ATL_se0_ag1_m_03_1.wav  \n",
       "7   ../data/coraal/audio/wav/ATL_se0_ag1_f_01_1.wav  \n",
       "8   ../data/coraal/audio/wav/ATL_se0_ag1_f_03_1.wav  \n",
       "9   ../data/coraal/audio/wav/ATL_se0_ag1_m_01_1.wav  \n",
       "10  ../data/coraal/audio/wav/ATL_se0_ag1_m_04_2.wav  \n",
       "11  ../data/coraal/audio/wav/ATL_se0_ag1_m_04_1.wav  \n",
       "12  ../data/coraal/audio/wav/ATL_se0_ag1_f_02_1.wav  \n",
       "13  ../data/coraal/audio/wav/ATL_se0_ag1_m_02_1.wav  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "transcript_dir = '../data/coraal/transcript/text/'\n",
    "audio_dir = '../data/coraal/audio/wav/'\n",
    "\n",
    "paths_df = create_file_mapping(transcript_dir, audio_dir)\n",
    "display(paths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transcripts(paths_df):\n",
    "    all_transcript_data = []\n",
    "\n",
    "    # Iterate over each row in the file_mapping_df\n",
    "    for _, row in paths_df.iterrows():\n",
    "        transcript_path = row['Transcript Path']\n",
    "        \n",
    "        # Load transcript data\n",
    "        transcript_df = pd.read_csv(transcript_path, delimiter=\"\\t\")\n",
    "        \n",
    "        # Extract relevant columns\n",
    "        transcript_data = transcript_df[['StTime', 'EnTime', 'Content']].copy()\n",
    "        \n",
    "        # Convert times from minutes to milliseconds for easier calculations\n",
    "        transcript_data['StTime'] *= 1000\n",
    "        transcript_data['EnTime'] *= 1000\n",
    "        transcript_data['Content'] = transcript_data['Content'].str.upper()\n",
    "        \n",
    "        # Add identifier column (optional)\n",
    "        transcript_data['Interview'] = row['Interview']\n",
    "\n",
    "        # Append to list\n",
    "        all_transcript_data.append(transcript_data)\n",
    "    \n",
    "    # Combine all transcript data into a single DataFrame\n",
    "    combined_transcript_df = pd.concat(all_transcript_data, ignore_index=True)\n",
    "    \n",
    "    return combined_transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>Interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>752.6</td>\n",
       "      <td>2511.3</td>\n",
       "      <td>HEY WHAT'S GOING ON?</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2511.3</td>\n",
       "      <td>3144.7</td>\n",
       "      <td>(PAUSE 0.63)</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3144.7</td>\n",
       "      <td>4165.9</td>\n",
       "      <td>I'M HERE WITH</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4165.9</td>\n",
       "      <td>5083.0</td>\n",
       "      <td>(PAUSE 0.92)</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5083.0</td>\n",
       "      <td>5853.6</td>\n",
       "      <td>/RD-NAME-2/.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5853.6</td>\n",
       "      <td>6312.2</td>\n",
       "      <td>(PAUSE 0.46)</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6312.2</td>\n",
       "      <td>7844.7</td>\n",
       "      <td>THIS IS /RD-NAME-2/ BY THE WAY.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7844.7</td>\n",
       "      <td>8799.6</td>\n",
       "      <td>(PAUSE 0.95)</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8799.6</td>\n",
       "      <td>10241.5</td>\n",
       "      <td>UM, /RD-NAME-2/, IF YOU COULD</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10241.5</td>\n",
       "      <td>10534.6</td>\n",
       "      <td>(PAUSE 0.29)</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    StTime   EnTime                          Content           Interview\n",
       "0    752.6   2511.3             HEY WHAT'S GOING ON?  ATL_se0_ag2_f_02_1\n",
       "1   2511.3   3144.7                     (PAUSE 0.63)  ATL_se0_ag2_f_02_1\n",
       "2   3144.7   4165.9                    I'M HERE WITH  ATL_se0_ag2_f_02_1\n",
       "3   4165.9   5083.0                     (PAUSE 0.92)  ATL_se0_ag2_f_02_1\n",
       "4   5083.0   5853.6                     /RD-NAME-2/.  ATL_se0_ag2_f_02_1\n",
       "5   5853.6   6312.2                     (PAUSE 0.46)  ATL_se0_ag2_f_02_1\n",
       "6   6312.2   7844.7  THIS IS /RD-NAME-2/ BY THE WAY.  ATL_se0_ag2_f_02_1\n",
       "7   7844.7   8799.6                     (PAUSE 0.95)  ATL_se0_ag2_f_02_1\n",
       "8   8799.6  10241.5    UM, /RD-NAME-2/, IF YOU COULD  ATL_se0_ag2_f_02_1\n",
       "9  10241.5  10534.6                     (PAUSE 0.29)  ATL_se0_ag2_f_02_1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>Interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23827</th>\n",
       "      <td>2423303.1</td>\n",
       "      <td>2424396.2</td>\n",
       "      <td>ABOUT YOUR FUTURE.</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23828</th>\n",
       "      <td>2424396.2</td>\n",
       "      <td>2425081.9</td>\n",
       "      <td>(PAUSE 0.69)</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23829</th>\n",
       "      <td>2425081.9</td>\n",
       "      <td>2425860.4</td>\n",
       "      <td>DEFINITELY GONNA</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23830</th>\n",
       "      <td>2425937.8</td>\n",
       "      <td>2426912.2</td>\n",
       "      <td>I APPRECIATE [THAT.]</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23831</th>\n",
       "      <td>2426726.6</td>\n",
       "      <td>2428514.3</td>\n",
       "      <td>[BE IN] TOUCH AFTER THIS INTERVIEW,</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23832</th>\n",
       "      <td>2429019.6</td>\n",
       "      <td>2429658.9</td>\n",
       "      <td>AND, UM,</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23833</th>\n",
       "      <td>2429658.9</td>\n",
       "      <td>2430942.7</td>\n",
       "      <td>(PAUSE 1.28)</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23834</th>\n",
       "      <td>2430942.7</td>\n",
       "      <td>2432412.1</td>\n",
       "      <td>IT'S /RD-NAME-3/, AND</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23835</th>\n",
       "      <td>2432412.1</td>\n",
       "      <td>2433113.3</td>\n",
       "      <td>(PAUSE 0.70)</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23836</th>\n",
       "      <td>2433113.3</td>\n",
       "      <td>2434628.8</td>\n",
       "      <td>I'M SIGNING OFF. THIS IS A WRAP.</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          StTime     EnTime                              Content  \\\n",
       "23827  2423303.1  2424396.2                   ABOUT YOUR FUTURE.   \n",
       "23828  2424396.2  2425081.9                         (PAUSE 0.69)   \n",
       "23829  2425081.9  2425860.4                     DEFINITELY GONNA   \n",
       "23830  2425937.8  2426912.2                 I APPRECIATE [THAT.]   \n",
       "23831  2426726.6  2428514.3  [BE IN] TOUCH AFTER THIS INTERVIEW,   \n",
       "23832  2429019.6  2429658.9                             AND, UM,   \n",
       "23833  2429658.9  2430942.7                         (PAUSE 1.28)   \n",
       "23834  2430942.7  2432412.1                IT'S /RD-NAME-3/, AND   \n",
       "23835  2432412.1  2433113.3                         (PAUSE 0.70)   \n",
       "23836  2433113.3  2434628.8     I'M SIGNING OFF. THIS IS A WRAP.   \n",
       "\n",
       "                Interview  \n",
       "23827  ATL_se0_ag1_m_02_1  \n",
       "23828  ATL_se0_ag1_m_02_1  \n",
       "23829  ATL_se0_ag1_m_02_1  \n",
       "23830  ATL_se0_ag1_m_02_1  \n",
       "23831  ATL_se0_ag1_m_02_1  \n",
       "23832  ATL_se0_ag1_m_02_1  \n",
       "23833  ATL_se0_ag1_m_02_1  \n",
       "23834  ATL_se0_ag1_m_02_1  \n",
       "23835  ATL_se0_ag1_m_02_1  \n",
       "23836  ATL_se0_ag1_m_02_1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "combined_transcript_df = process_transcripts(paths_df)\n",
    "display(combined_transcript_df.head(10), combined_transcript_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>Interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>752.6</td>\n",
       "      <td>2511.3</td>\n",
       "      <td>HEY WHAT'S GOING ON?</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3144.7</td>\n",
       "      <td>4165.9</td>\n",
       "      <td>I'M HERE WITH</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10534.6</td>\n",
       "      <td>11289.9</td>\n",
       "      <td>SAY HELLO.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12142.4</td>\n",
       "      <td>12846.2</td>\n",
       "      <td>HELLO.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13458.1</td>\n",
       "      <td>13962.9</td>\n",
       "      <td>OKAY,</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14227.6</td>\n",
       "      <td>15991.0</td>\n",
       "      <td>MIC SEEMS TO BE PICKING YOU UP WELL.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16841.9</td>\n",
       "      <td>17230.4</td>\n",
       "      <td>UM,</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17306.0</td>\n",
       "      <td>17618.0</td>\n",
       "      <td>MM.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17646.4</td>\n",
       "      <td>18227.9</td>\n",
       "      <td>WE'LL GO</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18932.3</td>\n",
       "      <td>21206.2</td>\n",
       "      <td>AND, UM, CONTINUE WITH THIS INTERVIEW.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    StTime   EnTime                                 Content  \\\n",
       "0    752.6   2511.3                    HEY WHAT'S GOING ON?   \n",
       "1   3144.7   4165.9                           I'M HERE WITH   \n",
       "2  10534.6  11289.9                              SAY HELLO.   \n",
       "3  12142.4  12846.2                                  HELLO.   \n",
       "4  13458.1  13962.9                                   OKAY,   \n",
       "5  14227.6  15991.0    MIC SEEMS TO BE PICKING YOU UP WELL.   \n",
       "6  16841.9  17230.4                                     UM,   \n",
       "7  17306.0  17618.0                                     MM.   \n",
       "8  17646.4  18227.9                                WE'LL GO   \n",
       "9  18932.3  21206.2  AND, UM, CONTINUE WITH THIS INTERVIEW.   \n",
       "\n",
       "            Interview  \n",
       "0  ATL_se0_ag2_f_02_1  \n",
       "1  ATL_se0_ag2_f_02_1  \n",
       "2  ATL_se0_ag2_f_02_1  \n",
       "3  ATL_se0_ag2_f_02_1  \n",
       "4  ATL_se0_ag2_f_02_1  \n",
       "5  ATL_se0_ag2_f_02_1  \n",
       "6  ATL_se0_ag2_f_02_1  \n",
       "7  ATL_se0_ag2_f_02_1  \n",
       "8  ATL_se0_ag2_f_02_1  \n",
       "9  ATL_se0_ag2_f_02_1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>Interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9958</th>\n",
       "      <td>2405803.3</td>\n",
       "      <td>2407020.0</td>\n",
       "      <td>THAT WAS DOPE AS WELL, MAN.</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9959</th>\n",
       "      <td>2409658.4</td>\n",
       "      <td>2411158.8</td>\n",
       "      <td>OH MAN, WELL,</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9960</th>\n",
       "      <td>2415648.1</td>\n",
       "      <td>2417452.7</td>\n",
       "      <td>AND THE WORDS OF WISDOM</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9961</th>\n",
       "      <td>2417782.6</td>\n",
       "      <td>2418267.3</td>\n",
       "      <td>AND</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9962</th>\n",
       "      <td>2419437.7</td>\n",
       "      <td>2420386.3</td>\n",
       "      <td>JUST, YOU KNOW,</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9963</th>\n",
       "      <td>2421273.1</td>\n",
       "      <td>2422947.4</td>\n",
       "      <td>EVERYTHING. I'M EXCITED</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>2423303.1</td>\n",
       "      <td>2424396.2</td>\n",
       "      <td>ABOUT YOUR FUTURE.</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9965</th>\n",
       "      <td>2425081.9</td>\n",
       "      <td>2425860.4</td>\n",
       "      <td>DEFINITELY GONNA</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9966</th>\n",
       "      <td>2429019.6</td>\n",
       "      <td>2429658.9</td>\n",
       "      <td>AND, UM,</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>2433113.3</td>\n",
       "      <td>2434628.8</td>\n",
       "      <td>I'M SIGNING OFF. THIS IS A WRAP.</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         StTime     EnTime                           Content  \\\n",
       "9958  2405803.3  2407020.0       THAT WAS DOPE AS WELL, MAN.   \n",
       "9959  2409658.4  2411158.8                     OH MAN, WELL,   \n",
       "9960  2415648.1  2417452.7           AND THE WORDS OF WISDOM   \n",
       "9961  2417782.6  2418267.3                               AND   \n",
       "9962  2419437.7  2420386.3                   JUST, YOU KNOW,   \n",
       "9963  2421273.1  2422947.4           EVERYTHING. I'M EXCITED   \n",
       "9964  2423303.1  2424396.2                ABOUT YOUR FUTURE.   \n",
       "9965  2425081.9  2425860.4                  DEFINITELY GONNA   \n",
       "9966  2429019.6  2429658.9                          AND, UM,   \n",
       "9967  2433113.3  2434628.8  I'M SIGNING OFF. THIS IS A WRAP.   \n",
       "\n",
       "               Interview  \n",
       "9958  ATL_se0_ag1_m_02_1  \n",
       "9959  ATL_se0_ag1_m_02_1  \n",
       "9960  ATL_se0_ag1_m_02_1  \n",
       "9961  ATL_se0_ag1_m_02_1  \n",
       "9962  ATL_se0_ag1_m_02_1  \n",
       "9963  ATL_se0_ag1_m_02_1  \n",
       "9964  ATL_se0_ag1_m_02_1  \n",
       "9965  ATL_se0_ag1_m_02_1  \n",
       "9966  ATL_se0_ag1_m_02_1  \n",
       "9967  ATL_se0_ag1_m_02_1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the regex pattern for unwanted characters\n",
    "pattern = r'[\\(\\)\\[\\]/<>]'\n",
    "\n",
    "# Filter out rows with unwanted characters in the 'Content' column\n",
    "filtered_transcript_df = combined_transcript_df[~combined_transcript_df['Content'].str.contains(pattern)].reset_index(drop=True)\n",
    "\n",
    "display(filtered_transcript_df.head(10), filtered_transcript_df.tail(10))\n",
    "\n",
    "# import re\n",
    "\n",
    "# # Define the regex pattern for unwanted characters and enclosed content\n",
    "# pattern = r'\\([^)]*\\)|\\[[^\\]]*\\]|<[^>]*>|\\/[^\\/]*\\/'\n",
    "\n",
    "# def remove_enclosed_content(text):\n",
    "#     return re.sub(pattern, '', text)\n",
    "\n",
    "# # Apply the function to remove enclosed content\n",
    "# combined_transcript_df['Content'] = combined_transcript_df['Content'].apply(remove_enclosed_content)\n",
    "\n",
    "# # Optionally, you can filter out rows with empty 'Content' after removal\n",
    "# filtered_transcript_df = combined_transcript_df[combined_transcript_df['Content'].str.strip() != ''].reset_index(drop=True)\n",
    "\n",
    "# display(filtered_transcript_df.head(10), filtered_transcript_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>Interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9105</th>\n",
       "      <td>118264.1</td>\n",
       "      <td>119268.1</td>\n",
       "      <td>YOU KNOW, THAT- JUST THAT-</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>642318.4</td>\n",
       "      <td>642748.4</td>\n",
       "      <td>IF NOT,</td>\n",
       "      <td>ATL_se0_ag2_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>1643770.0</td>\n",
       "      <td>1644977.7</td>\n",
       "      <td>THE ENTIRE PASSAGE?</td>\n",
       "      <td>ATL_se0_ag2_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>2082168.7</td>\n",
       "      <td>2084210.4</td>\n",
       "      <td>AND QUENCHED MY THIRST SO MANY TIMES.</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9385</th>\n",
       "      <td>814607.5</td>\n",
       "      <td>816630.0</td>\n",
       "      <td>BUT, YOU KNOW, AROUND THAT- THAT CONCEPT.</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5852</th>\n",
       "      <td>1414333.1</td>\n",
       "      <td>1417254.7</td>\n",
       "      <td>SOMEBODY NEED TO PUT OBAMA ON THE TWENTY-FIVE ...</td>\n",
       "      <td>ATL_se0_ag1_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>1569677.6</td>\n",
       "      <td>1571222.5</td>\n",
       "      <td>LIKE WHEN THEM S- KIDS USED TO COME</td>\n",
       "      <td>ATL_se0_ag2_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>612226.9</td>\n",
       "      <td>616651.3</td>\n",
       "      <td>THAT YOU DIDN'T SEE FOR A WHILE COME AROUND. A...</td>\n",
       "      <td>ATL_se0_ag1_f_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7623</th>\n",
       "      <td>358665.4</td>\n",
       "      <td>359614.1</td>\n",
       "      <td>WHAT ABOUT, UM,</td>\n",
       "      <td>ATL_se0_ag1_m_04_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>223694.1</td>\n",
       "      <td>224934.6</td>\n",
       "      <td>LET'S SEE</td>\n",
       "      <td>ATL_se0_ag1_f_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>842574.4</td>\n",
       "      <td>842925.0</td>\n",
       "      <td>MM-HM.</td>\n",
       "      <td>ATL_se0_ag2_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6562</th>\n",
       "      <td>1713167.4</td>\n",
       "      <td>1715840.9</td>\n",
       "      <td>SO WE COULD CALL- SO I COULD CALL YOU AFTER TH...</td>\n",
       "      <td>ATL_se0_ag1_f_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6425</th>\n",
       "      <td>1331542.7</td>\n",
       "      <td>1332053.4</td>\n",
       "      <td>FOR THEM.</td>\n",
       "      <td>ATL_se0_ag1_f_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>1016241.1</td>\n",
       "      <td>1017746.4</td>\n",
       "      <td>THE BEST OF BOTH WORLDS. LIKE</td>\n",
       "      <td>ATL_se0_ag2_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>1525433.7</td>\n",
       "      <td>1526009.8</td>\n",
       "      <td>HE REALLY</td>\n",
       "      <td>ATL_se0_ag2_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>2099618.3</td>\n",
       "      <td>2102877.0</td>\n",
       "      <td>YOU KNOW WHAT I'M SAYING, BUT A LOT OF THESE N...</td>\n",
       "      <td>ATL_se0_ag2_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6910</th>\n",
       "      <td>964048.9</td>\n",
       "      <td>965364.1</td>\n",
       "      <td>FUCKING FEBRUARY.</td>\n",
       "      <td>ATL_se0_ag1_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>1471405.0</td>\n",
       "      <td>1473194.4</td>\n",
       "      <td>ALL OF THOSE SHOWS WAS ON,</td>\n",
       "      <td>ATL_se0_ag2_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7629</th>\n",
       "      <td>372865.5</td>\n",
       "      <td>373150.8</td>\n",
       "      <td>MM.</td>\n",
       "      <td>ATL_se0_ag1_m_04_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6959</th>\n",
       "      <td>1132040.8</td>\n",
       "      <td>1132328.8</td>\n",
       "      <td>HOW-</td>\n",
       "      <td>ATL_se0_ag1_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>1227690.1</td>\n",
       "      <td>1228722.4</td>\n",
       "      <td>THE WORST, BRUH.</td>\n",
       "      <td>ATL_se0_ag1_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>730664.9</td>\n",
       "      <td>731651.5</td>\n",
       "      <td>UM, LET'S SEE,</td>\n",
       "      <td>ATL_se0_ag2_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>1174074.8</td>\n",
       "      <td>1176391.8</td>\n",
       "      <td>SO MANY YEARS, AND ALSO COMING TO ATLANTA,</td>\n",
       "      <td>ATL_se0_ag2_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>1242619.5</td>\n",
       "      <td>1246727.4</td>\n",
       "      <td>YEAH, YEAH, YEAH, YEAH, YEAH, YEAH, LIKE THOSE...</td>\n",
       "      <td>ATL_se0_ag2_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>1193535.2</td>\n",
       "      <td>1194428.7</td>\n",
       "      <td>IT DESTROYED.</td>\n",
       "      <td>ATL_se0_ag2_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>585579.1</td>\n",
       "      <td>586416.5</td>\n",
       "      <td>REAL COOL.</td>\n",
       "      <td>ATL_se0_ag1_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>850616.7</td>\n",
       "      <td>851553.4</td>\n",
       "      <td>OKAY, SO</td>\n",
       "      <td>ATL_se0_ag1_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7846</th>\n",
       "      <td>95536.0</td>\n",
       "      <td>99804.4</td>\n",
       "      <td>CALI, ALL THE HOUSES ARE DIFFERENT, PAINTED DI...</td>\n",
       "      <td>ATL_se0_ag1_m_04_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>533595.4</td>\n",
       "      <td>534997.8</td>\n",
       "      <td>WHAT YOU CALL IT AGAIN? UM,</td>\n",
       "      <td>ATL_se0_ag1_m_05_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>730321.7</td>\n",
       "      <td>730899.1</td>\n",
       "      <td>I- I HAVE A-</td>\n",
       "      <td>ATL_se0_ag1_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>1215559.5</td>\n",
       "      <td>1217716.4</td>\n",
       "      <td>WHOEVER'S HOSTING IT SAY, OH NO, WE MOVED IT.</td>\n",
       "      <td>ATL_se0_ag1_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9383</th>\n",
       "      <td>809748.4</td>\n",
       "      <td>811618.5</td>\n",
       "      <td>YOU KNOW, THE LOGICAL, EMOTIONAL,</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>1685021.3</td>\n",
       "      <td>1688130.3</td>\n",
       "      <td>LIKE I D- I- I PERSONALLY- LIKE I HAVE NO FAMO...</td>\n",
       "      <td>ATL_se0_ag1_m_05_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>1916754.9</td>\n",
       "      <td>1917531.1</td>\n",
       "      <td>UM,</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>1174726.8</td>\n",
       "      <td>1176055.2</td>\n",
       "      <td>THEY BUILT IT TO BE AN ISH-</td>\n",
       "      <td>ATL_se0_ag2_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>1611119.0</td>\n",
       "      <td>1614144.4</td>\n",
       "      <td>I DON'T THINK I HAD ANY FAVORITES IN HIGH SCHOOL.</td>\n",
       "      <td>ATL_se0_ag2_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>2008685.9</td>\n",
       "      <td>2010196.6</td>\n",
       "      <td>AND LOVE DON'T MAKE DOLLARS.</td>\n",
       "      <td>ATL_se0_ag1_m_05_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>1012164.6</td>\n",
       "      <td>1013045.4</td>\n",
       "      <td>WENT ALL THE WAY OUT.</td>\n",
       "      <td>ATL_se0_ag1_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4871</th>\n",
       "      <td>680894.2</td>\n",
       "      <td>682183.1</td>\n",
       "      <td>WHERE IT'S CONSTANT ACTION.</td>\n",
       "      <td>ATL_se0_ag1_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>1322501.7</td>\n",
       "      <td>1323115.4</td>\n",
       "      <td>UM,</td>\n",
       "      <td>ATL_se0_ag2_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516</th>\n",
       "      <td>913018.3</td>\n",
       "      <td>913374.2</td>\n",
       "      <td>MM.</td>\n",
       "      <td>ATL_se0_ag2_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362</th>\n",
       "      <td>1154722.3</td>\n",
       "      <td>1156870.4</td>\n",
       "      <td>I KNOW WHAT I'M DOING AFTER THIS INTERVIEW.</td>\n",
       "      <td>ATL_se0_ag1_f_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9807</th>\n",
       "      <td>1952675.2</td>\n",
       "      <td>1953704.6</td>\n",
       "      <td>MAN, HONESTLY</td>\n",
       "      <td>ATL_se0_ag1_m_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>2221881.1</td>\n",
       "      <td>2223894.7</td>\n",
       "      <td>THAT IT IS NOW PART OF MY SUBCONSCIOUS.</td>\n",
       "      <td>ATL_se0_ag2_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7154</th>\n",
       "      <td>1695826.3</td>\n",
       "      <td>1699155.3</td>\n",
       "      <td>I DON'T KNOW, BRUH. THIS SHIT THAT I'M DOING, ...</td>\n",
       "      <td>ATL_se0_ag1_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7108</th>\n",
       "      <td>1567096.1</td>\n",
       "      <td>1569043.8</td>\n",
       "      <td>RELATIONSHIP WITH YOUR FAMILY IS?</td>\n",
       "      <td>ATL_se0_ag1_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>1796473.9</td>\n",
       "      <td>1798299.2</td>\n",
       "      <td>PROBABLY GONNA BE LIKE THAT. SO</td>\n",
       "      <td>ATL_se0_ag1_m_05_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>1153473.9</td>\n",
       "      <td>1154969.5</td>\n",
       "      <td>GOD SISTER AND MY</td>\n",
       "      <td>ATL_se0_ag2_f_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7622</th>\n",
       "      <td>357794.1</td>\n",
       "      <td>358185.9</td>\n",
       "      <td>MM.</td>\n",
       "      <td>ATL_se0_ag1_m_04_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6685</th>\n",
       "      <td>227706.3</td>\n",
       "      <td>228713.3</td>\n",
       "      <td>IF YOU EVER PEEPED IT.</td>\n",
       "      <td>ATL_se0_ag1_m_01_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         StTime     EnTime                                            Content  \\\n",
       "9105   118264.1   119268.1                         YOU KNOW, THAT- JUST THAT-   \n",
       "1146   642318.4   642748.4                                            IF NOT,   \n",
       "1513  1643770.0  1644977.7                                THE ENTIRE PASSAGE?   \n",
       "9845  2082168.7  2084210.4              AND QUENCHED MY THIRST SO MANY TIMES.   \n",
       "9385   814607.5   816630.0          BUT, YOU KNOW, AROUND THAT- THAT CONCEPT.   \n",
       "5852  1414333.1  1417254.7  SOMEBODY NEED TO PUT OBAMA ON THE TWENTY-FIVE ...   \n",
       "3732  1569677.6  1571222.5                LIKE WHEN THEM S- KIDS USED TO COME   \n",
       "6182   612226.9   616651.3  THAT YOU DIDN'T SEE FOR A WHILE COME AROUND. A...   \n",
       "7623   358665.4   359614.1                                    WHAT ABOUT, UM,   \n",
       "6041   223694.1   224934.6                                          LET'S SEE   \n",
       "2798   842574.4   842925.0                                             MM-HM.   \n",
       "6562  1713167.4  1715840.9  SO WE COULD CALL- SO I COULD CALL YOU AFTER TH...   \n",
       "6425  1331542.7  1332053.4                                          FOR THEM.   \n",
       "2156  1016241.1  1017746.4                      THE BEST OF BOTH WORLDS. LIKE   \n",
       "1478  1525433.7  1526009.8                                          HE REALLY   \n",
       "1669  2099618.3  2102877.0  YOU KNOW WHAT I'M SAYING, BUT A LOT OF THESE N...   \n",
       "6910   964048.9   965364.1                                  FUCKING FEBRUARY.   \n",
       "3703  1471405.0  1473194.4                         ALL OF THOSE SHOWS WAS ON,   \n",
       "7629   372865.5   373150.8                                                MM.   \n",
       "6959  1132040.8  1132328.8                                               HOW-   \n",
       "6997  1227690.1  1228722.4                                   THE WORST, BRUH.   \n",
       "2052   730664.9   731651.5                                     UM, LET'S SEE,   \n",
       "2202  1174074.8  1176391.8         SO MANY YEARS, AND ALSO COMING TO ATLANTA,   \n",
       "1382  1242619.5  1246727.4  YEAH, YEAH, YEAH, YEAH, YEAH, YEAH, LIKE THOSE...   \n",
       "3615  1193535.2  1194428.7                                      IT DESTROYED.   \n",
       "5668   585579.1   586416.5                                         REAL COOL.   \n",
       "5727   850616.7   851553.4                                           OKAY, SO   \n",
       "7846    95536.0    99804.4  CALI, ALL THE HOUSES ARE DIFFERENT, PAINTED DI...   \n",
       "4121   533595.4   534997.8                        WHAT YOU CALL IT AGAIN? UM,   \n",
       "4888   730321.7   730899.1                                       I- I HAVE A-   \n",
       "5040  1215559.5  1217716.4      WHOEVER'S HOSTING IT SAY, OH NO, WE MOVED IT.   \n",
       "9383   809748.4   811618.5                  YOU KNOW, THE LOGICAL, EMOTIONAL,   \n",
       "4461  1685021.3  1688130.3  LIKE I D- I- I PERSONALLY- LIKE I HAVE NO FAMO...   \n",
       "647   1916754.9  1917531.1                                                UM,   \n",
       "3611  1174726.8  1176055.2                        THEY BUILT IT TO BE AN ISH-   \n",
       "2349  1611119.0  1614144.4  I DON'T THINK I HAD ANY FAVORITES IN HIGH SCHOOL.   \n",
       "4545  2008685.9  2010196.6                       AND LOVE DON'T MAKE DOLLARS.   \n",
       "5759  1012164.6  1013045.4                              WENT ALL THE WAY OUT.   \n",
       "4871   680894.2   682183.1                        WHERE IT'S CONSTANT ACTION.   \n",
       "2249  1322501.7  1323115.4                                                UM,   \n",
       "3516   913018.3   913374.2                                                MM.   \n",
       "6362  1154722.3  1156870.4        I KNOW WHAT I'M DOING AFTER THIS INTERVIEW.   \n",
       "9807  1952675.2  1953704.6                                      MAN, HONESTLY   \n",
       "2523  2221881.1  2223894.7            THAT IT IS NOW PART OF MY SUBCONSCIOUS.   \n",
       "7154  1695826.3  1699155.3  I DON'T KNOW, BRUH. THIS SHIT THAT I'M DOING, ...   \n",
       "7108  1567096.1  1569043.8                  RELATIONSHIP WITH YOUR FAMILY IS?   \n",
       "4490  1796473.9  1798299.2                    PROBABLY GONNA BE LIKE THAT. SO   \n",
       "2194  1153473.9  1154969.5                                  GOD SISTER AND MY   \n",
       "7622   357794.1   358185.9                                                MM.   \n",
       "6685   227706.3   228713.3                             IF YOU EVER PEEPED IT.   \n",
       "\n",
       "               Interview  \n",
       "9105  ATL_se0_ag1_m_02_1  \n",
       "1146  ATL_se0_ag2_m_02_1  \n",
       "1513  ATL_se0_ag2_m_02_1  \n",
       "9845  ATL_se0_ag1_m_02_1  \n",
       "9385  ATL_se0_ag1_m_02_1  \n",
       "5852  ATL_se0_ag1_f_01_1  \n",
       "3732  ATL_se0_ag2_m_01_1  \n",
       "6182  ATL_se0_ag1_f_03_1  \n",
       "7623  ATL_se0_ag1_m_04_2  \n",
       "6041  ATL_se0_ag1_f_03_1  \n",
       "2798  ATL_se0_ag2_m_03_1  \n",
       "6562  ATL_se0_ag1_f_03_1  \n",
       "6425  ATL_se0_ag1_f_03_1  \n",
       "2156  ATL_se0_ag2_f_01_1  \n",
       "1478  ATL_se0_ag2_m_02_1  \n",
       "1669  ATL_se0_ag2_m_02_1  \n",
       "6910  ATL_se0_ag1_m_01_1  \n",
       "3703  ATL_se0_ag2_m_01_1  \n",
       "7629  ATL_se0_ag1_m_04_2  \n",
       "6959  ATL_se0_ag1_m_01_1  \n",
       "6997  ATL_se0_ag1_m_01_1  \n",
       "2052  ATL_se0_ag2_f_01_1  \n",
       "2202  ATL_se0_ag2_f_01_1  \n",
       "1382  ATL_se0_ag2_m_02_1  \n",
       "3615  ATL_se0_ag2_m_01_1  \n",
       "5668  ATL_se0_ag1_f_01_1  \n",
       "5727  ATL_se0_ag1_f_01_1  \n",
       "7846  ATL_se0_ag1_m_04_1  \n",
       "4121  ATL_se0_ag1_m_05_1  \n",
       "4888  ATL_se0_ag1_m_03_1  \n",
       "5040  ATL_se0_ag1_m_03_1  \n",
       "9383  ATL_se0_ag1_m_02_1  \n",
       "4461  ATL_se0_ag1_m_05_1  \n",
       "647   ATL_se0_ag2_f_02_1  \n",
       "3611  ATL_se0_ag2_m_01_1  \n",
       "2349  ATL_se0_ag2_f_01_1  \n",
       "4545  ATL_se0_ag1_m_05_1  \n",
       "5759  ATL_se0_ag1_f_01_1  \n",
       "4871  ATL_se0_ag1_m_03_1  \n",
       "2249  ATL_se0_ag2_f_01_1  \n",
       "3516  ATL_se0_ag2_m_01_1  \n",
       "6362  ATL_se0_ag1_f_03_1  \n",
       "9807  ATL_se0_ag1_m_02_1  \n",
       "2523  ATL_se0_ag2_f_01_1  \n",
       "7154  ATL_se0_ag1_m_01_1  \n",
       "7108  ATL_se0_ag1_m_01_1  \n",
       "4490  ATL_se0_ag1_m_05_1  \n",
       "2194  ATL_se0_ag2_f_01_1  \n",
       "7622  ATL_se0_ag1_m_04_2  \n",
       "6685  ATL_se0_ag1_m_01_1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset = filtered_transcript_df.sample(50)\n",
    "data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_audio_segment(segment, target_length, padding_value=0):\n",
    "    \"\"\"\n",
    "    Pads an audio segment to the target length.\n",
    "    \n",
    "    Parameters:\n",
    "    - segment (torch.Tensor): The audio segment to be padded.\n",
    "    - target_length (int): The desired length in samples.\n",
    "    - padding_value (float): The value to use for padding. Default is 0.\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: Padded audio segment.\n",
    "    \"\"\"\n",
    "    current_length = segment.size(1)\n",
    "    if current_length < target_length:\n",
    "        padding_size = target_length - current_length\n",
    "        padding = torch.full((segment.size(0), padding_size), padding_value)\n",
    "        padded_segment = torch.cat((segment, padding), dim=1)\n",
    "    else:\n",
    "        padded_segment = segment[:, :target_length]  # Truncate if longer than target length\n",
    "    return padded_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_segment(audio_file_path, start_time_ms, end_time_ms, padding_value=0):\n",
    "    \"\"\"\n",
    "    Extracts and pads a segment from an audio file based on start and end times.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_file_path (str): Path to the audio file.\n",
    "    - start_time_ms (int): Start time in milliseconds.\n",
    "    - end_time_ms (int): End time in milliseconds.\n",
    "    - padding_value (float): The value to use for padding. Default is 0.\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: Extracted and padded audio segment.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    waveform, sr = torchaudio.load(audio_file_path)\n",
    "    \n",
    "    # Convert milliseconds to sample indices\n",
    "    start_sample = int(start_time_ms * sr / 1000)\n",
    "    end_sample = int(end_time_ms * sr / 1000)\n",
    "    target_length_ms = 15000  # Target length of 15 seconds (15000 milliseconds)\n",
    "    \n",
    "    # Extract the segment\n",
    "    segment = waveform[:, start_sample:end_sample]\n",
    "    \n",
    "    # Convert target length from milliseconds to samples\n",
    "    target_length_samples = int(target_length_ms * sr / 1000)\n",
    "    \n",
    "    # Pad the segment\n",
    "    padded_segment = pad_audio_segment(segment, target_length_samples, padding_value)\n",
    "    \n",
    "    return padded_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Interview</th>\n",
       "      <th>Content</th>\n",
       "      <th>Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1486802.6</td>\n",
       "      <td>1490400.2</td>\n",
       "      <td>ATL_se0_ag2_m_01_1</td>\n",
       "      <td>YOU KNOW, I AIN'T KNOW WHAT FREAKNIK WAS. I JU...</td>\n",
       "      <td>[[tensor(-0.0004), tensor(-0.0003), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>411784.0</td>\n",
       "      <td>413218.5</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "      <td>DON'T REALLY THINK ABOUT HIM.</td>\n",
       "      <td>[[tensor(-0.0026), tensor(-0.0025), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2101098.7</td>\n",
       "      <td>2102099.0</td>\n",
       "      <td>ATL_se0_ag1_m_03_1</td>\n",
       "      <td>I MET HER,</td>\n",
       "      <td>[[tensor(0.0003), tensor(0.0004), tensor(0.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2749747.4</td>\n",
       "      <td>2750289.2</td>\n",
       "      <td>ATL_se0_ag1_m_01_1</td>\n",
       "      <td>FOR SURE.</td>\n",
       "      <td>[[tensor(-0.0004), tensor(-0.0005), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2445679.0</td>\n",
       "      <td>2446416.5</td>\n",
       "      <td>ATL_se0_ag1_m_01_1</td>\n",
       "      <td>WOW,</td>\n",
       "      <td>[[tensor(0.0020), tensor(0.0020), tensor(0.001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>359799.5</td>\n",
       "      <td>360743.1</td>\n",
       "      <td>ATL_se0_ag1_f_02_1</td>\n",
       "      <td>SHUT UP, SPARKY.</td>\n",
       "      <td>[[tensor(-0.0014), tensor(-0.0014), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>288361.0</td>\n",
       "      <td>289381.8</td>\n",
       "      <td>ATL_se0_ag1_m_04_1</td>\n",
       "      <td>DEFINITELY, DEFINITELY.</td>\n",
       "      <td>[[tensor(-0.0005), tensor(-0.0005), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>485938.8</td>\n",
       "      <td>486962.3</td>\n",
       "      <td>ATL_se0_ag1_f_01_1</td>\n",
       "      <td>OH, OKAY.</td>\n",
       "      <td>[[tensor(-3.0518e-05), tensor(9.1553e-05), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>274038.7</td>\n",
       "      <td>276081.3</td>\n",
       "      <td>ATL_se0_ag1_f_03_1</td>\n",
       "      <td>MIDDLE SCHOOL AND- AND HIGH SCHOOL HERE.</td>\n",
       "      <td>[[tensor(0.0005), tensor(0.0005), tensor(0.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1806153.9</td>\n",
       "      <td>1806682.6</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "      <td>WOW.</td>\n",
       "      <td>[[tensor(-0.0005), tensor(-0.0006), tensor(-0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      StTime     EnTime           Interview  \\\n",
       "0  1486802.6  1490400.2  ATL_se0_ag2_m_01_1   \n",
       "1   411784.0   413218.5  ATL_se0_ag2_f_02_1   \n",
       "2  2101098.7  2102099.0  ATL_se0_ag1_m_03_1   \n",
       "3  2749747.4  2750289.2  ATL_se0_ag1_m_01_1   \n",
       "4  2445679.0  2446416.5  ATL_se0_ag1_m_01_1   \n",
       "5   359799.5   360743.1  ATL_se0_ag1_f_02_1   \n",
       "6   288361.0   289381.8  ATL_se0_ag1_m_04_1   \n",
       "7   485938.8   486962.3  ATL_se0_ag1_f_01_1   \n",
       "8   274038.7   276081.3  ATL_se0_ag1_f_03_1   \n",
       "9  1806153.9  1806682.6  ATL_se0_ag2_f_02_1   \n",
       "\n",
       "                                             Content  \\\n",
       "0  YOU KNOW, I AIN'T KNOW WHAT FREAKNIK WAS. I JU...   \n",
       "1                      DON'T REALLY THINK ABOUT HIM.   \n",
       "2                                         I MET HER,   \n",
       "3                                          FOR SURE.   \n",
       "4                                               WOW,   \n",
       "5                                   SHUT UP, SPARKY.   \n",
       "6                            DEFINITELY, DEFINITELY.   \n",
       "7                                          OH, OKAY.   \n",
       "8           MIDDLE SCHOOL AND- AND HIGH SCHOOL HERE.   \n",
       "9                                               WOW.   \n",
       "\n",
       "                                             Segment  \n",
       "0  [[tensor(-0.0004), tensor(-0.0003), tensor(-0....  \n",
       "1  [[tensor(-0.0026), tensor(-0.0025), tensor(-0....  \n",
       "2  [[tensor(0.0003), tensor(0.0004), tensor(0.000...  \n",
       "3  [[tensor(-0.0004), tensor(-0.0005), tensor(-0....  \n",
       "4  [[tensor(0.0020), tensor(0.0020), tensor(0.001...  \n",
       "5  [[tensor(-0.0014), tensor(-0.0014), tensor(-0....  \n",
       "6  [[tensor(-0.0005), tensor(-0.0005), tensor(-0....  \n",
       "7  [[tensor(-3.0518e-05), tensor(9.1553e-05), ten...  \n",
       "8  [[tensor(0.0005), tensor(0.0005), tensor(0.000...  \n",
       "9  [[tensor(-0.0005), tensor(-0.0006), tensor(-0....  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a list to store extracted audio segments\n",
    "audio_segments = []\n",
    "\n",
    "for idx, row in data_subset.iterrows():\n",
    "    start_tm = row['StTime']\n",
    "    end_tm = row['EnTime']\n",
    "    content = row['Content']\n",
    "    interview = row['Interview']\n",
    "\n",
    "    transcript_path = transcript_dir+interview+\".txt\"\n",
    "    audio_path = audio_dir+interview+\".wav\"\n",
    "\n",
    "    segment = extract_audio_segment(audio_path, start_tm, end_tm)\n",
    "    \n",
    "    # Optionally, save the segment or process it further\n",
    "    audio_segments.append({\n",
    "        'StTime': start_tm,\n",
    "        'EnTime': end_tm,\n",
    "        'Interview': interview,\n",
    "        'Content': content,\n",
    "        'Segment': segment\n",
    "    })\n",
    "\n",
    "audio_segments_subset_df = pd.DataFrame(audio_segments)\n",
    "audio_segments_subset_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 661500])\n",
      "torch.Size([1, 661500])\n",
      "torch.Size([1, 661500])\n",
      "torch.Size([1, 661500])\n",
      "torch.Size([1, 661500])\n",
      "torch.Size([1, 661500])\n",
      "torch.Size([1, 661500])\n",
      "torch.Size([1, 661500])\n",
      "torch.Size([1, 661500])\n",
      "torch.Size([1, 661500])\n"
     ]
    }
   ],
   "source": [
    "for idx, row in audio_segments_subset_df.iterrows():\n",
    "    if idx == 10:\n",
    "        break\n",
    "    print(row['Segment'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processor and model for whisper-tiny\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to the appropriate device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(audio_tensor, sample_rate, target_sample_rate=16000):\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "        audio_tensor = resampler(audio_tensor)\n",
    "    return audio_tensor\n",
    "\n",
    "def transcribe_audio(audio_tensor, model, processor):\n",
    "    audio_tensor = audio_tensor.to(device)\n",
    "    inputs = processor(audio_tensor.squeeze().cpu().numpy(), return_tensors=\"pt\", sampling_rate=16000)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(**inputs)\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    return transcription[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment Start: 1486802.6\n",
      "Actual Transcript: YOU KNOW, I AIN'T KNOW WHAT FREAKNIK WAS. I JUST HAPPENED TO GO DOWNTOWN.\n",
      "Model Transcription:  YOU KNOW, I KNOW WHAT FREAKIN' MEEK WAS. I JUST HAPPENED TO GO DOWNTOWN.\n",
      "\n",
      "\n",
      "Segment Start: 411784.0\n",
      "Actual Transcript: DON'T REALLY THINK ABOUT HIM.\n",
      "Model Transcription:  DON'T REALLY THINK ABOUT IT.\n",
      "\n",
      "\n",
      "Segment Start: 2101098.7\n",
      "Actual Transcript: I MET HER,\n",
      "Model Transcription:  I MET HER.\n",
      "\n",
      "\n",
      "Segment Start: 2749747.4000000004\n",
      "Actual Transcript: FOR SURE.\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 2445679.0\n",
      "Actual Transcript: WOW,\n",
      "Model Transcription:  WOW.\n",
      "\n",
      "\n",
      "Segment Start: 359799.5\n",
      "Actual Transcript: SHUT UP, SPARKY.\n",
      "Model Transcription:  SHOUT OUT, SWAGGY!\n",
      "\n",
      "\n",
      "Segment Start: 288361.0\n",
      "Actual Transcript: DEFINITELY, DEFINITELY.\n",
      "Model Transcription:  DEFINITELY.\n",
      "\n",
      "\n",
      "Segment Start: 485938.8\n",
      "Actual Transcript: OH, OKAY.\n",
      "Model Transcription:  OH, OKAY.\n",
      "\n",
      "\n",
      "Segment Start: 274038.7\n",
      "Actual Transcript: MIDDLE SCHOOL AND- AND HIGH SCHOOL HERE.\n",
      "Model Transcription:  MIDDLE SCHOOL AND HIGH SCHOOL HERE.\n",
      "\n",
      "\n",
      "Segment Start: 1806153.9\n",
      "Actual Transcript: WOW.\n",
      "Model Transcription:  WOW.\n",
      "\n",
      "\n",
      "Segment Start: 134711.3\n",
      "Actual Transcript: I AIN'T THE DUMBEST.\n",
      "Model Transcription:  I AIN'T A DUMBEST.\n",
      "\n",
      "\n",
      "Segment Start: 1829687.7\n",
      "Actual Transcript: I CLING TO ANYTHING THAT'S-\n",
      "Model Transcription:  I'M NOT GOING TO HAVE ANYTHING THAT'S...\n",
      "\n",
      "\n",
      "Segment Start: 1425080.2000000002\n",
      "Actual Transcript: WE GET\n",
      "Model Transcription:  WE GET...\n",
      "\n",
      "\n",
      "Segment Start: 1364152.4\n",
      "Actual Transcript: EVERY TIME YOU SEE A COP.\n",
      "Model Transcription:  EVERY TIME YOU SEE A COP.\n",
      "\n",
      "\n",
      "Segment Start: 735876.8\n",
      "Actual Transcript: THAT'S\n",
      "Model Transcription:  THIS.\n",
      "\n",
      "\n",
      "Segment Start: 266506.6\n",
      "Actual Transcript: NAH THAT'S COOL.\n",
      "Model Transcription:  THAT'S COOL.\n",
      "\n",
      "\n",
      "Segment Start: 1270881.1\n",
      "Actual Transcript: WORKING PROBABLY\n",
      "Model Transcription:  WORKROOM, POLLY.\n",
      "\n",
      "\n",
      "Segment Start: 946034.2000000001\n",
      "Actual Transcript: T- WHAT'S THE WORD I'M LOOKING FOR?\n",
      "Model Transcription:  AND WHAT'S THE WORD I'M LOOKING FOR?\n",
      "\n",
      "\n",
      "Segment Start: 1039024.3\n",
      "Actual Transcript: NECESSARILY THINK I HAVE THE MOST\n",
      "Model Transcription:  NECESSARILY THINK I HAVE THE MOST.\n",
      "\n",
      "\n",
      "Segment Start: 1672524.7999999998\n",
      "Actual Transcript: YO\n",
      "Model Transcription:  YEAH.\n",
      "\n",
      "\n",
      "Segment Start: 2442190.3000000003\n",
      "Actual Transcript: AND MAKE SURE THEY ALL DO SOMETHING DIFFERENT\n",
      "Model Transcription:  AND MAKE SURE THEY ALL DO SOMETHING DIFFERENT.\n",
      "\n",
      "\n",
      "Segment Start: 561175.8999999999\n",
      "Actual Transcript: YOU GOT\n",
      "Model Transcription:  YOU GOT IT.\n",
      "\n",
      "\n",
      "Segment Start: 1203423.5\n",
      "Actual Transcript: LIKE HOW- HOW MUCH WOULD YOU PAY FOR\n",
      "Model Transcription:  ABOUT HOW MUCH WOULD YOU PAY FOR?\n",
      "\n",
      "\n",
      "Segment Start: 319293.4\n",
      "Actual Transcript: BUT, YOU KNOW, Y- YOU BE ONE PLACE LONG ENOUGH, YOU L- YOU LEARN A VIBE. YOU LEARN HOW TO-\n",
      "Model Transcription:  BUT YOU KNOW, YOU BE ONE PLACE LONG ENOUGH, YOU LEARN TO VIBE, YOU LEARN HOW TO.\n",
      "\n",
      "\n",
      "Segment Start: 1158162.9000000001\n",
      "Actual Transcript: WE'RE KINDA HARSH TOWARDS ONE ANOTHER, BUT I THINK THAT'S A NEW YORK THING. BUT\n",
      "Model Transcription:  WE'RE KIND OF HARSH TOWARDS ONE ANOTHER, BUT I THINK THAT'S A NEW YORK THING, BUT.\n",
      "\n",
      "\n",
      "Segment Start: 1074840.7\n",
      "Actual Transcript: UM,\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 2114688.0\n",
      "Actual Transcript: OKAY.\n",
      "Model Transcription:  OKAY.\n",
      "\n",
      "\n",
      "Segment Start: 989892.9\n",
      "Actual Transcript: AND, YOU KNOW, SHIT, GOD DAMN.\n",
      "Model Transcription:  YOU KNOW, SHIT, GODDAMN.\n",
      "\n",
      "\n",
      "Segment Start: 29830.9\n",
      "Actual Transcript: UM,\n",
      "Model Transcription:  UM,\n",
      "\n",
      "\n",
      "Segment Start: 1469783.6\n",
      "Actual Transcript: YEAH, ALL UP.\n",
      "Model Transcription:  YEAH, ALL OF THEM.\n",
      "\n",
      "\n",
      "Segment Start: 995688.6\n",
      "Actual Transcript: OKAY. IT'S-\n",
      "Model Transcription:  OKAY, IT'S...\n",
      "\n",
      "\n",
      "Segment Start: 1391572.7\n",
      "Actual Transcript: I BE TRYING TO EITHER GET TOO DEEP INTO POLITICS AND STUFF. I BE LISTENING TO IT-\n",
      "Model Transcription:  EVERY CHANNEL THAT YOU GET TOO DEEP IN POLITICS IS THAT I BE LISTENING TO IT.\n",
      "\n",
      "\n",
      "Segment Start: 399015.4\n",
      "Actual Transcript: OKAY.\n",
      "Model Transcription:  OKAY.\n",
      "\n",
      "\n",
      "Segment Start: 1329237.0\n",
      "Actual Transcript: YOU KNOW, OPENING YOUR ROOT UP. A LOT OF PEOPLE'S ROOTS ARE CLOSED.\n",
      "Model Transcription:  YOU KNOW, OPENING YOUR ROOT UP A LOT OF PEOPLE'S ROOTS ARE CLOSED.\n",
      "\n",
      "\n",
      "Segment Start: 747807.6\n",
      "Actual Transcript: WOW.\n",
      "Model Transcription:  WOW.\n",
      "\n",
      "\n",
      "Segment Start: 2243347.1\n",
      "Actual Transcript: IF YOU JUST SMOKE THAT SHIT TO SMOKE THAT SHIT,\n",
      "Model Transcription:  IF YOU JUST SMOKE THAT SHIT, JUST SMOKE THAT SHIT.\n",
      "\n",
      "\n",
      "Segment Start: 902402.9\n",
      "Actual Transcript: REGARDLESS.\n",
      "Model Transcription:  REGARDLESS.\n",
      "\n",
      "\n",
      "Segment Start: 1317000.2999999998\n",
      "Actual Transcript: UM,\n",
      "Model Transcription:  ON.\n",
      "\n",
      "\n",
      "Segment Start: 440906.4\n",
      "Actual Transcript: JUST BIG BIG PEOPLE.\n",
      "Model Transcription:  BIG, BIG PEOPLE.\n",
      "\n",
      "\n",
      "Segment Start: 1561769.9\n",
      "Actual Transcript: CLIPPERS UP THREE ONE LA-\n",
      "Model Transcription:  CLIPPERS ARE 3-1 LAST.\n",
      "\n",
      "\n",
      "Segment Start: 400554.0\n",
      "Actual Transcript: SCHOOL WAS\n",
      "Model Transcription:  SCHOOL WAS\n",
      "\n",
      "\n",
      "Segment Start: 1927480.3\n",
      "Actual Transcript: ATLANTA WOMEN- IF YOU TALK A GOOD ENOUGH GAME TO 'EM,\n",
      "Model Transcription:  ATLANTA WOMEN, IF YOU TALK A GOOD ENOUGH GAME,\n",
      "\n",
      "\n",
      "Segment Start: 1882074.5\n",
      "Actual Transcript: WHAT WOULD YOU CUR-\n",
      "Model Transcription:  WHAT WOULD YOU CARE?\n",
      "\n",
      "\n",
      "Segment Start: 1326228.0\n",
      "Actual Transcript: JUST LISTEN TO SOLAR PLEXUS HEALING AND,\n",
      "Model Transcription:  JUST LISTEN TO SOLAR PLEXUS HEALING IT.\n",
      "\n",
      "\n",
      "Segment Start: 1933993.4000000001\n",
      "Actual Transcript: IS BASED ON BELIEF THAT AS\n",
      "Model Transcription:  BASED ON BELIEF.\n",
      "\n",
      "\n",
      "Segment Start: 1165930.4\n",
      "Actual Transcript: THAT'S NICE. THAT'S COOL.\n",
      "Model Transcription:  THAT'S COOL.\n",
      "\n",
      "\n",
      "Segment Start: 1809756.3\n",
      "Actual Transcript: YOU GOT A, UM, FAVORITE TEAM?\n",
      "Model Transcription:  YOU GOT A FAVORITE TEAM?\n",
      "\n",
      "\n",
      "Segment Start: 1625246.3\n",
      "Actual Transcript: HE JUST SOUND LIKE HE JUST MUMBLED. HE SAID THE FIRST WORD AND THE LAST WORD, AND EVERYTHING ELSE IN BETWEEN WAS JUST ONE BIG ASS MUMBLE.\n",
      "Model Transcription:  HE JUST, HE JUST MUMBLED. HE SAID THE FIRST WORD AND LAST WORD AND EVERYTHING ELSE BETWEEN WHICH IS ONE BIG ASS MUMBLE.\n",
      "\n",
      "\n",
      "Segment Start: 1422726.5999999999\n",
      "Actual Transcript: THAT'S WHAT WE- THAT'S WHAT WE GONNA ENJOY.\n",
      "Model Transcription:  THAT'S WHAT WE, THAT'S WHAT WE'RE GONNA ENJOY.\n",
      "\n",
      "\n",
      "Segment Start: 1634563.3\n",
      "Actual Transcript: YOU- YOU LISTENING TO S- MUSIC THE NEXT NIGHT, YOU ON INSTAGRAM THE NEXT NIGHT,\n",
      "Model Transcription:  YOU LISTEN INTO MUSIC THE NEXT NIGHT, YOU OWN INSTAGRAM AND NEXT NIGHT.\n",
      "\n",
      "\n",
      "Segment Start: 1138713.2\n",
      "Actual Transcript: UM,\n",
      "Model Transcription:  AND...\n",
      "\n",
      "\n",
      "Segment Start: 249087.19999999998\n",
      "Actual Transcript: COMING FROM WHERE I COME FROM,\n",
      "Model Transcription:  COMING FROM\n",
      "\n",
      "\n",
      "Segment Start: 809930.6\n",
      "Actual Transcript: MM-HM.\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 54134.799999999996\n",
      "Actual Transcript: UH, I'LL SAY THE NATURE OF\n",
      "Model Transcription:  I'LL SAY THE NATURE OF...\n",
      "\n",
      "\n",
      "Segment Start: 1953.4\n",
      "Actual Transcript: YUP.\n",
      "Model Transcription:  YEAH.\n",
      "\n",
      "\n",
      "Segment Start: 1140053.7\n",
      "Actual Transcript: MY M- LIKE\n",
      "Model Transcription:  I'M LATE.\n",
      "\n",
      "\n",
      "Segment Start: 1386179.0\n",
      "Actual Transcript: SO,\n",
      "Model Transcription:  SO\n",
      "\n",
      "\n",
      "Segment Start: 437660.5\n",
      "Actual Transcript: OR A NEIGHBOR,\n",
      "Model Transcription:  OR A NEIGHBOR.\n",
      "\n",
      "\n",
      "Segment Start: 2076216.4\n",
      "Actual Transcript: HIM SPEAKING\n",
      "Model Transcription:  HIM SPEAKING.\n",
      "\n",
      "\n",
      "Segment Start: 49354.100000000006\n",
      "Actual Transcript: ALL\n",
      "Model Transcription:  OH.\n",
      "\n",
      "\n",
      "Segment Start: 347256.8\n",
      "Actual Transcript: EVEN IF IT WAS JUST LIKE A LITTLE, UM,\n",
      "Model Transcription:  EVEN IF IT WAS JUST LIKE A LITTLE, UM.\n",
      "\n",
      "\n",
      "Segment Start: 2200565.4\n",
      "Actual Transcript: MM.\n",
      "Model Transcription:  MMM.\n",
      "\n",
      "\n",
      "Segment Start: 1020827.6\n",
      "Actual Transcript: GO OUT- OUT-\n",
      "Model Transcription:  GO OUT.\n",
      "\n",
      "\n",
      "Segment Start: 860326.2999999999\n",
      "Actual Transcript: MM-HM.\n",
      "Model Transcription:  YEAH.\n",
      "\n",
      "\n",
      "Segment Start: 1931544.5999999999\n",
      "Actual Transcript: THE MYTH OF IT'S EFFECTIVENESS\n",
      "Model Transcription:  THE MAN FOR THIS EFFECTIVENESS.\n",
      "\n",
      "\n",
      "Segment Start: 2552594.8\n",
      "Actual Transcript: AND PUT YOUR MONEY ON PANDORA, AND IT MIGHT NOT EVEN BE PANDORA.\n",
      "Model Transcription:  AND PUT YOUR MONEY ON PANDORA, AND YOU MIGHT NOT NEED TO BE PANDORA.\n",
      "\n",
      "\n",
      "Segment Start: 165155.9\n",
      "Actual Transcript: YEAH YOU F- CHANGED YOUR FATE\n",
      "Model Transcription:  YEAH, YOU'VE CHANGED YOUR FEET.\n",
      "\n",
      "\n",
      "Segment Start: 807788.8\n",
      "Actual Transcript: SHIRTLESS WITH SHORTS AND LIKE\n",
      "Model Transcription:  SHIRTLESS WITH SHORTS AND LIKE.\n",
      "\n",
      "\n",
      "Segment Start: 1167531.9\n",
      "Actual Transcript: OKAY.\n",
      "Model Transcription:  OKAY.\n",
      "\n",
      "\n",
      "Segment Start: 1830294.3\n",
      "Actual Transcript: YEAH.\n",
      "Model Transcription:  YEAH.\n",
      "\n",
      "\n",
      "Segment Start: 877089.5\n",
      "Actual Transcript: THAT WEED, I DONE- I DONE GOT A LITTLE EDGE ON THAT SHIT, YOU KNOW WHAT I MEAN, UNLESS I'M'A JUST BLOW IT\n",
      "Model Transcription:  I MEAN, I MEAN, I MEAN, LET'S HOW MUCH IS BLOAT.\n",
      "\n",
      "\n",
      "Segment Start: 298980.1\n",
      "Actual Transcript: OKAY.\n",
      "Model Transcription:  OKAY.\n",
      "\n",
      "\n",
      "Segment Start: 270748.89999999997\n",
      "Actual Transcript: I HAD TO INTERVIEW A COUPLE DIFFERENT\n",
      "Model Transcription:  I'LL INTERVIEW A COUPLE DIFFERENT.\n",
      "\n",
      "\n",
      "Segment Start: 1130156.0\n",
      "Actual Transcript: MAJORITY OF THE GREAT PLAYERS THAT\n",
      "Model Transcription:  MAJORITY OF THE GREAT PLAYERS THAT\n",
      "\n",
      "\n",
      "Segment Start: 300108.9\n",
      "Actual Transcript: YEAH, MY MOM'S MOM, UH, I HAVE A RELATIONSHIP.\n",
      "Model Transcription:  YEAH, MY MOM, I HAVE A RELATIONSHIP.\n",
      "\n",
      "\n",
      "Segment Start: 1440270.8\n",
      "Actual Transcript: WE GET TWENTY-FIVE,\n",
      "Model Transcription:  GET 25.\n",
      "\n",
      "\n",
      "Segment Start: 1111924.0999999999\n",
      "Actual Transcript: YOU KNOW WHAT I'M SAYING.\n",
      "Model Transcription:  YOU KNOW WHAT I MEAN?\n",
      "\n",
      "\n",
      "Segment Start: 2182449.4\n",
      "Actual Transcript: I MEAN I GUESS\n",
      "Model Transcription:  I MEAN, I GUESS.\n",
      "\n",
      "\n",
      "Segment Start: 2622610.6\n",
      "Actual Transcript: GOT ABOUT THREE PAIR.\n",
      "Model Transcription:  THANK YOU.\n",
      "\n",
      "\n",
      "Segment Start: 277700.8\n",
      "Actual Transcript: WITHIN THE BLACK COMMUNITY.\n",
      "Model Transcription:  WITHIN THE BLACK COMMUNITY.\n",
      "\n",
      "\n",
      "Segment Start: 328984.89999999997\n",
      "Actual Transcript: YOUR SIBLINGS GOT AWAY WITH THINGS THAT\n",
      "Model Transcription:  YES, SIBLINGS GOT AWAY WITH THINGS THAT\n",
      "\n",
      "\n",
      "Segment Start: 2274259.1\n",
      "Actual Transcript: GO FROM THERE, MAN.\n",
      "Model Transcription:  GO FROM THERE, MAN.\n",
      "\n",
      "\n",
      "Segment Start: 812004.9\n",
      "Actual Transcript: THE MIDDLE SCHOOL FRIENDS?\n",
      "Model Transcription:  THE MIDDLE SCHOOL FRIENDS?\n",
      "\n",
      "\n",
      "Segment Start: 157346.6\n",
      "Actual Transcript: IS THERE A HOOK OR\n",
      "Model Transcription:  THE HOOK OR\n",
      "\n",
      "\n",
      "Segment Start: 1769591.4\n",
      "Actual Transcript: RIGHT.\n",
      "Model Transcription:  RIGHT.\n",
      "\n",
      "\n",
      "Segment Start: 774471.6\n",
      "Actual Transcript: AT THE END OF THE DAY.\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 63148.6\n",
      "Actual Transcript: TWO WEEKS IN BALTIMORE,\n",
      "Model Transcription:  TO THE LEAST AND BALTIMORE.\n",
      "\n",
      "\n",
      "Segment Start: 2533352.6\n",
      "Actual Transcript: SLAY THAT SHIT,\n",
      "Model Transcription:  SLIGHT OUT SHIT.\n",
      "\n",
      "\n",
      "Segment Start: 2541392.5\n",
      "Actual Transcript: YOU KNOW WHAT I'M SAYING, THE MOVEMENT- THE MOVEMENT HAS ALREADY BEGUN.\n",
      "Model Transcription:  YOU KNOW, THE MOVEMENT, THE MOVEMENT IS ALREADY BEGUN.\n",
      "\n",
      "\n",
      "Segment Start: 1749846.0\n",
      "Actual Transcript: CAMPAIGN, NIGGA,\n",
      "Model Transcription:  CAMPAIGN.\n",
      "\n",
      "\n",
      "Segment Start: 2399123.0999999996\n",
      "Actual Transcript: STOP- WHAT?\n",
      "Model Transcription:  STOP WORDS!\n",
      "\n",
      "\n",
      "Segment Start: 285394.60000000003\n",
      "Actual Transcript: MM.\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 1252397.3\n",
      "Actual Transcript: I'M'A GET IT.\n",
      "Model Transcription:  I'M A GOODIE.\n",
      "\n",
      "\n",
      "Segment Start: 1903690.5999999999\n",
      "Actual Transcript: APPRECIATE IT.\n",
      "Model Transcription:  APPRECIATE IT.\n",
      "\n",
      "\n",
      "Segment Start: 869072.4\n",
      "Actual Transcript: IS YOUR CALLING, YOUR PASSION.\n",
      "Model Transcription:  IS IT CALLING YOUR PASSION?\n",
      "\n",
      "\n",
      "Segment Start: 1682886.0999999999\n",
      "Actual Transcript: YOU FEEL ME.\n",
      "Model Transcription:  I'M GONNA FILM YOU.\n",
      "\n",
      "\n",
      "Segment Start: 1922693.9\n",
      "Actual Transcript: BEAR'S GREASE WAS A POPULAR TREATMENT FOR MEN WITH HAIR LOSS FROM AT LEAST AS EARLY AS SIXTEEN FIFTY-THREE UNTIL ABOUT THE FIRST WAR.\n",
      "Model Transcription:  BEARS GRACE WAS A POPULAR TREATMENT FOR MAMB WITH HAIR LOSS FROM AT LEAST AS EARLY AS 1653 IN CENTRAL FRONT TO FIRST WAR.\n",
      "\n",
      "\n",
      "Segment Start: 1270921.5\n",
      "Actual Transcript: A WEEK.\n",
      "Model Transcription:  PLEASE.\n",
      "\n",
      "\n",
      "Segment Start: 561887.1\n",
      "Actual Transcript: I LOVED THE FACT THAT\n",
      "Model Transcription:  I LOVE THE FACT THEN.\n",
      "\n",
      "\n",
      "Segment Start: 830858.3999999999\n",
      "Actual Transcript: EVEN ON-\n",
      "Model Transcription:  YOU LOVE.\n",
      "\n",
      "\n",
      "Segment Start: 862767.6\n",
      "Actual Transcript: YOU KNOW WHAT I'M SAYING, I'M LOOKING OUT FOR YOU CAUSE I KNOW\n",
      "Model Transcription:  YOU KNOW WHAT I'M LOOKING OUT FOR YOU BECAUSE I KNOW.\n",
      "\n",
      "\n",
      "Segment Start: 949497.4\n",
      "Actual Transcript: AND, UH, MY MOM, LIKE SHE KNEW THEY WAS GONNA END UP LIKE, EXPELLING ME, SO SHE JUST WITHDREW ME\n",
      "Model Transcription:  AND MY MOM, LIKE, SEE NUDE WAS GOING INTO LIKE, SPELLING ME SO SHE JUST WITHDREW ME.\n",
      "\n",
      "\n",
      "Segment Start: 2122559.9000000004\n",
      "Actual Transcript: LOVE DUBAI, JUST THE-\n",
      "Model Transcription:  I LOVE TO BUY JUST A\n",
      "\n",
      "\n",
      "Segment Start: 974881.7000000001\n",
      "Actual Transcript: YOU KNOW, IF YOU GONNA DO SOMETHING THAT'S,\n",
      "Model Transcription:  YEAH, IF YOU'RE GONNA DO SOMETHING THIS.\n",
      "\n",
      "\n",
      "Segment Start: 182247.3\n",
      "Actual Transcript: LETTING YOU KNOW.\n",
      "Model Transcription:  LET YOU KNOW.\n",
      "\n",
      "\n",
      "Segment Start: 967868.2\n",
      "Actual Transcript: PERSPECTIVE. YOU DON'T HAVE THAT PERSON TELLING YOU LIKE, OH NO,\n",
      "Model Transcription:  PERSPECTIVE, YOU'LL HAVE THAT PERSON'S TIME, YOU'RE LIKE, OH NO.\n",
      "\n",
      "\n",
      "Segment Start: 286660.1\n",
      "Actual Transcript: WOW.\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 1419783.4000000001\n",
      "Actual Transcript: BE KEEPING GOOD COMPANY.\n",
      "Model Transcription:  BE KEEPING GOOD COMPANY.\n",
      "\n",
      "\n",
      "Segment Start: 1239423.6\n",
      "Actual Transcript: MM-HM.\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 304037.5\n",
      "Actual Transcript: SCHOOL\n",
      "Model Transcription:  SCHOOL.\n",
      "\n",
      "\n",
      "Segment Start: 1058352.0\n",
      "Actual Transcript: I MEAN, YOU KNOW,\n",
      "Model Transcription:  I MEAN, YOU KNOW.\n",
      "\n",
      "\n",
      "Segment Start: 2147272.1999999997\n",
      "Actual Transcript: MM-HM.\n",
      "Model Transcription:  HUH?\n",
      "\n",
      "\n",
      "Segment Start: 1387912.4\n",
      "Actual Transcript: THE MUSIC BECAUSE THAT'S REALLY WHAT THIS AREA IS.\n",
      "Model Transcription:  THE MUSIC BECAUSE THAT'S REALLY WHAT THIS AREA IS.\n",
      "\n",
      "\n",
      "Segment Start: 168919.0\n",
      "Actual Transcript: THANKS.\n",
      "Model Transcription:  THANKS.\n",
      "\n",
      "\n",
      "Segment Start: 752.6\n",
      "Actual Transcript: HEY WHAT'S GOING ON?\n",
      "Model Transcription:  HEY, WHAT'S GOING ON?\n",
      "\n",
      "\n",
      "Segment Start: 660824.2000000001\n",
      "Actual Transcript: UM, ONCE I GOT TO ABOUT LIKE THE TENTH, ELEVENTH GRADE THOUGH, IT WAS JUST ABOUT TIME TO TAKE MARTA.\n",
      "Model Transcription:  ONCE I GOT TO ABOUT LIKE THE 10TH 11TH GRADE, THOUGH, IS JUST ABOUT TIME TO TAKE MARTA.\n",
      "\n",
      "\n",
      "Segment Start: 1176938.3\n",
      "Actual Transcript: WHAT ABOUT\n",
      "Model Transcription:  WHAT ABOUT\n",
      "\n",
      "\n",
      "Segment Start: 2204133.6\n",
      "Actual Transcript: THE-\n",
      "Model Transcription:  YEAH.\n",
      "\n",
      "\n",
      "Segment Start: 2626770.5999999996\n",
      "Actual Transcript: HELL YEAH,\n",
      "Model Transcription:  OH YEAH.\n",
      "\n",
      "\n",
      "Segment Start: 419591.7\n",
      "Actual Transcript: AND, UM,\n",
      "Model Transcription:  AND UM...\n",
      "\n",
      "\n",
      "Segment Start: 1156542.5\n",
      "Actual Transcript: I- HE- HE WASN'T LIKE\n",
      "Model Transcription:  HE WASN'T LIKE...\n",
      "\n",
      "\n",
      "Segment Start: 1162135.5\n",
      "Actual Transcript: I'M GONNA TEACH THEM TO BE A LITTLE SOFTER AND NICER WITH EACH OTHER.\n",
      "Model Transcription:  I'M GONNA TEACH THEM TO BE A LITTLE SOFTER AND NICE OVER EACH OTHER.\n",
      "\n",
      "\n",
      "Segment Start: 1783064.0\n",
      "Actual Transcript: AND A LEGIT HIP HOP ARTIST,\n",
      "Model Transcription:  AND THE LEGIT HIP-HOP HARNESS.\n",
      "\n",
      "\n",
      "Segment Start: 695173.0\n",
      "Actual Transcript: I- MAN, I HEARD SOME SHIT FROM DJ UNK THE OTHER DAY, MY NIGGA, AND I DON'T- I- Y-\n",
      "Model Transcription:  I'M NOT HERE TO HEAR SOME SHIT FROM DJ ON THE OTHER DAY, MY NIGGA, AND I'LL, YOU.\n",
      "\n",
      "\n",
      "Segment Start: 2038617.0999999999\n",
      "Actual Transcript: GOVERNMENT IS GONNA BE\n",
      "Model Transcription:  GOVERNMENT IS GOING TO BE.\n",
      "\n",
      "\n",
      "Segment Start: 1676614.0\n",
      "Actual Transcript: BOYS ARE\n",
      "Model Transcription:  BORES.\n",
      "\n",
      "\n",
      "Segment Start: 1134413.3\n",
      "Actual Transcript: HIS LYRICAL CONTENT.\n",
      "Model Transcription:  HIS LYRICAL CONTENT.\n",
      "\n",
      "\n",
      "Segment Start: 556850.2\n",
      "Actual Transcript: UM, I ALWAYS GREW UP IN CHURCH, GREW UP IN MUSIC. YOU KNOW, EVERYBODY IN MY FAMILY PL-\n",
      "Model Transcription:  I ALWAYS GREW UP IN CHURCH GREW UP IN MUSIC AND I'LL EVERYBODY IN MY FAMILY PUT IT.\n",
      "\n",
      "\n",
      "Segment Start: 1942439.7\n",
      "Actual Transcript: DO THIS, DID YOU HONK I- DID YOUR- LIGHTS ON?\n",
      "Model Transcription:  DO THIS AND YOU'RE HONKING YOUR LIGHTS ON.\n",
      "\n",
      "\n",
      "Segment Start: 778963.6000000001\n",
      "Actual Transcript: OKAY.\n",
      "Model Transcription:  OKAY.\n",
      "\n",
      "\n",
      "Segment Start: 1002776.0\n",
      "Actual Transcript: BUT I CALL THEM MY BROTHERS AND SISTERS.\n",
      "Model Transcription:  BUT I CALL THEM OUR BUSINESSES.\n",
      "\n",
      "\n",
      "Segment Start: 1086115.8\n",
      "Actual Transcript: SO HE AIN'T HAVE TO GO THROUGH\n",
      "Model Transcription:  SO HERE YOU HAVE TO GO THROUGH.\n",
      "\n",
      "\n",
      "Segment Start: 507537.69999999995\n",
      "Actual Transcript: GEORGIA,\n",
      "Model Transcription:  GEORGIA.\n",
      "\n",
      "\n",
      "Segment Start: 218427.6\n",
      "Actual Transcript: IT EXISTS.\n",
      "Model Transcription:  ANYWAYS.\n",
      "\n",
      "\n",
      "Segment Start: 565861.5\n",
      "Actual Transcript: DOING STUFF THAT IT AIN'T SUPPOSED TO BE DOING TO US.\n",
      "Model Transcription:  DOING STUFF THAT AIN'T SUPPOSED TO BE DOING TO US.\n",
      "\n",
      "\n",
      "Segment Start: 865599.5\n",
      "Actual Transcript: I HAD TO MOVE.\n",
      "Model Transcription:  THE MOVE.\n",
      "\n",
      "\n",
      "Segment Start: 511687.3\n",
      "Actual Transcript: UM,\n",
      "Model Transcription:  UM\n",
      "\n",
      "\n",
      "Segment Start: 1978386.2999999998\n",
      "Actual Transcript: WAS POPULAR AMONG BOTH MEN AND WOMEN.\n",
      "Model Transcription:  WAS POPULAR AMONG BOTH MEN AND WOMEN.\n",
      "\n",
      "\n",
      "Segment Start: 44482.9\n",
      "Actual Transcript: WELL,\n",
      "Model Transcription:  WELL.\n",
      "\n",
      "\n",
      "Segment Start: 2492639.3\n",
      "Actual Transcript: READ OVER THAT\n",
      "Model Transcription:  READ OVER THAT.\n",
      "\n",
      "\n",
      "Segment Start: 1873535.5999999999\n",
      "Actual Transcript: THAT TITLE JOINT?\n",
      "Model Transcription:  GOOD, SORRY, I'LL JOIN.\n",
      "\n",
      "\n",
      "Segment Start: 1049083.1\n",
      "Actual Transcript: AND, UM,\n",
      "Model Transcription:  YOU KNOW\n",
      "\n",
      "\n",
      "Segment Start: 735506.4\n",
      "Actual Transcript: NIGGAS WASN'T GROWING UP WHEN TUPAC WAS LIKE OUT LIKE THAT.\n",
      "Model Transcription:  AND ANYONE WRONG WENT TOO PUDDLE WAS LIKE, HOW AM I BAD?\n",
      "\n",
      "\n",
      "Segment Start: 1019647.2999999999\n",
      "Actual Transcript: MM-HM.\n",
      "Model Transcription:  MM-HMM.\n",
      "\n",
      "\n",
      "Segment Start: 1990234.9\n",
      "Actual Transcript: STUFF.\n",
      "Model Transcription:  STUFF.\n",
      "\n",
      "\n",
      "Segment Start: 1532067.1\n",
      "Actual Transcript: YOU GOT A INTERESTING, UM,\n",
      "Model Transcription:  YOU GOT TO INTEREST IN...\n",
      "\n",
      "\n",
      "Segment Start: 2481364.4\n",
      "Actual Transcript: IT'S- THIS THE YOU- THIS THE WORLD.\n",
      "Model Transcription:  THIS IS THE WORLD.\n",
      "\n",
      "\n",
      "Segment Start: 1355427.1\n",
      "Actual Transcript: LIKE\n",
      "Model Transcription:  LIKE.\n",
      "\n",
      "\n",
      "Segment Start: 1932994.9\n",
      "Actual Transcript: HERE WE GO.\n",
      "Model Transcription:  GOOD.\n",
      "\n",
      "\n",
      "Segment Start: 65361.4\n",
      "Actual Transcript: OKAY.\n",
      "Model Transcription:  THANK YOU.\n",
      "\n",
      "\n",
      "Segment Start: 2154103.0999999996\n",
      "Actual Transcript: AIN'T NOTHING BECAUSE THE FEW BLACKS THAT GOT A LITTLE BIT OF MONEY,\n",
      "Model Transcription:  AIN'T NOTHING BECAUSE THE FEW BLACKS THAT GOT A LITTLE BIT OF MONEY.\n",
      "\n",
      "\n",
      "Segment Start: 1905185.3\n",
      "Actual Transcript: WELL, LOOK, UH, L-\n",
      "Model Transcription:  WELL, UH, UH...\n",
      "\n",
      "\n",
      "Segment Start: 214763.2\n",
      "Actual Transcript: MM-HM.\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 170258.4\n",
      "Actual Transcript: CAN'T REALLY LINK UP HOW YOU USED TO, BUT THAT DON'T MEAN WE NOT CLOSE.\n",
      "Model Transcription:  OKAY, READY, MAKE UP HOW YOU USED TO, BUT NOW MAYBE NOT CLOSE.\n",
      "\n",
      "\n",
      "Segment Start: 1035269.8\n",
      "Actual Transcript: BUT AT THE END OF THE DAY,\n",
      "Model Transcription:  BUT AT THE END OF THE DAY.\n",
      "\n",
      "\n",
      "Segment Start: 943069.6000000001\n",
      "Actual Transcript: EVERY NOW AND THEN CATCH SOME OLD-\n",
      "Model Transcription:  EVERY NIGHT IN KESSAMOLE.\n",
      "\n",
      "\n",
      "Segment Start: 1493597.2999999998\n",
      "Actual Transcript: SO.\n",
      "Model Transcription:  SO\n",
      "\n",
      "\n",
      "Segment Start: 2810030.4\n",
      "Actual Transcript: YEAH, THE DJ ALWAYS IMPORTANT, AND THE PRODUCER THOUGH\n",
      "Model Transcription:  THEY'RE THE DJ'S, I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-\n",
      "\n",
      "\n",
      "Segment Start: 565094.2999999999\n",
      "Actual Transcript: LIKE ARE WE TALKING ABOUT BIOLOGICAL?\n",
      "Model Transcription:  LIKE ARE WE TALKING ABOUT BIOLOGICAL?\n",
      "\n",
      "\n",
      "Segment Start: 825086.6\n",
      "Actual Transcript: THEY- YEAH, PEOPLE MIGHT THINK LIKE THEY'RE FAKE OR WHATEVER.\n",
      "Model Transcription:  THEY, YEAH, PEOPLE MIGHT THINK LIKE THEY'RE FAKE OR WHATEVER.\n",
      "\n",
      "\n",
      "Segment Start: 1077419.2\n",
      "Actual Transcript: LIKE SEVENTEEN OF HIS POINTS OR SOMETHING LIKE THAT, THEY CAME FROM THE FREE THROW LINE. HE DIDN'T HIT THOSE JUMPERS.\n",
      "Model Transcription:  LIKE, 17 OF HIS POINTS AND STUFF LIKE THAT, THAT CAME FROM THE FRITO LINE. HE DIDN'T HIT THOSE JUMPERS.\n",
      "\n",
      "\n",
      "Segment Start: 1614074.1\n",
      "Actual Transcript: MM-HM.\n",
      "Model Transcription:  MM-HMM.\n",
      "\n",
      "\n",
      "Segment Start: 363216.60000000003\n",
      "Actual Transcript: THINKING ABOUT?\n",
      "Model Transcription:  THANK YOU.\n",
      "\n",
      "\n",
      "Segment Start: 409956.1\n",
      "Actual Transcript: SO SAUCE,\n",
      "Model Transcription:  SO SAUCE.\n",
      "\n",
      "\n",
      "Segment Start: 2047582.7\n",
      "Actual Transcript: FOR MY ARTISTIC ABILITIES, AND THEY HAD ME IN RIVERDALE FOR LIKE\n",
      "Model Transcription:  FOR MY ARTISTIC ABILITIES AND I, ME AND RIVERDALE FOR LIKE.\n",
      "\n",
      "\n",
      "Segment Start: 643723.6\n",
      "Actual Transcript: A DRIVE.\n",
      "Model Transcription:  A DRIVE.\n",
      "\n",
      "\n",
      "Segment Start: 610539.7000000001\n",
      "Actual Transcript: I DON'T KNOW, EVERYBODY YOU SEE FOR-\n",
      "Model Transcription:  EVERYBODY YOU SEE FOR.\n",
      "\n",
      "\n",
      "Segment Start: 1691630.0\n",
      "Actual Transcript: UM,\n",
      "Model Transcription:  BYE.\n",
      "\n",
      "\n",
      "Segment Start: 494178.7\n",
      "Actual Transcript: OH WOW, OKAY.\n",
      "Model Transcription:  WOW, OKAY.\n",
      "\n",
      "\n",
      "Segment Start: 1422320.0999999999\n",
      "Actual Transcript: OKAY.\n",
      "Model Transcription:  OKAY.\n",
      "\n",
      "\n",
      "Segment Start: 568013.4\n",
      "Actual Transcript: AMIGOS, THEY- THEY- THEY PUT THEY WORK IN, YOU FEEL ME, SO, YOU KNOW WHAT I MEAN, I RESPECT IT, YOU FEEL ME. I AIN'T A HATER. I B- I RESPECT IT, YOU FEEL ME.\n",
      "Model Transcription:  AMIGO, THEY PUT THEIR WORK IN IT. YOU FEEL ME? SO, YOU KNOW WHAT I MEAN? I RESPECT IT. IF I AIN'T A HATE, I RESPECT IT.\n",
      "\n",
      "\n",
      "Segment Start: 263878.0\n",
      "Actual Transcript: THE EDUCATORS WOULD HAVE KIND OF\n",
      "Model Transcription:  THE EDUCATORS WOULD HAVE KIND OF\n",
      "\n",
      "\n",
      "Segment Start: 1909279.2999999998\n",
      "Actual Transcript: MM-HM.\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 101747.29999999999\n",
      "Actual Transcript: YOU KNOW, AND THEN-\n",
      "Model Transcription:  YOU KNOW, I THEN\n",
      "\n",
      "\n",
      "Segment Start: 590544.7000000001\n",
      "Actual Transcript: M- M-\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 1043435.7999999999\n",
      "Actual Transcript: WHEN SOME PEOPLE LOOK AT MY PLAYLIST, OR HEAR LIKE DIFFERENT THINGS, WHEN I'M DRIVING AROUND WITH THEM,\n",
      "Model Transcription:  WHEN SOME PEOPLE LOOK AT MY PLAYLIST OR HEAR LIKE DIFFERENT THINGS, WHEN I'M DRIVING AROUND WITH THEM.\n",
      "\n",
      "\n",
      "Segment Start: 2311855.3000000003\n",
      "Actual Transcript: OH.\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 1798451.0\n",
      "Actual Transcript: GOODIES BUT OLDIES.\n",
      "Model Transcription:  AT LEAST WITH ALLERGIES.\n",
      "\n",
      "\n",
      "Segment Start: 737120.9\n",
      "Actual Transcript: I CANNOT EVEN\n",
      "Model Transcription:  I CANNOT EVEN.\n",
      "\n",
      "\n",
      "Segment Start: 467211.1\n",
      "Actual Transcript: OKAY.\n",
      "Model Transcription:  OKAY.\n",
      "\n",
      "\n",
      "Segment Start: 2178253.7\n",
      "Actual Transcript: UH, THE BEST WAY TO GET RID OF 'EM\n",
      "Model Transcription:  THE BEST WAY TO GET RID OF THEM.\n",
      "\n",
      "\n",
      "Segment Start: 1910192.0\n",
      "Actual Transcript: YUP.\n",
      "Model Transcription:  YEAH.\n",
      "\n",
      "\n",
      "Segment Start: 1949603.4\n",
      "Actual Transcript: YOU'LL BE ABLE TO BUILD UP A TOLERANCE FOR IT, JUST LIKE PEOPLE SAY, OH I DON'T DRINK,\n",
      "Model Transcription:  YOU'LL BE ABLE TO BUILD A PHOTOGRAPHER. JUST LIKE PEOPLE SAY, OH, I DON'T DRINK.\n",
      "\n",
      "\n",
      "Segment Start: 1515647.8\n",
      "Actual Transcript: AND THEN SOME OF MY FRIENDS OUT HERE, THEY'RE FROM NEW YORK TOO, SO.\n",
      "Model Transcription:  AND THEN SOME OF MY FRIENDS OUT HERE THERE FROM NEW YORK TOO, SO.\n",
      "\n",
      "\n",
      "Segment Start: 123485.6\n",
      "Actual Transcript: AND I WAS LIKE,\n",
      "Model Transcription:  AND I WAS LIKE,\n",
      "\n",
      "\n",
      "Segment Start: 1983313.0\n",
      "Actual Transcript: NOPE.\n",
      "Model Transcription:  NOPE.\n",
      "\n",
      "\n",
      "Segment Start: 806222.4\n",
      "Actual Transcript: MM-HM.\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 1505063.5\n",
      "Actual Transcript: BUT THAT WAS BECAUSE I WAS IN A CATHOLIC SCHOOL, AND THEN SHE DECIDED TO CHANGE MY SCHOOL.\n",
      "Model Transcription:  BUT THAT WAS BECAUSE I WAS IN A CATHOLIC SCHOOL AND THEN SHE DECIDED TO CHANGE MY SCHOOL.\n",
      "\n",
      "\n",
      "Segment Start: 1072154.4\n",
      "Actual Transcript: WE DON'T REALLY DO NOTHING MAJOR L- OH, AND LIKE,\n",
      "Model Transcription:  WE DON'T REALLY DO NOTHING MAJOR AT ALL.\n",
      "\n",
      "\n",
      "Segment Start: 1849938.1\n",
      "Actual Transcript: OH,\n",
      "Model Transcription:  I'LL...\n",
      "\n",
      "\n",
      "Segment Start: 327564.7\n",
      "Actual Transcript: ABOUT YOUR RELATIONSHIP WITH YOUR FAMILY.\n",
      "Model Transcription:  ABOUT YOUR RELATIONSHIP WITH YOUR FAMILY.\n",
      "\n",
      "\n",
      "Segment Start: 1050167.8\n",
      "Actual Transcript: BEEN DRIPPING FOR A THOUSAND YEARS, AND NOW IT MADE THESE HUGE STALACTITES THAT'S IN THIS CAVE.\n",
      "Model Transcription:  BEEN DRIPPIN' FOR A THOUSAND YEARS AND I MADE THESE HUGE STALAG TIGHTS THAT'S IN THIS CAVE.\n",
      "\n",
      "\n",
      "Segment Start: 2134645.3000000003\n",
      "Actual Transcript: HOW MUCH MONEY WE SPEND WITH THE OTHER FOLKS BECAUSE EVENTUALLY WE WILL BE WIPED OUT.\n",
      "Model Transcription:  HOW MUCH MONEY WE SPEND WITH THE OTHER FOLKS BECAUSE EVENTUALLY WE WILL BE WIPED OUT.\n",
      "\n",
      "\n",
      "Segment Start: 715310.6\n",
      "Actual Transcript: ALL OUR GENERATION IS TWENTY-ONE.\n",
      "Model Transcription:  OUR LARGE GENERATION IS 21.\n",
      "\n",
      "\n",
      "Segment Start: 611925.7999999999\n",
      "Actual Transcript: I- I- I- IT'S- IT'S COMPETITION.\n",
      "Model Transcription:  IS COMPETITION.\n",
      "\n",
      "\n",
      "Segment Start: 1086787.7000000002\n",
      "Actual Transcript: SO ARE YOU TRYING TO, IN A SENSE,\n",
      "Model Transcription:  SO ARE YOU TRYING TO INNOCENCE?\n",
      "\n",
      "\n",
      "Segment Start: 476917.0\n",
      "Actual Transcript: FORTY KIDS IN A CLASSROOM.\n",
      "Model Transcription:  40 KEYS IN A GLASS ROOM.\n",
      "\n",
      "\n",
      "Segment Start: 118264.1\n",
      "Actual Transcript: YOU KNOW, THAT- JUST THAT-\n",
      "Model Transcription:  YOU KNOW THAT JUST THAT.\n",
      "\n",
      "\n",
      "Segment Start: 853098.1000000001\n",
      "Actual Transcript: AND IT'S\n",
      "Model Transcription:  AND THIS.\n",
      "\n",
      "\n",
      "Segment Start: 1804057.4\n",
      "Actual Transcript: SOMEWHAT.\n",
      "Model Transcription:  SOMEWHAT.\n",
      "\n",
      "\n",
      "Segment Start: 546235.1\n",
      "Actual Transcript: THREE BROTHERS, UH,\n",
      "Model Transcription:  THREE BROTHERS.\n",
      "\n",
      "\n",
      "Segment Start: 498623.8\n",
      "Actual Transcript: BUT\n",
      "Model Transcription:  WITH.\n",
      "\n",
      "\n",
      "Segment Start: 1841915.7\n",
      "Actual Transcript: PSH.\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 2096173.4999999998\n",
      "Actual Transcript: OTHER PLACES.\n",
      "Model Transcription:  OTHER PLACES.\n",
      "\n",
      "\n",
      "Segment Start: 69248.09999999999\n",
      "Actual Transcript: MM.\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 548366.1\n",
      "Actual Transcript: SO\n",
      "Model Transcription:  SO.\n",
      "\n",
      "\n",
      "Segment Start: 2276629.5\n",
      "Actual Transcript: I CAN'T DO THIS ANYMORE.\n",
      "Model Transcription:  I CAN'T DO THIS ANYMORE.\n",
      "\n",
      "\n",
      "Segment Start: 1526648.7\n",
      "Actual Transcript: ON?\n",
      "Model Transcription:  ON.\n",
      "\n",
      "\n",
      "Segment Start: 1301794.4\n",
      "Actual Transcript: AND LIKE\n",
      "Model Transcription:  AND LIGHT.\n",
      "\n",
      "\n",
      "Segment Start: 1789571.5\n",
      "Actual Transcript: I WASN'T REALLY INTO LIKE,\n",
      "Model Transcription:  I WASN'T REALLY INTO LIKE...\n",
      "\n",
      "\n",
      "Segment Start: 1043524.5\n",
      "Actual Transcript: ALL TYPES OF PEOPLE COME THROUGH THERE, YOU KNOW WHAT I'M SAYING, LIKE JUST RAPPERS, ARTISTS AND ALL TYPES OF SHIT. IT WAS A VERY PROMINENT BARBER SHOP AT THE TIME, AND I BELIEVE IT'S STILL IN EXISTENCE.\n",
      "Model Transcription:  ALL THE TYPES OF PEOPLE COME THROUGH THERE, YOU KNOW WHAT I'M SAYING? I EAT JUST RAPPERS, ARTISTS, AND ALL TYPES OF SHIT. IT WAS A VERY PROMINENT BARBERSHOP AT THE TIME, AND I BELIEVE THIS STILL IN EXISTENCE.\n",
      "\n",
      "\n",
      "Segment Start: 114580.8\n",
      "Actual Transcript: I MAKE POP MUSIC AND HIP HOP\n",
      "Model Transcription:  I MAKE POP MUSIC AND HIP HOP.\n",
      "\n",
      "\n",
      "Segment Start: 989904.4\n",
      "Actual Transcript: THUGGER,\n",
      "Model Transcription:  DR.\n",
      "\n",
      "\n",
      "Segment Start: 312103.2\n",
      "Actual Transcript: FOR REAL?\n",
      "Model Transcription:  FOR REAL.\n",
      "\n",
      "\n",
      "Segment Start: 466399.2\n",
      "Actual Transcript: UM, THERE WERE MORE JOBS HERE. SO THAT'S KIND OF REALLY W- IT W- IT- WHAT IT REALLY WAS.\n",
      "Model Transcription:  I'M NEVER MORE JOBS HERE, SO THAT'S KIND OF REALLY WHAT IT REALLY WAS.\n",
      "\n",
      "\n",
      "Segment Start: 1263814.1\n",
      "Actual Transcript: TATTOOS ON MY FACE, GOLDS IN MY MOUTH, SAGGING,\n",
      "Model Transcription:  TATTOOS OF MY FAKE GOALS AND MY MOUSE SAGGING.\n",
      "\n",
      "\n",
      "Segment Start: 1102461.3\n",
      "Actual Transcript: ESPECIALLY AS A YOUNG CHILD,\n",
      "Model Transcription:  ESPECIALLY AS A YOUNG CHILD.\n",
      "\n",
      "\n",
      "Segment Start: 534820.1\n",
      "Actual Transcript: I COULD EAT THAT BACON BACON BURGER\n",
      "Model Transcription:  I CAN EAT THAT BACON BACON BURGER.\n",
      "\n",
      "\n",
      "Segment Start: 226723.09999999998\n",
      "Actual Transcript: YEAH, DEFINITELY WAS A AGED SCHOOL.\n",
      "Model Transcription:  YEAH, DEFINITELY WAS AGE SCHOOL.\n",
      "\n",
      "\n",
      "Segment Start: 100556.29999999999\n",
      "Actual Transcript: BEEN UP NORTH, THEN YOU CAME DOWN SOUTH WITH IT, THAT'S COOL.\n",
      "Model Transcription:  AND I'M NORTH AND THEN CAME DOWN. SO THAT'S COOL.\n",
      "\n",
      "\n",
      "Segment Start: 823930.8999999999\n",
      "Actual Transcript: MAN, I'M REALLY SO LOST IN THE QUESTION. YOU SAID\n",
      "Model Transcription:  I'M REALLY SO LOST IN THE PLACE YOU SAID.\n",
      "\n",
      "\n",
      "Segment Start: 269356.60000000003\n",
      "Actual Transcript: GEEKY OR WHATEVER Y'ALL WANT TO CALL IT.\n",
      "Model Transcription:  GEEKY OR WHATEVER YOU WANT TO CALL IT.\n",
      "\n",
      "\n",
      "Segment Start: 666438.9\n",
      "Actual Transcript: NAH, COOL, COOL. ANY, UM, I GUESS GOOD-\n",
      "Model Transcription:  COOL, COOL, ANY, UM, I GUESS GOOD.\n",
      "\n",
      "\n",
      "Segment Start: 1177029.0999999999\n",
      "Actual Transcript: INDESTRUCTIBLE SHIP.\n",
      "Model Transcription:  INDESTRUCTIBLE SELF.\n",
      "\n",
      "\n",
      "Segment Start: 379003.6\n",
      "Actual Transcript: SO IT'S JUST LIKE, AS THE- AS-\n",
      "Model Transcription:  SO IT'S JUST LIKE AS...\n",
      "\n",
      "\n",
      "Segment Start: 909544.3\n",
      "Actual Transcript: TRADITIONS GROWING UP\n",
      "Model Transcription:  TRADITIONS GROWING UP.\n",
      "\n",
      "\n",
      "Segment Start: 1463562.2000000002\n",
      "Actual Transcript: SHORTY, YOU TRIPPING.\n",
      "Model Transcription:  SAUDI TRIVEN.\n",
      "\n",
      "\n",
      "Segment Start: 431729.6\n",
      "Actual Transcript: HOO.\n",
      "Model Transcription:  COOL.\n",
      "\n",
      "\n",
      "Segment Start: 1757394.2\n",
      "Actual Transcript: BRUH, LIKE\n",
      "Model Transcription:  LIKE...\n",
      "\n",
      "\n",
      "Segment Start: 176525.7\n",
      "Actual Transcript: HOO.\n",
      "Model Transcription:  OOH!\n",
      "\n",
      "\n",
      "Segment Start: 437991.6\n",
      "Actual Transcript: BUT,\n",
      "Model Transcription:  BUT.\n",
      "\n",
      "\n",
      "Segment Start: 2175607.9\n",
      "Actual Transcript: THREE MINUTES, THREE PERCENT, THREE MINUTES, NIGGA.\n",
      "Model Transcription:  THREE MINUTES, THREE PERCENT, THREE MINUTES, NIGGA.\n",
      "\n",
      "\n",
      "Segment Start: 1674196.6\n",
      "Actual Transcript: DAMN.\n",
      "Model Transcription:  DAMN.\n",
      "\n",
      "\n",
      "Segment Start: 1138341.1\n",
      "Actual Transcript: PERFECT WORD I WAS LOOKING-\n",
      "Model Transcription:  I WAS LOOKING FOR A FEW MORE HOURS.\n",
      "\n",
      "\n",
      "Segment Start: 470994.89999999997\n",
      "Actual Transcript: WASN'T NO SNOWBALL FIGHT.\n",
      "Model Transcription:  WASN'T NO SNOWBALL FIGHT.\n",
      "\n",
      "\n",
      "Segment Start: 1301871.1\n",
      "Actual Transcript: N-\n",
      "Model Transcription:  YOU\n",
      "\n",
      "\n",
      "Segment Start: 1626187.7\n",
      "Actual Transcript: IT'S GONNA HAPPEN. YOU GONNA SEE IT BECAUSE YOU'RE NOT GONNA GET WARNED\n",
      "Model Transcription:  IT'S GONNA HAPPEN. YOU'RE GONNA SEE IT BECAUSE YOU'RE NOT GONNA GET WARM.\n",
      "\n",
      "\n",
      "Segment Start: 912714.6\n",
      "Actual Transcript: HUH?\n",
      "Model Transcription:  HUH?\n",
      "\n",
      "\n",
      "Segment Start: 278389.9\n",
      "Actual Transcript: IT- IT HAS EVERYTHING TO DO WITH BEING BLACK, BUT\n",
      "Model Transcription:  IT HAS EVERYTHING TO DO WITH BEING BLACK, BUT.\n",
      "\n",
      "\n",
      "Segment Start: 536945.2999999999\n",
      "Actual Transcript: FELT LIKE\n",
      "Model Transcription:  GO, LIKE.\n",
      "\n",
      "\n",
      "Segment Start: 2355126.1\n",
      "Actual Transcript: OKAY.\n",
      "Model Transcription:  OKAY.\n",
      "\n",
      "\n",
      "Segment Start: 888743.2\n",
      "Actual Transcript: OKAY. WHY YOU- WHY YOU SAY USHER, IN PARTICULAR?\n",
      "Model Transcription:  OKAY, WHY YOU SAY US AND PARTICULARLY?\n",
      "\n",
      "\n",
      "Segment Start: 758165.1000000001\n",
      "Actual Transcript: SO IT'S JUST LIKE,\n",
      "Model Transcription:  SO IT WAS JUST LIKE...\n",
      "\n",
      "\n",
      "Segment Start: 1821128.0\n",
      "Actual Transcript: I JUST WENT HOME. SO I JUST NEVER WAS INTERESTED IN ANYTHING. I'M A REALLY CLINGER. I CLING TO MY MOM.\n",
      "Model Transcription:  I JUST WENT HOME SO I JUST NEVER WAS INTERESTED IN ANYTHING. I'M A REAL CLINGER. I'M A CLINGER. I'M A MOM.\n",
      "\n",
      "\n",
      "Segment Start: 2074293.5999999999\n",
      "Actual Transcript: WHAT WI-FI DOES TO THE BODY. IT CAUSES CANCER SO QUICK.\n",
      "Model Transcription:  WHAT WI-FI DOES TO THE BODY. IT CAUSES CANCER SO QUICK.\n",
      "\n",
      "\n",
      "Segment Start: 40122.5\n",
      "Actual Transcript: UM,\n",
      "Model Transcription:  UM\n",
      "\n",
      "\n",
      "Segment Start: 941365.9\n",
      "Actual Transcript: THEY DIDN'T TELL ME HOW LONG I WAS SUSPENDED. THEY JUST SAID DON'T COME BACK TO SCHOOL TIL WE SORT SHIT OUT.\n",
      "Model Transcription:  THEY DIDN'T TELL ME HOW LONG I WAS JUST FINISHED, SAID, DON'T COME BACK TO SCHOOL UNTIL WE SORT OF SHUT UP.\n",
      "\n",
      "\n",
      "Segment Start: 1922182.3\n",
      "Actual Transcript: YOU KNOW. IT'S ALL ABOUT CONSISTENCY I WOULD SAY, WHAT YOU STAY DOWN FOR.\n",
      "Model Transcription:  YOU KNOW, IT'S ALL ABOUT CONSISTENCY, I WOULD SAY, WHAT YOU STAY DOWN FOR.\n",
      "\n",
      "\n",
      "Segment Start: 1696138.5\n",
      "Actual Transcript: THAT SH- I AIN'T GONNA EVEN LIE, THAT SHIT WAS\n",
      "Model Transcription:  I'M GONNA BE RIGHT BACK WITH YOU.\n",
      "\n",
      "\n",
      "Segment Start: 1458872.0\n",
      "Actual Transcript: OKAY, IT'S LIKE-\n",
      "Model Transcription:  OKAY, IT'S LIKE...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists for metrics\n",
    "true_transcriptions = []\n",
    "predicted_transcriptions = []\n",
    "\n",
    "sample_rate = 44100\n",
    "\n",
    "# Process each segment and compare transcriptions\n",
    "for idx in range(len(audio_segments_subset_df)):\n",
    "    audio_tensor = audio_segments_subset_df['Segment'][idx]\n",
    "    actual_transcript = audio_segments_subset_df['Content'][idx]\n",
    "    \n",
    "    # Ensure audio is in the correct format\n",
    "    audio_tensor = preprocess_audio(audio_tensor, sample_rate)\n",
    "    \n",
    "    # Transcribe audio\n",
    "    model_transcription = transcribe_audio(audio_tensor, model, processor)\n",
    "    model_transcription = model_transcription.upper()\n",
    "    \n",
    "    # Store transcriptions for metric calculation\n",
    "    true_transcriptions.append(actual_transcript)\n",
    "    predicted_transcriptions.append(model_transcription)\n",
    "    \n",
    "    # Print segment info\n",
    "    print(f\"Segment Start: {audio_segments_subset_df['StTime'][idx]}\")\n",
    "    print(f\"Actual Transcript: {actual_transcript}\")\n",
    "    print(f\"Model Transcription: {model_transcription}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate (WER): 0.41649484536082476\n"
     ]
    }
   ],
   "source": [
    "wer_score = wer(true_transcriptions, predicted_transcriptions)\n",
    "print(f\"Word Error Rate (WER): {wer_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training `whisper-tiny` on CORAAL:ATL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, WhisperConfig, WhisperFeatureExtractor\n",
    "from jiwer import wer\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_mapping(transcript_dir, audio_dir):\n",
    "    # Create lists of transcript and audio file paths\n",
    "    transcript_paths = [os.path.join(transcript_dir, filename) for filename in os.listdir(transcript_dir) if filename.endswith('.txt')]\n",
    "    audio_paths = [os.path.join(audio_dir, filename) for filename in os.listdir(audio_dir) if filename.endswith('.wav')]\n",
    "\n",
    "    # Extract identifiers from filenames\n",
    "    transcript_ids = [os.path.splitext(os.path.basename(path))[0] for path in transcript_paths]\n",
    "    audio_ids = [os.path.splitext(os.path.basename(path))[0] for path in audio_paths]\n",
    "\n",
    "    # Create a dictionary to map identifiers to file paths\n",
    "    file_mapping = {\n",
    "        'Interview': [],\n",
    "        'Transcript Path': [],\n",
    "        'Audio Path': []\n",
    "    }\n",
    "\n",
    "    # Match transcript files with audio files using their identifiers\n",
    "    for transcript_id in transcript_ids:\n",
    "        if transcript_id in audio_ids:\n",
    "            transcript_path = os.path.join(transcript_dir, transcript_id + '.txt')\n",
    "            audio_path = os.path.join(audio_dir, transcript_id + '.wav')\n",
    "            file_mapping['Interview'].append(transcript_id)\n",
    "            file_mapping['Transcript Path'].append(transcript_path)\n",
    "            file_mapping['Audio Path'].append(audio_path)\n",
    "\n",
    "    # Create DataFrame from the file mapping dictionary\n",
    "    df = pd.DataFrame(file_mapping)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_transcripts(paths_df):\n",
    "    all_transcript_data = []\n",
    "\n",
    "    # Iterate over each row in the file_mapping_df\n",
    "    for _, row in paths_df.iterrows():\n",
    "        transcript_path = row['Transcript Path']\n",
    "        \n",
    "        # Load transcript data\n",
    "        transcript_df = pd.read_csv(transcript_path, delimiter=\"\\t\")\n",
    "        \n",
    "        # Extract relevant columns\n",
    "        transcript_data = transcript_df[['StTime', 'EnTime', 'Content']].copy()\n",
    "        \n",
    "        # Convert times from minutes to milliseconds for easier calculations\n",
    "        transcript_data['StTime'] *= 1000\n",
    "        transcript_data['EnTime'] *= 1000\n",
    "        transcript_data['Content'] = transcript_data['Content'].str.upper()\n",
    "        \n",
    "        # Add identifier column (optional)\n",
    "        transcript_data['Interview'] = row['Interview']\n",
    "\n",
    "        # Append to list\n",
    "        all_transcript_data.append(transcript_data)\n",
    "    \n",
    "    # Combine all transcript data into a single DataFrame\n",
    "    combined_transcript_df = pd.concat(all_transcript_data, ignore_index=True)\n",
    "    \n",
    "    return combined_transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "transcript_dir = '../data/coraal/transcript/text/'\n",
    "audio_dir = '../data/coraal/audio/wav/'\n",
    "\n",
    "paths_df = create_file_mapping(transcript_dir, audio_dir)\n",
    "combined_transcript_df = process_transcripts(paths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with unwanted characters in the 'Content' column\n",
    "pattern = r'[\\(\\)\\[\\]/<>]'\n",
    "filtered_transcript_df = combined_transcript_df[~combined_transcript_df['Content'].str.contains(pattern)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "# subset_size = int(len(filtered_transcript_df)*.20)\n",
    "# data_subset = filtered_transcript_df.sample(subset_size)\n",
    "data_subset = filtered_transcript_df.sample(250)\n",
    "print(len(data_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>Interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>2497451.9</td>\n",
       "      <td>2498142.3</td>\n",
       "      <td>AWESOME.</td>\n",
       "      <td>ATL_se0_ag2_f_02_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7067</th>\n",
       "      <td>1442971.0</td>\n",
       "      <td>1446815.2</td>\n",
       "      <td>FREEDOM, YOU KNOW WHAT I'M SAYING, KIND OF ENE...</td>\n",
       "      <td>ATL_se0_ag1_m_01_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4492</th>\n",
       "      <td>1803180.4</td>\n",
       "      <td>1805892.4</td>\n",
       "      <td>THEY JUST DON'T GET THAT RESPECT BECAUSE</td>\n",
       "      <td>ATL_se0_ag1_m_05_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>980297.7</td>\n",
       "      <td>981786.0</td>\n",
       "      <td>WHAT IT WAS IN THE PAST</td>\n",
       "      <td>ATL_se0_ag2_m_03_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6160</th>\n",
       "      <td>563491.7</td>\n",
       "      <td>563938.3</td>\n",
       "      <td>OKAY.</td>\n",
       "      <td>ATL_se0_ag1_f_03_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         StTime     EnTime                                            Content  \\\n",
       "864   2497451.9  2498142.3                                           AWESOME.   \n",
       "7067  1442971.0  1446815.2  FREEDOM, YOU KNOW WHAT I'M SAYING, KIND OF ENE...   \n",
       "4492  1803180.4  1805892.4           THEY JUST DON'T GET THAT RESPECT BECAUSE   \n",
       "2833   980297.7   981786.0                            WHAT IT WAS IN THE PAST   \n",
       "6160   563491.7   563938.3                                              OKAY.   \n",
       "\n",
       "               Interview  \n",
       "864   ATL_se0_ag2_f_02_1  \n",
       "7067  ATL_se0_ag1_m_01_1  \n",
       "4492  ATL_se0_ag1_m_05_1  \n",
       "2833  ATL_se0_ag2_m_03_1  \n",
       "6160  ATL_se0_ag1_f_03_1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(data_subset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, df, transcript_dir, audio_dir, processor, target_sample_rate=16000, target_length_ms=15000, padding_value=0):\n",
    "        \"\"\"\n",
    "        Audio Dataset with Padding for ASR tasks.\n",
    "\n",
    "        Parameters:\n",
    "        - df (pd.DataFrame): DataFrame containing the dataset information.\n",
    "        - transcript_dir (str): Directory containing transcript files.\n",
    "        - audio_dir (str): Directory containing audio files.\n",
    "        - processor: Processor for audio and text processing.\n",
    "        - target_sample_rate (int): Target sample rate for audio segments.\n",
    "        - target_length_ms (int): Target length for audio segments in milliseconds.\n",
    "        - padding_value (float): Value to use for padding audio segments.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.transcript_dir = transcript_dir\n",
    "        self.audio_dir = audio_dir\n",
    "        self.processor = processor\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.target_length_ms = target_length_ms\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        start_tm = row['StTime']\n",
    "        end_tm = row['EnTime']\n",
    "        content = row['Content']\n",
    "        interview = row['Interview']\n",
    "        audio_path = os.path.join(self.audio_dir, interview + '.wav')\n",
    "        \n",
    "        # Extract audio segment\n",
    "        audio_segment = self.extract_audio_segment(audio_path, start_tm, end_tm)\n",
    "        \n",
    "        # Preprocess audio segment\n",
    "        audio_tensor = self.processor(audio_segment.squeeze().numpy(), sampling_rate=self.target_sample_rate, return_tensors=\"pt\").input_features\n",
    "        \n",
    "        # Tokenize and pad transcription\n",
    "        encodings = self.processor.tokenizer(content, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=448)  # Adjust max_length as needed\n",
    "        labels = encodings.input_ids.squeeze()\n",
    "        attention_mask = encodings.attention_mask.squeeze()\n",
    "        \n",
    "        return {\n",
    "            'input_features': audio_tensor.squeeze(),\n",
    "            'labels': labels,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "    \n",
    "    def extract_audio_segment(self, audio_file_path, start_time_ms, end_time_ms):\n",
    "        \"\"\"\n",
    "        Extracts and pads a segment from an audio file based on start and end times.\n",
    "        \n",
    "        Parameters:\n",
    "        - audio_file_path (str): Path to the audio file.\n",
    "        - start_time_ms (int): Start time in milliseconds.\n",
    "        - end_time_ms (int): End time in milliseconds.\n",
    "        \n",
    "        Returns:\n",
    "        - torch.Tensor: Extracted and padded audio segment.\n",
    "        \"\"\"\n",
    "        # Load the audio file\n",
    "        waveform, sr = torchaudio.load(audio_file_path)\n",
    "        \n",
    "        # Convert milliseconds to sample indices\n",
    "        start_sample = int(start_time_ms * sr / 1000)\n",
    "        end_sample = int(end_time_ms * sr / 1000)\n",
    "        \n",
    "        # Extract the segment\n",
    "        segment = waveform[:, start_sample:end_sample]\n",
    "        \n",
    "        # Resample audio to target sample rate if necessary\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.target_sample_rate)\n",
    "            segment = resampler(segment)\n",
    "        \n",
    "        # Convert target length from milliseconds to samples\n",
    "        target_length_samples = int(self.target_length_ms * self.target_sample_rate / 1000)\n",
    "        \n",
    "        # Pad the segment\n",
    "        padded_segment = self.pad_audio_segment(segment, target_length_samples)\n",
    "        \n",
    "        return padded_segment\n",
    "    \n",
    "    def pad_audio_segment(self, segment, target_length, padding_value=0):\n",
    "        \"\"\"\n",
    "        Pads an audio segment to the target length.\n",
    "        \n",
    "        Parameters:\n",
    "        - segment (torch.Tensor): The audio segment to be padded.\n",
    "        - target_length (int): The desired length in samples.\n",
    "        - padding_value (float): The value to use for padding. Default is 0.\n",
    "        \n",
    "        Returns:\n",
    "        - torch.Tensor: Padded audio segment.\n",
    "        \"\"\"\n",
    "        current_length = segment.size(1)\n",
    "        if current_length < target_length:\n",
    "            padding_size = target_length - current_length\n",
    "            padding = torch.full((segment.size(0), padding_size), padding_value)\n",
    "            padded_segment = torch.cat((segment, padding), dim=1)\n",
    "        else:\n",
    "            padded_segment = segment[:, :target_length]  # Truncate if longer than target length\n",
    "        return padded_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processor and model\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "config = WhisperConfig.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = AudioDataset(train_df, transcript_dir, audio_dir, processor)\n",
    "test_dataset = AudioDataset(test_df, transcript_dir, audio_dir, processor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_loader, processor, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    true_transcriptions = []\n",
    "    predicted_transcriptions = []\n",
    "    \n",
    "    for batch in tqdm(train_loader, total=len(train_loader), desc='Training'):\n",
    "        inputs = batch['input_features'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_features=inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        outputs = model.generate(input_features=inputs)\n",
    "        transcriptions = processor.batch_decode(outputs, skip_special_tokens=True)\n",
    "        true_transcriptions.extend(processor.batch_decode(labels, skip_special_tokens=True))\n",
    "        predicted_transcriptions.extend(transcriptions)\n",
    "\n",
    "        predicted_transcriptions = [x.upper() for x in predicted_transcriptions]\n",
    "        wer_score = wer(true_transcriptions, predicted_transcriptions)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    total_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    return total_loss, wer_score\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, test_loader, processor, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    true_transcriptions = []\n",
    "    predicted_transcriptions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # for batch in tqdm(test_loader, total=len(test_loader), desc='Testing'):\n",
    "        for batch in test_loader:\n",
    "            inputs = batch['input_features'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_features=inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            outputs = model.generate(input_features=inputs)\n",
    "            transcriptions = processor.batch_decode(outputs, skip_special_tokens=True)\n",
    "            true_transcriptions.extend(processor.batch_decode(labels, skip_special_tokens=True))\n",
    "            predicted_transcriptions.extend(transcriptions)\n",
    "\n",
    "    total_loss = total_loss / len(train_loader)\n",
    "    predicted_transcriptions = [x.upper() for x in predicted_transcriptions]\n",
    "    wer_score = wer(true_transcriptions, predicted_transcriptions)\n",
    "    \n",
    "    return total_loss, wer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Training: 100%|| 25/25 [03:38<00:00,  8.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2713, WER: 0.4554\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 25/25 [03:39<00:00,  8.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1214, WER: 0.4536\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 25/25 [03:47<00:00,  9.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1208, WER: 0.4536\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 25/25 [03:48<00:00,  9.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1208, WER: 0.4536\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 25/25 [03:47<00:00,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1208, WER: 0.4536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    train_loss, train_wer = train(model, train_loader, processor, optimizer, scheduler, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}, WER: {train_wer:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0324, WER: 0.3930\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_wer = evaluate(model, test_loader, processor, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, WER: {test_wer:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_test = []\n",
    "for k in range(10):\n",
    "    test_loss, test_wer = evaluate(model, test_loader, processor, device)\n",
    "    k_test.append([k, test_loss, test_wer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_test_df = pd.DataFrame(k_test, columns=['k', 'Loss', 'Word Error Rate']).sort_values(by=\"Word Error Rate\", ascending=False).groupby('k')[:5]\n",
    "k_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-to-text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
