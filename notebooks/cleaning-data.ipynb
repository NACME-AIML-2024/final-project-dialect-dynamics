{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for coraal folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working on cleaning data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove all component details within the \"Content\" column in such a way that we only have text. \n",
    "1. Drop rows that contain anything different text. (Pauses, Actions, Unintelligble Speech)\n",
    "1. Remove punctuation marks from every row. (Removing \".\", \",\", \"'\", \"?\", etc.)\n",
    "1. Always keep the corresponding \"StTime\" and \"EnTime\".\n",
    "1. You can ommit/remove the \"Spkr\" \"Line\" or line columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Spkr</th>\n",
       "      <th>StTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>EnTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ATL_se0_ag1_f_01</td>\n",
       "      <td>0.4436</td>\n",
       "      <td>They talking about, don't send him to his daddy.</td>\n",
       "      <td>2.4068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ATL_se0_ag1_f_01</td>\n",
       "      <td>2.4068</td>\n",
       "      <td>(pause 0.28)</td>\n",
       "      <td>2.6829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ATL_se0_ag1_f_01</td>\n",
       "      <td>2.6829</td>\n",
       "      <td>You just need to go file for child support.</td>\n",
       "      <td>4.9538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>5.1142</td>\n",
       "      <td>[/Oh man/.]</td>\n",
       "      <td>5.6125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ATL_se0_ag1_f_01</td>\n",
       "      <td>5.1488</td>\n",
       "      <td>[Bye.]</td>\n",
       "      <td>5.5995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Line              Spkr  StTime  \\\n",
       "0     1  ATL_se0_ag1_f_01  0.4436   \n",
       "1     2  ATL_se0_ag1_f_01  2.4068   \n",
       "2     3  ATL_se0_ag1_f_01  2.6829   \n",
       "3     4        ATL_int_01  5.1142   \n",
       "4     5  ATL_se0_ag1_f_01  5.1488   \n",
       "\n",
       "                                            Content  EnTime  \n",
       "0  They talking about, don't send him to his daddy.  2.4068  \n",
       "1                                      (pause 0.28)  2.6829  \n",
       "2       You just need to go file for child support.  4.9538  \n",
       "3                                       [/Oh man/.]  5.6125  \n",
       "4                                            [Bye.]  5.5995  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_dir = \"../notebooks/coraal/transcript/text\"\n",
    "\n",
    "transcript_df = pd.read_csv(transcript_dir+\"/ATL_se0_ag1_f_01_1.txt\", delimiter=\"\\t\")\n",
    "transcript_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Spkr</th>\n",
       "      <th>StTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>EnTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ATL_se0_ag1_f_01</td>\n",
       "      <td>0.4436</td>\n",
       "      <td>They talking about, don't send him to his daddy.</td>\n",
       "      <td>2.4068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ATL_se0_ag1_f_01</td>\n",
       "      <td>2.4068</td>\n",
       "      <td>(pause 0.28)</td>\n",
       "      <td>2.6829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ATL_se0_ag1_f_01</td>\n",
       "      <td>2.6829</td>\n",
       "      <td>You just need to go file for child support.</td>\n",
       "      <td>4.9538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>5.1142</td>\n",
       "      <td>[/Oh man/.]</td>\n",
       "      <td>5.6125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ATL_se0_ag1_f_01</td>\n",
       "      <td>5.1488</td>\n",
       "      <td>[Bye.]</td>\n",
       "      <td>5.5995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>1229</td>\n",
       "      <td>ATL_se0_ag1_f_01</td>\n",
       "      <td>1855.6029</td>\n",
       "      <td>[Wanna] play?</td>\n",
       "      <td>1856.1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>1230</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>1855.8262</td>\n",
       "      <td>[Hm.]</td>\n",
       "      <td>1856.1798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>1231</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>1856.3473</td>\n",
       "      <td>Yeah let me- let me see it.</td>\n",
       "      <td>1857.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1232</td>\n",
       "      <td>ATL_se0_ag1_f_01</td>\n",
       "      <td>1858.3942</td>\n",
       "      <td>Your phone dead.</td>\n",
       "      <td>1859.3929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>1233</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>1859.4177</td>\n",
       "      <td>My phone all the way- it- And the charger righ...</td>\n",
       "      <td>1862.4884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Line              Spkr     StTime  \\\n",
       "0        1  ATL_se0_ag1_f_01     0.4436   \n",
       "1        2  ATL_se0_ag1_f_01     2.4068   \n",
       "2        3  ATL_se0_ag1_f_01     2.6829   \n",
       "3        4        ATL_int_01     5.1142   \n",
       "4        5  ATL_se0_ag1_f_01     5.1488   \n",
       "...    ...               ...        ...   \n",
       "1228  1229  ATL_se0_ag1_f_01  1855.6029   \n",
       "1229  1230        ATL_int_01  1855.8262   \n",
       "1230  1231        ATL_int_01  1856.3473   \n",
       "1231  1232  ATL_se0_ag1_f_01  1858.3942   \n",
       "1232  1233        ATL_int_01  1859.4177   \n",
       "\n",
       "                                                Content     EnTime  \n",
       "0      They talking about, don't send him to his daddy.     2.4068  \n",
       "1                                          (pause 0.28)     2.6829  \n",
       "2           You just need to go file for child support.     4.9538  \n",
       "3                                           [/Oh man/.]     5.6125  \n",
       "4                                                [Bye.]     5.5995  \n",
       "...                                                 ...        ...  \n",
       "1228                                      [Wanna] play?  1856.1984  \n",
       "1229                                              [Hm.]  1856.1798  \n",
       "1230                        Yeah let me- let me see it.  1857.6250  \n",
       "1231                                   Your phone dead.  1859.3929  \n",
       "1232  My phone all the way- it- And the charger righ...  1862.4884  \n",
       "\n",
       "[1233 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaing df of unwanted data on a copy df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# droped rows with [], ect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StTime  EnTime                                 CleanedContent\n",
      "0  0.4436  2.4068  They talking about dont send him to his daddy\n",
      "1  2.4068  2.6829                                      pause 028\n",
      "2  2.6829  4.9538     You just need to go file for child support\n",
      "5  6.0026  6.3944                                            Why\n",
      "6  6.3944  7.1901                                      pause 080\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# # Load your original DataFrame\n",
    "# transcript_dir = \"../notebooks/coraal/transcript/text\"\n",
    "# transcript_df = pd.read_csv(transcript_dir + \"/ATL_se0_ag1_f_01_1.txt\", delimiter=\"\\t\")\n",
    "\n",
    "# Create a copy of the original DataFrame to avoid corruption\n",
    "cleaned_df = transcript_df.copy()\n",
    "\n",
    "# Function to clean the \"Content\" column\n",
    "def clean_content(content):\n",
    "    # Remove anything within [ … ], / … /, and < … >\n",
    "    content = re.sub(r'\\[.*?\\]|\\<.*?\\>|\\/.*?\\/', '', content)\n",
    "    # Remove punctuation marks\n",
    "    content = re.sub(r'[^\\w\\s]', '', content)\n",
    "    # Strip leading and trailing whitespaces\n",
    "    content = content.strip()\n",
    "    return content\n",
    "\n",
    "# Apply the cleaning function to the \"Content\" column\n",
    "cleaned_df['CleanedContent'] = cleaned_df['Content'].apply(clean_content)\n",
    "\n",
    "# Drop rows where \"CleanedContent\" is empty after cleaning\n",
    "cleaned_df = cleaned_df[cleaned_df['CleanedContent'] != '']\n",
    "\n",
    "# Keep only the \"StTime\", \"EnTime\", and \"CleanedContent\" columns\n",
    "final_df = cleaned_df[['StTime', 'EnTime', 'CleanedContent']]\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# removed rows still containg pause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StTime  EnTime                                 CleanedContent\n",
      "0  0.4436  2.4068  They talking about dont send him to his daddy\n",
      "2  2.6829  4.9538     You just need to go file for child support\n",
      "5  6.0026  6.3944                                            Why\n",
      "7  7.1901  7.5398                                            Why\n",
      "8  8.6665  9.7375                           Okay whats your name\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# # Load your original DataFrame\n",
    "# transcript_dir = \"../notebooks/coraal/transcript/text\"\n",
    "# transcript_df = pd.read_csv(transcript_dir + \"/ATL_se0_ag1_f_01_1.txt\", delimiter=\"\\t\")\n",
    "\n",
    "# # Create a copy of the original DataFrame to avoid corruption\n",
    "# cleaned_df = transcript_df.copy()\n",
    "\n",
    "# Function to clean the \"Content\" column\n",
    "def clean_content(content):\n",
    "    # Remove anything within [ … ], / … /, and < … >\n",
    "    content = re.sub(r'\\[.*?\\]|\\<.*?\\>|\\/.*?\\/', '', content)\n",
    "    # Remove punctuation marks\n",
    "    content = re.sub(r'[^\\w\\s]', '', content)\n",
    "    # Strip leading and trailing whitespaces\n",
    "    content = content.strip()\n",
    "    return content\n",
    "\n",
    "# Apply the cleaning function to the \"Content\" column\n",
    "cleaned_df['CleanedContent'] = cleaned_df['Content'].apply(clean_content)\n",
    "\n",
    "# Drop rows where \"CleanedContent\" is empty after cleaning\n",
    "cleaned_df = cleaned_df[cleaned_df['CleanedContent'] != '']\n",
    "\n",
    "# Remove rows containing the word \"pause\" in \"CleanedContent\"\n",
    "cleaned_df = cleaned_df[~cleaned_df['CleanedContent'].str.contains(r'\\bpause\\b', case=False, na=False)]\n",
    "\n",
    "# Keep only the \"StTime\", \"EnTime\", and \"CleanedContent\" columns\n",
    "final_df = cleaned_df[['StTime', 'EnTime', 'CleanedContent']]\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fixing index misorder after row deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StTime  EnTime                                 CleanedContent\n",
      "0  0.4436  2.4068  They talking about dont send him to his daddy\n",
      "1  2.6829  4.9538     You just need to go file for child support\n",
      "2  6.0026  6.3944                                            Why\n",
      "3  7.1901  7.5398                                            Why\n",
      "4  8.6665  9.7375                           Okay whats your name\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# # Load your original DataFrame\n",
    "# transcript_dir = \"../notebooks/coraal/transcript/text\"\n",
    "# transcript_df = pd.read_csv(transcript_dir + \"/ATL_se0_ag1_f_01_1.txt\", delimiter=\"\\t\")\n",
    "\n",
    "# # Create a copy of the original DataFrame to avoid corruption\n",
    "# cleaned_df = transcript_df.copy()\n",
    "\n",
    "# Function to clean the \"Content\" column\n",
    "def clean_content(content):\n",
    "    # Remove anything within [ … ], / … /, and < … >\n",
    "    content = re.sub(r'\\[.*?\\]|\\<.*?\\>|\\/.*?\\/', '', content)\n",
    "    # Remove punctuation marks\n",
    "    content = re.sub(r'[^\\w\\s]', '', content)\n",
    "    # Strip leading and trailing whitespaces\n",
    "    content = content.strip()\n",
    "    return content\n",
    "\n",
    "# Apply the cleaning function to the \"Content\" column\n",
    "cleaned_df['CleanedContent'] = cleaned_df['Content'].apply(clean_content)\n",
    "\n",
    "# Drop rows where \"CleanedContent\" is empty after cleaning\n",
    "cleaned_df = cleaned_df[cleaned_df['CleanedContent'] != '']\n",
    "\n",
    "# Remove rows containing the word \"pause\" in \"CleanedContent\"\n",
    "cleaned_df = cleaned_df[~cleaned_df['CleanedContent'].str.contains(r'\\bpause\\b', case=False, na=False)]\n",
    "\n",
    "# Keep only the \"StTime\", \"EnTime\", and \"CleanedContent\" columns\n",
    "final_df = cleaned_df[['StTime', 'EnTime', 'CleanedContent']]\n",
    "\n",
    "# Reset the index of the cleaned DataFrame\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleeaned df keeping puncuations and droping rows of Special symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StTime  EnTime                                           Content\n",
      "0  0.4436  2.4068  They talking about, don't send him to his daddy.\n",
      "1  2.6829  4.9538       You just need to go file for child support.\n",
      "2  6.0026  6.3944                                              Why?\n",
      "3  7.1901  7.5398                                              Why?\n",
      "4  8.6665  9.7375                           Okay, what's your name?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# # Load your original DataFrame\n",
    "# transcript_dir = \"../notebooks/coraal/transcript/text\"\n",
    "# transcript_df = pd.read_csv(transcript_dir + \"/ATL_se0_ag1_f_01_1.txt\", delimiter=\"\\t\")\n",
    "\n",
    "# # Create a copy of the original DataFrame to avoid corruption\n",
    "# cleaned_df = transcript_df.copy()\n",
    "\n",
    "# Function to check for unwanted patterns in the \"Content\" column\n",
    "def contains_unwanted_patterns(content):\n",
    "    patterns = [r'\\[.*?\\]', r'\\<.*?\\>', r'\\/.*?\\/', r'\\(.*?\\)']\n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, content):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Apply the function to filter rows with unwanted patterns\n",
    "cleaned_df = cleaned_df[~cleaned_df['Content'].apply(contains_unwanted_patterns)]\n",
    "\n",
    "# Remove rows where \"Content\" is empty after removing unwanted patterns\n",
    "cleaned_df = cleaned_df[cleaned_df['Content'].str.strip() != '']\n",
    "\n",
    "# Remove rows containing the word \"pause\" in \"Content\"\n",
    "cleaned_df = cleaned_df[~cleaned_df['Content'].str.contains(r'\\bpause\\b', case=False, na=False)]\n",
    "\n",
    "# Keep only the \"StTime\", \"EnTime\", and \"Content\" columns\n",
    "final_df = cleaned_df[['StTime', 'EnTime', 'Content']]\n",
    "\n",
    "# Reset the index of the cleaned DataFrame\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking df of clean vs not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           They talking about dont send him to his daddy\n",
       "1                                               pause 028\n",
       "2              You just need to go file for child support\n",
       "5                                                     Why\n",
       "6                                               pause 080\n",
       "                              ...                        \n",
       "1227                             the um Game Pigeon games\n",
       "1228                                                 play\n",
       "1230                            Yeah let me let me see it\n",
       "1231                                      Your phone dead\n",
       "1232    My phone all the way it And the charger right ...\n",
       "Name: CleanedContent, Length: 1014, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['CleanedContent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           They talking about dont send him to his daddy\n",
       "2              You just need to go file for child support\n",
       "5                                                     Why\n",
       "7                                                     Why\n",
       "8                                    Okay whats your name\n",
       "                              ...                        \n",
       "1227                             the um Game Pigeon games\n",
       "1228                                                 play\n",
       "1230                            Yeah let me let me see it\n",
       "1231                                      Your phone dead\n",
       "1232    My phone all the way it And the charger right ...\n",
       "Name: CleanedContent, Length: 669, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['CleanedContent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          They talking about dont send him to his daddy\n",
       "1             You just need to go file for child support\n",
       "2                                                    Why\n",
       "3                                                    Why\n",
       "4                                   Okay whats your name\n",
       "                             ...                        \n",
       "664                             the um Game Pigeon games\n",
       "665                                                 play\n",
       "666                            Yeah let me let me see it\n",
       "667                                      Your phone dead\n",
       "668    My phone all the way it And the charger right ...\n",
       "Name: CleanedContent, Length: 669, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['CleanedContent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['CleanedContent'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1233"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "transcript_df['Content'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       They talking about, don't send him to his daddy.\n",
       "1            You just need to go file for child support.\n",
       "2                                                   Why?\n",
       "3                                                   Why?\n",
       "4                                Okay, what's your name?\n",
       "                             ...                        \n",
       "488       Oh. What kind of games you play on your phone?\n",
       "489                                                 Psh.\n",
       "490                          Yeah let me- let me see it.\n",
       "491                                     Your phone dead.\n",
       "492    My phone all the way- it- And the charger righ...\n",
       "Name: Content, Length: 493, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['Content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at different samples for missed cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329    Aint gonna lie I was like oh man I forgot how ...\n",
       "104                                         whos younger\n",
       "93                                     No thats for real\n",
       "573                       Yeah thats all I could say too\n",
       "66                                  I have four brothers\n",
       "437                                               Im not\n",
       "314    you can ak you cant ask them about that Like t...\n",
       "195                                               So  um\n",
       "450                                    Nah that was real\n",
       "57                                              You know\n",
       "Name: CleanedContent, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['CleanedContent'].sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      669\n",
       "unique     601\n",
       "top       Okay\n",
       "freq        14\n",
       "Name: CleanedContent, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['CleanedContent'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465    never experienced. And then y'all bring like, ...\n",
       "251    Really all of them joints the same for real fo...\n",
       "134                                    with that friend?\n",
       "90                                                   I'm\n",
       "270                                             Okay, so\n",
       "321                                         Alright bro.\n",
       "272                                   seventy-two cents?\n",
       "39                                              And, uh,\n",
       "186                                        whoever else.\n",
       "247                                                Yeah.\n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df dropping rows containing special symbols from documentation and keeping puncuations \n",
    "# sampling to see if df was cleaned to desired parameters\n",
    "final_df['Content'].sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of new df dropping rows with special symbols and keeping puncuations\n",
    "final_df['Content'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StTime</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4436</td>\n",
       "      <td>2.4068</td>\n",
       "      <td>They talking about, don't send him to his daddy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.6829</td>\n",
       "      <td>4.9538</td>\n",
       "      <td>You just need to go file for child support.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0026</td>\n",
       "      <td>6.3944</td>\n",
       "      <td>Why?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.1901</td>\n",
       "      <td>7.5398</td>\n",
       "      <td>Why?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.6665</td>\n",
       "      <td>9.7375</td>\n",
       "      <td>Okay, what's your name?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>1839.6002</td>\n",
       "      <td>1841.3867</td>\n",
       "      <td>Oh. What kind of games you play on your phone?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1841.9157</td>\n",
       "      <td>1842.7283</td>\n",
       "      <td>Psh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1856.3473</td>\n",
       "      <td>1857.6250</td>\n",
       "      <td>Yeah let me- let me see it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1858.3942</td>\n",
       "      <td>1859.3929</td>\n",
       "      <td>Your phone dead.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1859.4177</td>\n",
       "      <td>1862.4884</td>\n",
       "      <td>My phone all the way- it- And the charger righ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        StTime     EnTime                                            Content\n",
       "0       0.4436     2.4068   They talking about, don't send him to his daddy.\n",
       "1       2.6829     4.9538        You just need to go file for child support.\n",
       "2       6.0026     6.3944                                               Why?\n",
       "3       7.1901     7.5398                                               Why?\n",
       "4       8.6665     9.7375                            Okay, what's your name?\n",
       "..         ...        ...                                                ...\n",
       "488  1839.6002  1841.3867     Oh. What kind of games you play on your phone?\n",
       "489  1841.9157  1842.7283                                               Psh.\n",
       "490  1856.3473  1857.6250                        Yeah let me- let me see it.\n",
       "491  1858.3942  1859.3929                                   Your phone dead.\n",
       "492  1859.4177  1862.4884  My phone all the way- it- And the charger righ...\n",
       "\n",
       "[493 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (1014,), (0,))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m final_df[\u001b[43mfinal_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCleanedContent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m]\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml3/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml3/lib/python3.11/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml3/lib/python3.11/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:321\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, (np\u001b[38;5;241m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# TODO: make this treatment consistent across ops and classes.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m#  We are not catching all listlikes here (e.g. frozenset, tuple)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m#  The ambiguous case is object-dtype.  See GH#27803\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lvalues) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(rvalues):\n\u001b[0;32m--> 321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    322\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths must match to compare\u001b[39m\u001b[38;5;124m\"\u001b[39m, lvalues\u001b[38;5;241m.\u001b[39mshape, rvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    323\u001b[0m         )\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    326\u001b[0m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    328\u001b[0m ):\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m op(lvalues, rvalues)\n",
      "\u001b[0;31mValueError\u001b[0m: ('Lengths must match to compare', (1014,), (0,))"
     ]
    }
   ],
   "source": [
    "# error not used now just tests\n",
    "final_df[final_df['CleanedContent'] == []].sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corral dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now adding wave and audio paths to data frame and combining them with their respective transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting path to all transcripts in corral folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../notebooks/coraal/transcript/text/ATL_se0_ag2_f_02_1.txt',\n",
       " '../notebooks/coraal/transcript/text/ATL_se0_ag2_m_02_1.txt',\n",
       " '../notebooks/coraal/transcript/text/ATL_se0_ag2_f_01_1.txt',\n",
       " '../notebooks/coraal/transcript/text/ATL_se0_ag2_m_03_1.txt',\n",
       " '../notebooks/coraal/transcript/text/ATL_se0_ag2_m_01_1.txt',\n",
       " '../notebooks/coraal/transcript/text/ATL_se0_ag1_m_05_1.txt',\n",
       " '../notebooks/coraal/transcript/text/ATL_se0_ag1_m_03_1.txt',\n",
       " '../notebooks/coraal/transcript/text/ATL_se0_ag1_f_01_1.txt',\n",
       " '../notebooks/coraal/transcript/text/ATL_se0_ag1_f_03_1.txt',\n",
       " '../notebooks/coraal/transcript/text/ATL_se0_ag1_m_01_1.txt',\n",
       " '../notebooks/coraal/transcript/text/ATL_se0_ag1_m_04_2.txt',\n",
       " '../notebooks/coraal/transcript/text/ATL_se0_ag1_m_04_1.txt',\n",
       " '../notebooks/coraal/transcript/text/ATL_se0_ag1_f_02_1.txt',\n",
       " '../notebooks/coraal/transcript/text/ATL_se0_ag1_m_02_1.txt']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the path to your directory\n",
    "transcript_dir = '../notebooks/coraal/transcript/text'\n",
    "\n",
    "# Create a list of file paths\n",
    "transcript_paths = [os.path.join(transcript_dir, filename) for filename in os.listdir(transcript_dir) if filename.endswith('.txt')]\n",
    "transcript_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting paths to all .wav files in coraal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02_1.wav',\n",
       " '../notebooks/coraal/audio/wav/ATL_se0_ag2_f_02_1.wav',\n",
       " '../notebooks/coraal/audio/wav/ATL_se0_ag2_m_01_1.wav',\n",
       " '../notebooks/coraal/audio/wav/ATL_se0_ag2_f_01_1.wav',\n",
       " '../notebooks/coraal/audio/wav/ATL_se0_ag2_m_03_1.wav',\n",
       " '../notebooks/coraal/audio/wav/ATL_se0_ag1_m_05_1.wav',\n",
       " '../notebooks/coraal/audio/wav/ATL_se0_ag1_f_03_1.wav',\n",
       " '../notebooks/coraal/audio/wav/ATL_se0_ag1_m_01_1.wav',\n",
       " '../notebooks/coraal/audio/wav/ATL_se0_ag1_m_03_1.wav',\n",
       " '../notebooks/coraal/audio/wav/ATL_se0_ag1_f_01_1.wav',\n",
       " '../notebooks/coraal/audio/wav/ATL_se0_ag1_m_04_1.wav',\n",
       " '../notebooks/coraal/audio/wav/ATL_se0_ag1_m_04_2.wav',\n",
       " '../notebooks/coraal/audio/wav/ATL_se0_ag1_m_02_1.wav',\n",
       " '../notebooks/coraal/audio/wav/ATL_se0_ag1_f_02_1.wav']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the path to your directory\n",
    "audio_directory = '../notebooks/coraal/audio/wav'\n",
    "\n",
    "# Create a list of file paths\n",
    "audio_paths = [os.path.join(audio_directory, filename) for filename in os.listdir(audio_directory) if filename.endswith('.wav')]\n",
    "audio_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Spkr</th>\n",
       "      <th>StTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Transcript Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>Hey what's going on?</td>\n",
       "      <td>2.5113</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>2.5113</td>\n",
       "      <td>(pause 0.63)</td>\n",
       "      <td>3.1447</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>3.1447</td>\n",
       "      <td>I'm here with</td>\n",
       "      <td>4.1659</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>4.1659</td>\n",
       "      <td>(pause 0.92)</td>\n",
       "      <td>5.0830</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>5.0830</td>\n",
       "      <td>/RD-NAME-2/.</td>\n",
       "      <td>5.8536</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Line        Spkr  StTime               Content  EnTime  \\\n",
       "0     1  ATL_int_01  0.7526  Hey what's going on?  2.5113   \n",
       "1     2  ATL_int_01  2.5113          (pause 0.63)  3.1447   \n",
       "2     3  ATL_int_01  3.1447         I'm here with  4.1659   \n",
       "3     4  ATL_int_01  4.1659          (pause 0.92)  5.0830   \n",
       "4     5  ATL_int_01  5.0830          /RD-NAME-2/.  5.8536   \n",
       "\n",
       "                                     Transcript Path  \n",
       "0  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
       "1  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
       "2  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
       "3  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
       "4  ../notebooks/coraal/transcript/text/ATL_se0_ag...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transcript_properties(filepath):\n",
    "    df = pd.read_csv(filepath, delimiter=\"\\t\", index_col=\"Line\")\n",
    "    df['Transcript Path'] = filepath\n",
    "    return df\n",
    "\n",
    "# List to hold individual DataFrames\n",
    "transcript_df = []\n",
    "\n",
    "# Iterate through each file path, read the DataFrame, and append it to the list\n",
    "for path in transcript_paths:\n",
    "    transcript_df.append(transcript_properties(path))\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "transcript_df = pd.concat(transcript_df).reset_index()\n",
    "\n",
    "# Display the combined DataFrame\n",
    "transcript_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143022"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning before transcript goes into process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Line              Spkr   StTime               Content   EnTime  \\\n",
      "0     1        ATL_int_01   0.7526  Hey what's going on?   2.5113   \n",
      "1     3        ATL_int_01   3.1447         I'm here with   4.1659   \n",
      "2    11        ATL_int_01  10.5346            say hello.  11.2899   \n",
      "3    12  ATL_se0_ag2_f_02  12.1424                Hello.  12.8462   \n",
      "4    13        ATL_int_01  13.4581                 Okay,  13.9629   \n",
      "\n",
      "                                     Transcript Path  \n",
      "0  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
      "1  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
      "2  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
      "3  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
      "4  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# # Load your original DataFrame\n",
    "# transcript_dir = \"../notebooks/coraal/transcript/text\"\n",
    "# transcript_df = pd.read_csv(transcript_dir + \"/ATL_se0_ag1_f_01_1.txt\", delimiter=\"\\t\")\n",
    "\n",
    "# # Create a copy of the original DataFrame to avoid corruption\n",
    "# cleaned_df2 = transcript_df.copy() # swap merged_df and transcript_df\n",
    "\n",
    "# Function to check for unwanted patterns in the \"Content\" column\n",
    "def contains_unwanted_patterns(content):\n",
    "    patterns = [r'\\[.*?\\]', r'\\<.*?\\>', r'\\/.*?\\/', r'\\(.*?\\)']\n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, content):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Apply the function to filter rows with unwanted patterns\n",
    "transcript_df = transcript_df[~transcript_df['Content'].apply(contains_unwanted_patterns)]\n",
    "\n",
    "# Remove rows where \"Content\" is empty after removing unwanted patterns\n",
    "transcript_df = transcript_df[transcript_df['Content'].str.strip() != '']\n",
    "\n",
    "# Remove rows containing the word \"pause\" in \"Content\"\n",
    "#cleaned_df2 = cleaned_df2[~cleaned_df['Content'].str.contains(r'\\bpause\\b', case=False, na=False)] # commented bc dataframe got empty for merge_df above\n",
    "\n",
    "# Keep only the \"StTime\", \"EnTime\", and \"Content\" columns\n",
    "# final_df2 = cleaned_df2#[['StTime', 'EnTime', 'Content']] commented out bc wanted to keep coulmns made already\n",
    "\n",
    "# Reset the index of the cleaned DataFrame\n",
    "transcript_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(transcript_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59838"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# return to sebastian code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_to_tensors(audio_path, interval=30):\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    total_length = waveform.size(1) / sample_rate  # in seconds\n",
    "    num_chunks = int(np.ceil(total_length / interval))\n",
    "    \n",
    "    tensors = []\n",
    "    start_times = []\n",
    "    end_times = []\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        start = int(i * interval * sample_rate)\n",
    "        end = int(min((i + 1) * interval * sample_rate, waveform.size(1)))\n",
    "        chunk_waveform = waveform[:, start:end]\n",
    "        tensors.append(chunk_waveform)\n",
    "        start_times.append(start / sample_rate)\n",
    "        end_times.append(end / sample_rate)\n",
    "    \n",
    "    return tensors, start_times, end_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_transcript(transcript_df, interval=30):\n",
    "    transcript_df['StTime'] = pd.to_timedelta(transcript_df['StTime'], unit='s')\n",
    "    transcript_df['EnTime'] = pd.to_timedelta(transcript_df['EnTime'], unit='s')\n",
    "    \n",
    "    new_rows = []\n",
    "    current_content = []\n",
    "    current_start_time = pd.to_timedelta(0, unit='s')\n",
    "    current_end_time = pd.to_timedelta(interval, unit='s')\n",
    "    \n",
    "    for _, row in transcript_df.iterrows():\n",
    "        start_time = row['StTime']\n",
    "        end_time = row['EnTime']\n",
    "        content = row['Content']\n",
    "        \n",
    "        if start_time >= current_end_time:\n",
    "            # Save the current chunk\n",
    "            new_rows.append({\n",
    "                'Content': ' '.join(current_content),\n",
    "                'Start Time': current_start_time.total_seconds(),\n",
    "                'End Time': current_end_time.total_seconds()\n",
    "            })\n",
    "            # Reset for the next chunk\n",
    "            current_content = []\n",
    "            current_start_time = current_end_time\n",
    "            current_end_time += pd.to_timedelta(interval, unit='s')\n",
    "        \n",
    "        current_content.append(content)\n",
    "    \n",
    "    # Add the last chunk\n",
    "    if current_content:\n",
    "        new_rows.append({\n",
    "            'Content': ' '.join(current_content),\n",
    "            'Start Time': current_start_time.total_seconds(),\n",
    "            'End Time': current_end_time.total_seconds()\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(new_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small subset of data\n",
    "def load_small_subset(transcript_path, audio_path, num_rows=120):\n",
    "    # Load transcript data\n",
    "    transcript_df = pd.read_csv(transcript_path, delimiter='\\t')\n",
    "    \n",
    "    # Select a subset of rows\n",
    "    transcript_subset = transcript_df.head(num_rows).copy()\n",
    "\n",
    "    # Load audio data\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    \n",
    "    return transcript_subset, waveform, sample_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# back for testing cleaning data for desired results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code changed for processing no punc and all caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Line              Spkr  StTime                    Content  EnTime\n",
      "0     1        ATL_int_01  0.8713  CAN YOU TELL ME YOUR NAME  1.9540\n",
      "1     2  ATL_se0_ag2_m_02  2.9491                         UH  3.8242\n",
      "2     4  ATL_se0_ag2_m_02  5.1544                        THE  5.4122\n",
      "3     6  ATL_se0_ag2_m_02  6.1185                I WAS NAMED  7.1703\n",
      "4     8  ATL_se0_ag2_m_02  7.9334          BY THE GOVERNMENT  9.8462\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Audio Tensor</th>\n",
       "      <th>Audio Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAN YOU TELL ME YOUR NAME UH THE I WAS NAMED B...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>[[tensor(-6.1035e-05), tensor(-3.0518e-05), te...</td>\n",
       "      <td>../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHAT DO YOU IDENTIFY E ETHNICALLY ETHNICITYWIS...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>[[tensor(-0.0110), tensor(-0.0120), tensor(-0....</td>\n",
       "      <td>../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THATS WHERE I MAINLY WENT TO SCHOOL COOL COOL ...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[[tensor(0.0081), tensor(0.0074), tensor(0.006...</td>\n",
       "      <td>../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UM THINK I LIVED IN NEW YORK FOR A WHILE IN BR...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>[[tensor(0.0004), tensor(0.0005), tensor(0.000...</td>\n",
       "      <td>../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AND OR SONGWRITER AND PRODUCER</td>\n",
       "      <td>120.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>[[tensor(0.0158), tensor(0.0150), tensor(0.014...</td>\n",
       "      <td>../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Start Time  End Time  \\\n",
       "0  CAN YOU TELL ME YOUR NAME UH THE I WAS NAMED B...         0.0      30.0   \n",
       "1  WHAT DO YOU IDENTIFY E ETHNICALLY ETHNICITYWIS...        30.0      60.0   \n",
       "2  THATS WHERE I MAINLY WENT TO SCHOOL COOL COOL ...        60.0      90.0   \n",
       "3  UM THINK I LIVED IN NEW YORK FOR A WHILE IN BR...        90.0     120.0   \n",
       "4                     AND OR SONGWRITER AND PRODUCER       120.0     150.0   \n",
       "\n",
       "                                        Audio Tensor  \\\n",
       "0  [[tensor(-6.1035e-05), tensor(-3.0518e-05), te...   \n",
       "1  [[tensor(-0.0110), tensor(-0.0120), tensor(-0....   \n",
       "2  [[tensor(0.0081), tensor(0.0074), tensor(0.006...   \n",
       "3  [[tensor(0.0004), tensor(0.0005), tensor(0.000...   \n",
       "4  [[tensor(0.0158), tensor(0.0150), tensor(0.014...   \n",
       "\n",
       "                                          Audio Path  \n",
       "0  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...  \n",
       "1  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...  \n",
       "2  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...  \n",
       "3  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...  \n",
       "4  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a small subset of data for demonstration\n",
    "transcript_path = '../notebooks/coraal/transcript/text/ATL_se0_ag2_m_02_1.txt'  # Replace with your transcript file path\n",
    "audio_path = '../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02_1.wav'  # Replace with your audio file path\n",
    "\n",
    "# Process data\n",
    "transcript_df_subset, waveform, sample_rate = load_small_subset(transcript_path, audio_path, num_rows=120)\n",
    "tensors, start_times, end_times = split_audio_to_tensors(audio_path, interval=30)\n",
    "\n",
    "# Create DataFrame for audio chunks\n",
    "audio_data_subset = pd.DataFrame({\n",
    "    'Audio Tensor': tensors,\n",
    "    'Start Time': start_times,\n",
    "    'End Time': end_times,\n",
    "    'Audio Path': [audio_path] * len(tensors)\n",
    "})\n",
    "\n",
    "###############\n",
    "# samuel found that after this line is when the column gets turned into intervals of 30 secs and the trans_df is unchanged before this step\n",
    "# only change to sebastian code\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# # Load your original DataFrame\n",
    "# transcript_dir = \"../notebooks/coraal/transcript/text\"\n",
    "# transcript_df = pd.read_csv(transcript_dir + \"/ATL_se0_ag1_f_01_1.txt\", delimiter=\"\\t\")\n",
    "# marker for code change\n",
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# # Load your original DataFrame\n",
    "# transcript_dir = \"../notebooks/coraal/transcript/text\"\n",
    "# transcript_df = pd.read_csv(transcript_dir + \"/ATL_se0_ag1_f_01_1.txt\", delimiter=\"\\t\")\n",
    "\n",
    "# Create a copy of the original DataFrame to avoid corruption\n",
    "cleaned_df6 = transcript_df_subset.copy()\n",
    "\n",
    "# Function to clean the \"Content\" column\n",
    "def clean_content(content):\n",
    "    # Remove anything within [ … ], / … /, < … >, and ( … )\n",
    "    content = re.sub(r'\\[.*?\\]|\\<.*?\\>|\\/.*?\\/|\\(.*?\\)', '', content)\n",
    "    # Remove special symbols while keeping punctuation marks\n",
    "    content = re.sub(r'[^a-zA-Z0-9\\s]', '', content)\n",
    "    # Capitalize all text\n",
    "    content = content.upper()\n",
    "    # Strip leading and trailing whitespaces\n",
    "    content = content.strip()\n",
    "    return content\n",
    "\n",
    "# Apply the cleaning function to the \"Content\" column\n",
    "cleaned_df6['Content'] = cleaned_df6['Content'].apply(clean_content)\n",
    "\n",
    "# Remove rows where \"Content\" is empty after removing unwanted patterns\n",
    "cleaned_df6 = cleaned_df6[cleaned_df6['Content'].str.strip() != '']\n",
    "\n",
    "# Keep the \"StTime\", \"EnTime\", and \"CleanedContent\" columns\n",
    "final_df6 = cleaned_df6#[['StTime', 'EnTime', 'Content']]\n",
    "\n",
    "# Reset the index of the cleaned DataFrame\n",
    "final_df6.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(final_df6.head())\n",
    "\n",
    "############\n",
    "# comment everything below to not get a df of 5 rows\n",
    "\n",
    "# Process the transcript subset\n",
    "final_df6 = split_transcript(final_df6, interval=30)\n",
    "# transcript_df_subset                  transcript_df_subset subsituted with final_df6\n",
    "# Merge DataFrames\n",
    "audio_data_subset['Start Time'] = audio_data_subset['Start Time'].apply(lambda x: round(x, 2))\n",
    "audio_data_subset['End Time'] = audio_data_subset['End Time'].apply(lambda x: round(x, 2))\n",
    "final_df6['Start Time'] = final_df6['Start Time'].apply(lambda x: round(x, 2))\n",
    "final_df6['End Time'] = final_df6['End Time'].apply(lambda x: round(x, 2))\n",
    "\n",
    "merged_df = pd.merge_asof(final_df6.sort_values('Start Time'),\n",
    "                            audio_data_subset.sort_values('Start Time'),\n",
    "                            on='Start Time', direction='backward')\n",
    "\n",
    "# Drop redundant columns\n",
    "merged_df = merged_df.drop(columns=['End Time_y'])\n",
    "merged_df = merged_df.rename(columns={'End Time_x': 'End Time'})\n",
    "\n",
    "#Display the merged DataFrame\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end of code for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Can you tell me your name? the- I was named Ok...\n",
       "1    what do you identify e- ethnically, ethnicity-...\n",
       "2    That's where I mainly went to school, Cool, co...\n",
       "3    Um, think- I lived in New York for a while in ...\n",
       "4                      and or songwriter and producer.\n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Audio Tensor</th>\n",
       "      <th>Audio Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you tell me your name? the- I was named Ok...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>[[tensor(-6.1035e-05), tensor(-3.0518e-05), te...</td>\n",
       "      <td>../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what do you identify e- ethnically, ethnicity-...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>[[tensor(-0.0110), tensor(-0.0120), tensor(-0....</td>\n",
       "      <td>../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That's where I mainly went to school, Cool, co...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[[tensor(0.0081), tensor(0.0074), tensor(0.006...</td>\n",
       "      <td>../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Um, think- I lived in New York for a while in ...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>[[tensor(0.0004), tensor(0.0005), tensor(0.000...</td>\n",
       "      <td>../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and or songwriter and producer.</td>\n",
       "      <td>120.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>[[tensor(0.0158), tensor(0.0150), tensor(0.014...</td>\n",
       "      <td>../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Start Time  End Time  \\\n",
       "0  Can you tell me your name? the- I was named Ok...         0.0      30.0   \n",
       "1  what do you identify e- ethnically, ethnicity-...        30.0      60.0   \n",
       "2  That's where I mainly went to school, Cool, co...        60.0      90.0   \n",
       "3  Um, think- I lived in New York for a while in ...        90.0     120.0   \n",
       "4                    and or songwriter and producer.       120.0     150.0   \n",
       "\n",
       "                                        Audio Tensor  \\\n",
       "0  [[tensor(-6.1035e-05), tensor(-3.0518e-05), te...   \n",
       "1  [[tensor(-0.0110), tensor(-0.0120), tensor(-0....   \n",
       "2  [[tensor(0.0081), tensor(0.0074), tensor(0.006...   \n",
       "3  [[tensor(0.0004), tensor(0.0005), tensor(0.000...   \n",
       "4  [[tensor(0.0158), tensor(0.0150), tensor(0.014...   \n",
       "\n",
       "                                          Audio Path  \n",
       "0  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...  \n",
       "1  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...  \n",
       "2  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...  \n",
       "3  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...  \n",
       "4  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Spkr</th>\n",
       "      <th>StTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>EnTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>0.8713</td>\n",
       "      <td>Can you tell me your name?</td>\n",
       "      <td>1.9540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>5.1544</td>\n",
       "      <td>the-</td>\n",
       "      <td>5.4122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>6.1185</td>\n",
       "      <td>I was named</td>\n",
       "      <td>7.1703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>10.3501</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>10.6955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>10.7316</td>\n",
       "      <td>Um, but I've renamed myself</td>\n",
       "      <td>12.6395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>114</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>114.6238</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>114.8764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>115</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>116.0468</td>\n",
       "      <td>Um,</td>\n",
       "      <td>116.7274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>117</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>117.7468</td>\n",
       "      <td>occupation?</td>\n",
       "      <td>118.5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>118</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>118.9894</td>\n",
       "      <td>Uh, I'm a professional musician</td>\n",
       "      <td>120.9589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>120</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>121.4694</td>\n",
       "      <td>and or songwriter and producer.</td>\n",
       "      <td>123.2172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Line              Spkr    StTime                          Content  \\\n",
       "0      1        ATL_int_01    0.8713       Can you tell me your name?   \n",
       "1      4  ATL_se0_ag2_m_02    5.1544                             the-   \n",
       "2      6  ATL_se0_ag2_m_02    6.1185                      I was named   \n",
       "3      9        ATL_int_01   10.3501                            Okay.   \n",
       "4     10  ATL_se0_ag2_m_02   10.7316      Um, but I've renamed myself   \n",
       "..   ...               ...       ...                              ...   \n",
       "58   114  ATL_se0_ag2_m_02  114.6238                            Yeah.   \n",
       "59   115        ATL_int_01  116.0468                              Um,   \n",
       "60   117        ATL_int_01  117.7468                      occupation?   \n",
       "61   118  ATL_se0_ag2_m_02  118.9894  Uh, I'm a professional musician   \n",
       "62   120  ATL_se0_ag2_m_02  121.4694  and or songwriter and producer.   \n",
       "\n",
       "      EnTime  \n",
       "0     1.9540  \n",
       "1     5.4122  \n",
       "2     7.1703  \n",
       "3    10.6955  \n",
       "4    12.6395  \n",
       "..       ...  \n",
       "58  114.8764  \n",
       "59  116.7274  \n",
       "60  118.5460  \n",
       "61  120.9589  \n",
       "62  123.2172  \n",
       "\n",
       "[63 rows x 5 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding in capitilzation and removing puncuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Spkr</th>\n",
       "      <th>StTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>EnTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>0.8713</td>\n",
       "      <td>CAN YOU TELL ME YOUR NAME</td>\n",
       "      <td>1.9540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>2.9491</td>\n",
       "      <td>UH</td>\n",
       "      <td>3.8242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>5.1544</td>\n",
       "      <td>THE</td>\n",
       "      <td>5.4122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>6.1185</td>\n",
       "      <td>I WAS NAMED</td>\n",
       "      <td>7.1703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>7.9334</td>\n",
       "      <td>BY THE GOVERNMENT</td>\n",
       "      <td>9.8462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>114</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>114.6238</td>\n",
       "      <td>YEAH</td>\n",
       "      <td>114.8764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>115</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>116.0468</td>\n",
       "      <td>UM</td>\n",
       "      <td>116.7274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>117</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>117.7468</td>\n",
       "      <td>OCCUPATION</td>\n",
       "      <td>118.5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>118</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>118.9894</td>\n",
       "      <td>UH IM A PROFESSIONAL MUSICIAN</td>\n",
       "      <td>120.9589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>120</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>121.4694</td>\n",
       "      <td>AND OR SONGWRITER AND PRODUCER</td>\n",
       "      <td>123.2172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Line              Spkr    StTime                         Content    EnTime\n",
       "0      1        ATL_int_01    0.8713       CAN YOU TELL ME YOUR NAME    1.9540\n",
       "1      2  ATL_se0_ag2_m_02    2.9491                              UH    3.8242\n",
       "2      4  ATL_se0_ag2_m_02    5.1544                             THE    5.4122\n",
       "3      6  ATL_se0_ag2_m_02    6.1185                     I WAS NAMED    7.1703\n",
       "4      8  ATL_se0_ag2_m_02    7.9334               BY THE GOVERNMENT    9.8462\n",
       "..   ...               ...       ...                             ...       ...\n",
       "62   114  ATL_se0_ag2_m_02  114.6238                            YEAH  114.8764\n",
       "63   115        ATL_int_01  116.0468                              UM  116.7274\n",
       "64   117        ATL_int_01  117.7468                      OCCUPATION  118.5460\n",
       "65   118  ATL_se0_ag2_m_02  118.9894   UH IM A PROFESSIONAL MUSICIAN  120.9589\n",
       "66   120  ATL_se0_ag2_m_02  121.4694  AND OR SONGWRITER AND PRODUCER  123.2172\n",
       "\n",
       "[67 rows x 5 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Spkr</th>\n",
       "      <th>StTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>EnTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>0.8713</td>\n",
       "      <td>Can you tell me your name?</td>\n",
       "      <td>1.9540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>2.9491</td>\n",
       "      <td>Uh, (breathy)</td>\n",
       "      <td>3.8242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>3.8242</td>\n",
       "      <td>(pause 1.33)</td>\n",
       "      <td>5.1544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>5.1544</td>\n",
       "      <td>the-</td>\n",
       "      <td>5.4122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>5.4122</td>\n",
       "      <td>(pause 0.71)</td>\n",
       "      <td>6.1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>116</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>116.7274</td>\n",
       "      <td>(pause 1.02)</td>\n",
       "      <td>117.7468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>117.7468</td>\n",
       "      <td>occupation?</td>\n",
       "      <td>118.5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>118</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>118.9894</td>\n",
       "      <td>Uh, I'm a professional musician</td>\n",
       "      <td>120.9589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>119</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>120.9589</td>\n",
       "      <td>(pause 0.51)</td>\n",
       "      <td>121.4694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>120</td>\n",
       "      <td>ATL_se0_ag2_m_02</td>\n",
       "      <td>121.4694</td>\n",
       "      <td>and or songwriter and producer.</td>\n",
       "      <td>123.2172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Line              Spkr    StTime                          Content  \\\n",
       "0       1        ATL_int_01    0.8713       Can you tell me your name?   \n",
       "1       2  ATL_se0_ag2_m_02    2.9491                    Uh, (breathy)   \n",
       "2       3  ATL_se0_ag2_m_02    3.8242                     (pause 1.33)   \n",
       "3       4  ATL_se0_ag2_m_02    5.1544                             the-   \n",
       "4       5  ATL_se0_ag2_m_02    5.4122                     (pause 0.71)   \n",
       "..    ...               ...       ...                              ...   \n",
       "115   116        ATL_int_01  116.7274                     (pause 1.02)   \n",
       "116   117        ATL_int_01  117.7468                      occupation?   \n",
       "117   118  ATL_se0_ag2_m_02  118.9894  Uh, I'm a professional musician   \n",
       "118   119  ATL_se0_ag2_m_02  120.9589                     (pause 0.51)   \n",
       "119   120  ATL_se0_ag2_m_02  121.4694  and or songwriter and producer.   \n",
       "\n",
       "       EnTime  \n",
       "0      1.9540  \n",
       "1      3.8242  \n",
       "2      5.1544  \n",
       "3      5.4122  \n",
       "4      6.1185  \n",
       "..        ...  \n",
       "115  117.7468  \n",
       "116  118.5460  \n",
       "117  120.9589  \n",
       "118  121.4694  \n",
       "119  123.2172  \n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/k355m06x52vd4ypck1wz5nzh0000gp/T/ipykernel_33946/1449465836.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  cleaned_df1 = cleaned_df1[cleaned_df['CleanedContent'] != '']\n"
     ]
    },
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m cleaned_df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleanedContent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cleaned_df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(clean_content)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Drop rows where \"CleanedContent\" is empty after cleaning\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m cleaned_df1 \u001b[38;5;241m=\u001b[39m \u001b[43mcleaned_df1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcleaned_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCleanedContent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Remove rows containing the word \"pause\" in \"CleanedContent\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m cleaned_df1 \u001b[38;5;241m=\u001b[39m cleaned_df1[\u001b[38;5;241m~\u001b[39mcleaned_df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleanedContent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbpause\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml3/lib/python3.11/site-packages/pandas/core/frame.py:4093\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 4093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4095\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   4096\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   4097\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml3/lib/python3.11/site-packages/pandas/core/frame.py:4149\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem wrong length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(key)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4145\u001b[0m     )\n\u001b[1;32m   4147\u001b[0m \u001b[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[1;32m   4148\u001b[0m \u001b[38;5;66;03m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[0;32m-> 4149\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m   4152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml3/lib/python3.11/site-packages/pandas/core/indexing.py:2662\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2660\u001b[0m indexer \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_indexer_for(index)\n\u001b[1;32m   2661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01min\u001b[39;00m indexer:\n\u001b[0;32m-> 2662\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\n\u001b[1;32m   2663\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnalignable boolean Series provided as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2664\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexer (index of the boolean Series and of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2665\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe indexed object do not match).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2666\u001b[0m     )\n\u001b[1;32m   2668\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   2670\u001b[0m \u001b[38;5;66;03m# fall through for boolean\u001b[39;00m\n",
      "\u001b[0;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "# Create a copy of the original DataFrame to avoid corruption\n",
    "cleaned_df1 = merged_df.copy()\n",
    "\n",
    "\n",
    "# Function to clean the \"Content\" column\n",
    "def clean_content(content):\n",
    "    # Remove anything within [ … ], / … /, and < … >\n",
    "    content = re.sub(r'\\[.*?\\]|\\<.*?\\>|\\/.*?\\/', '', content)\n",
    "    # Remove punctuation marks\n",
    "    content = re.sub(r'[^\\w\\s]', '', content)\n",
    "    # Strip leading and trailing whitespaces\n",
    "    content = content.strip()\n",
    "    return content\n",
    "\n",
    "# Apply the cleaning function to the \"Content\" column\n",
    "cleaned_df1['CleanedContent'] = cleaned_df1['Content'].apply(clean_content)\n",
    "\n",
    "# Drop rows where \"CleanedContent\" is empty after cleaning\n",
    "cleaned_df1 = cleaned_df1[cleaned_df['CleanedContent'] != '']\n",
    "\n",
    "# Remove rows containing the word \"pause\" in \"CleanedContent\"\n",
    "cleaned_df1 = cleaned_df1[~cleaned_df1['CleanedContent'].str.contains(r'\\bpause\\b', case=False, na=False)]\n",
    "\n",
    "# Keep only the \"StTime\", \"EnTime\", and \"CleanedContent\" columns\n",
    "final_df1 = cleaned_df1[['StTime', 'EnTime', 'CleanedContent']]\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(final_df1.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaned dataframe too much for merge so using transcript df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Line              Spkr   StTime               Content   EnTime  \\\n",
      "0     1        ATL_int_01   0.7526  Hey what's going on?   2.5113   \n",
      "1     3        ATL_int_01   3.1447         I'm here with   4.1659   \n",
      "2    11        ATL_int_01  10.5346            say hello.  11.2899   \n",
      "3    12  ATL_se0_ag2_f_02  12.1424                Hello.  12.8462   \n",
      "4    13        ATL_int_01  13.4581                 Okay,  13.9629   \n",
      "\n",
      "                                     Transcript Path  \n",
      "0  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
      "1  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
      "2  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
      "3  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
      "4  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# # Load your original DataFrame\n",
    "# transcript_dir = \"../notebooks/coraal/transcript/text\"\n",
    "# transcript_df = pd.read_csv(transcript_dir + \"/ATL_se0_ag1_f_01_1.txt\", delimiter=\"\\t\")\n",
    "\n",
    "# # Create a copy of the original DataFrame to avoid corruption\n",
    "cleaned_df2 = transcript_df.copy() # swap merged_df and transcript_df\n",
    "\n",
    "# Function to check for unwanted patterns in the \"Content\" column\n",
    "def contains_unwanted_patterns(content):\n",
    "    patterns = [r'\\[.*?\\]', r'\\<.*?\\>', r'\\/.*?\\/', r'\\(.*?\\)']\n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, content):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Apply the function to filter rows with unwanted patterns\n",
    "cleaned_df2 = cleaned_df2[~cleaned_df2['Content'].apply(contains_unwanted_patterns)]\n",
    "\n",
    "# Remove rows where \"Content\" is empty after removing unwanted patterns\n",
    "cleaned_df2 = cleaned_df2[cleaned_df2['Content'].str.strip() != '']\n",
    "\n",
    "# Remove rows containing the word \"pause\" in \"Content\"\n",
    "#cleaned_df2 = cleaned_df2[~cleaned_df['Content'].str.contains(r'\\bpause\\b', case=False, na=False)] # commented bc dataframe got empty for merge_df above\n",
    "\n",
    "# Keep only the \"StTime\", \"EnTime\", and \"Content\" columns\n",
    "final_df2 = cleaned_df2#[['StTime', 'EnTime', 'Content']] commented out bc wanted to keep coulmns made already\n",
    "\n",
    "# Reset the index of the cleaned DataFrame\n",
    "final_df2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(final_df2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Spkr</th>\n",
       "      <th>StTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>EnTime</th>\n",
       "      <th>Transcript Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>Hey what's going on?</td>\n",
       "      <td>2.5113</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>3.1447</td>\n",
       "      <td>I'm here with</td>\n",
       "      <td>4.1659</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>10.5346</td>\n",
       "      <td>say hello.</td>\n",
       "      <td>11.2899</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>ATL_se0_ag2_f_02</td>\n",
       "      <td>12.1424</td>\n",
       "      <td>Hello.</td>\n",
       "      <td>12.8462</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>13.4581</td>\n",
       "      <td>Okay,</td>\n",
       "      <td>13.9629</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9968</th>\n",
       "      <td>2198</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>2421.2731</td>\n",
       "      <td>everything. I'm excited</td>\n",
       "      <td>2422.9474</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9969</th>\n",
       "      <td>2200</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>2423.3031</td>\n",
       "      <td>about your future.</td>\n",
       "      <td>2424.3962</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>2202</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>2425.0819</td>\n",
       "      <td>Definitely gonna</td>\n",
       "      <td>2425.8604</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>2205</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>2429.0196</td>\n",
       "      <td>and, um,</td>\n",
       "      <td>2429.6589</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>2209</td>\n",
       "      <td>ATL_int_01</td>\n",
       "      <td>2433.1133</td>\n",
       "      <td>I'm signing off. This is a wrap.</td>\n",
       "      <td>2434.6288</td>\n",
       "      <td>../notebooks/coraal/transcript/text/ATL_se0_ag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9973 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Line              Spkr     StTime                           Content  \\\n",
       "0        1        ATL_int_01     0.7526              Hey what's going on?   \n",
       "1        3        ATL_int_01     3.1447                     I'm here with   \n",
       "2       11        ATL_int_01    10.5346                        say hello.   \n",
       "3       12  ATL_se0_ag2_f_02    12.1424                            Hello.   \n",
       "4       13        ATL_int_01    13.4581                             Okay,   \n",
       "...    ...               ...        ...                               ...   \n",
       "9968  2198        ATL_int_01  2421.2731           everything. I'm excited   \n",
       "9969  2200        ATL_int_01  2423.3031                about your future.   \n",
       "9970  2202        ATL_int_01  2425.0819                  Definitely gonna   \n",
       "9971  2205        ATL_int_01  2429.0196                          and, um,   \n",
       "9972  2209        ATL_int_01  2433.1133  I'm signing off. This is a wrap.   \n",
       "\n",
       "         EnTime                                    Transcript Path  \n",
       "0        2.5113  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
       "1        4.1659  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
       "2       11.2899  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
       "3       12.8462  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
       "4       13.9629  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
       "...         ...                                                ...  \n",
       "9968  2422.9474  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
       "9969  2424.3962  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
       "9970  2425.8604  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
       "9971  2429.6589  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
       "9972  2434.6288  ../notebooks/coraal/transcript/text/ATL_se0_ag...  \n",
       "\n",
       "[9973 rows x 6 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9087                                            one word,\n",
       "9838                                                 that\n",
       "9536                                   I love good music.\n",
       "1290                                                i- i-\n",
       "8356                      since the day she was born that\n",
       "5177                                                Damn.\n",
       "1185                              sports was the way out.\n",
       "9689                      And they don't- they don't even\n",
       "5838    Get rid of the school debts, or some shit like...\n",
       "4880                 and just, this is how it planned out\n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df2['Content'].sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diffrent kind of cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### still didnt change even though data was cleaned before hand. need to clean at the end of merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Content  Start Time  End Time  \\\n",
      "0  Can you tell me your name? Uh, (breathy) (paus...         0.0      30.0   \n",
      "1  (pause 0.12) what do you identify e- (pause 0....        30.0      60.0   \n",
      "2  (pause 0.31) That's where I mainly went to sch...        60.0      90.0   \n",
      "3  Um, (pause 0.37) <ts> (pause 0.40) think- I li...        90.0     120.0   \n",
      "4       (pause 0.51) and or songwriter and producer.       120.0     150.0   \n",
      "\n",
      "                                        Audio Tensor  \\\n",
      "0  [[tensor(-6.1035e-05), tensor(-3.0518e-05), te...   \n",
      "1  [[tensor(-0.0110), tensor(-0.0120), tensor(-0....   \n",
      "2  [[tensor(0.0081), tensor(0.0074), tensor(0.006...   \n",
      "3  [[tensor(0.0004), tensor(0.0005), tensor(0.000...   \n",
      "4  [[tensor(0.0158), tensor(0.0150), tensor(0.014...   \n",
      "\n",
      "                                          Audio Path  \\\n",
      "0  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...   \n",
      "1  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...   \n",
      "2  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...   \n",
      "3  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...   \n",
      "4  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...   \n",
      "\n",
      "                                      CleanedContent  \n",
      "0  Can you tell me your name Uh breathy pause 133...  \n",
      "1  pause 012 what do you identify e pause 045 eth...  \n",
      "2  pause 031 Thats where I mainly went to school ...  \n",
      "3  Um pause 037  pause 040 think I lived in New Y...  \n",
      "4           pause 051 and or songwriter and producer  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# # Load your original DataFrame\n",
    "# transcript_dir = \"../notebooks/coraal/transcript/text\"\n",
    "# transcript_df = pd.read_csv(transcript_dir + \"/ATL_se0_ag1_f_01_1.txt\", delimiter=\"\\t\")\n",
    "\n",
    "# Create a copy of the original DataFrame to avoid corruption\n",
    "cleaned_df3 = merged_df.copy()\n",
    "\n",
    "# Function to clean the \"Content\" column\n",
    "def clean_content(content):\n",
    "    # Remove anything within [ … ], / … /, and < … >\n",
    "    content = re.sub(r'\\[.*?\\]|\\<.*?\\>|\\/.*?\\/', '', content)\n",
    "    # Remove punctuation marks\n",
    "    content = re.sub(r'[^\\w\\s]', '', content)\n",
    "    # Strip leading and trailing whitespaces\n",
    "    content = content.strip()\n",
    "    return content\n",
    "\n",
    "# Apply the cleaning function to the \"Content\" column\n",
    "cleaned_df3['CleanedContent'] = cleaned_df3['Content'].apply(clean_content)\n",
    "\n",
    "# Drop rows where \"CleanedContent\" is empty after cleaning\n",
    "cleaned_df3 = cleaned_df3[cleaned_df3['CleanedContent'] != '']\n",
    "\n",
    "# Keep only the \"StTime\", \"EnTime\", and \"CleanedContent\" columns\n",
    "final_df3 = cleaned_df3#[['StTime', 'EnTime', 'CleanedContent']]\n",
    "\n",
    "# Reset the index of the cleaned DataFrame\n",
    "final_df3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(final_df3.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th time trying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Content  Start Time  End Time  \\\n",
      "0  Can you tell me your name? Uh, (breathy) (paus...         0.0      30.0   \n",
      "1  (pause 0.12) what do you identify e- (pause 0....        30.0      60.0   \n",
      "2  (pause 0.31) That's where I mainly went to sch...        60.0      90.0   \n",
      "3  Um, (pause 0.37) <ts> (pause 0.40) think- I li...        90.0     120.0   \n",
      "4       (pause 0.51) and or songwriter and producer.       120.0     150.0   \n",
      "\n",
      "                                        Audio Tensor  \\\n",
      "0  [[tensor(-6.1035e-05), tensor(-3.0518e-05), te...   \n",
      "1  [[tensor(-0.0110), tensor(-0.0120), tensor(-0....   \n",
      "2  [[tensor(0.0081), tensor(0.0074), tensor(0.006...   \n",
      "3  [[tensor(0.0004), tensor(0.0005), tensor(0.000...   \n",
      "4  [[tensor(0.0158), tensor(0.0150), tensor(0.014...   \n",
      "\n",
      "                                          Audio Path  \\\n",
      "0  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...   \n",
      "1  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...   \n",
      "2  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...   \n",
      "3  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...   \n",
      "4  ../notebooks/coraal/audio/wav/ATL_se0_ag2_m_02...   \n",
      "\n",
      "                                      CleanedContent  \n",
      "0  Can you tell me your name? Uh,   the-  I was n...  \n",
      "1  what do you identify e-  ethnically,  ethnicit...  \n",
      "2  That's where I mainly went to school,    Cool,...  \n",
      "3  Um,    think- I lived in New York for a while ...  \n",
      "4                    and or songwriter and producer.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# # Load your original DataFrame\n",
    "# transcript_dir = \"../notebooks/coraal/transcript/text\"\n",
    "# transcript_df = pd.read_csv(transcript_dir + \"/ATL_se0_ag1_f_01_1.txt\", delimiter=\"\\t\")\n",
    "\n",
    "# Create a copy of the original DataFrame to avoid corruption\n",
    "cleaned_df5 = merged_df.copy()\n",
    "\n",
    "# Function to clean the \"Content\" column\n",
    "def clean_content(content):\n",
    "    # Remove anything within [ … ], / … /, < … >, and ( … )\n",
    "    content = re.sub(r'\\[.*?\\]', '', content)\n",
    "    content = re.sub(r'\\<.*?\\>', '', content)\n",
    "    content = re.sub(r'\\/.*?\\/', '', content)\n",
    "    content = re.sub(r'\\(.*?\\)', '', content)\n",
    "    # Remove special symbols while keeping punctuation marks\n",
    "    content = re.sub(r'[^a-zA-Z0-9\\s\\.\\,\\?\\!\\;\\:\\'\\\"\\-]', '', content)\n",
    "    # Strip leading and trailing whitespaces\n",
    "    content = content.strip()\n",
    "    return content\n",
    "\n",
    "# Apply the cleaning function to the \"Content\" column\n",
    "cleaned_df5['CleanedContent'] = cleaned_df5['Content'].apply(clean_content)\n",
    "\n",
    "# Keep the \"StTime\", \"EnTime\", and \"CleanedContent\" columns\n",
    "final_df5 = cleaned_df5#[['StTime', 'EnTime', 'CleanedContent']]\n",
    "\n",
    "# Reset the index of the cleaned DataFrame\n",
    "final_df5.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(final_df5.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# still cleaned too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Content, Start Time, End Time, Audio Tensor, Audio Path]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# # Load your original DataFrame\n",
    "# transcript_dir = \"../notebooks/coraal/transcript/text\"\n",
    "# transcript_df = pd.read_csv(transcript_dir + \"/ATL_se0_ag1_f_01_1.txt\", delimiter=\"\\t\")\n",
    "\n",
    "# # Create a copy of the original DataFrame to avoid corruption\n",
    "cleaned_df4 = merged_df.copy() # swap merged_df and transcript_df\n",
    "\n",
    "# Function to check for unwanted patterns in the \"Content\" column\n",
    "def contains_unwanted_patterns(content):\n",
    "    patterns = [r'\\[.*?\\]', r'\\<.*?\\>', r'\\/.*?\\/', r'\\(.*?\\)']\n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, content):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Apply the function to filter rows with unwanted patterns\n",
    "cleaned_df4 = cleaned_df4[~cleaned_df4['Content'].apply(contains_unwanted_patterns)]\n",
    "\n",
    "# Remove rows where \"Content\" is empty after removing unwanted patterns\n",
    "cleaned_df4 = cleaned_df4[cleaned_df4['Content'].str.strip() != '']\n",
    "\n",
    "# Remove rows containing the word \"pause\" in \"Content\"\n",
    "#cleaned_df2 = cleaned_df2[~cleaned_df['Content'].str.contains(r'\\bpause\\b', case=False, na=False)] # commented bc dataframe got empty for merge_df above\n",
    "\n",
    "# Keep only the \"StTime\", \"EnTime\", and \"Content\" columns\n",
    "final_df4 = cleaned_df4#[['StTime', 'EnTime', 'Content']] commented out bc wanted to keep coulmns made already\n",
    "\n",
    "# Reset the index of the cleaned DataFrame\n",
    "final_df4.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(final_df4.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to iterate through df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, Line                                                      1\n",
      "Spkr                                       ATL_se0_ag1_f_01\n",
      "StTime                                               0.4436\n",
      "Content    They talking about, don't send him to his daddy.\n",
      "EnTime                                               2.4068\n",
      "Name: 0, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each row in our dataframe\n",
    "for row in transcript_df.iterrows():\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line\n"
     ]
    }
   ],
   "source": [
    "# Iterates through columns\n",
    "for data in transcript_df:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas(Index=0, Line=1, Spkr='ATL_se0_ag1_f_01', StTime=0.4436, Content=\"They talking about, don't send him to his daddy.\", EnTime=2.4068)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for tuples in transcript_df.itertuples():\n",
    "    display(tuples)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
